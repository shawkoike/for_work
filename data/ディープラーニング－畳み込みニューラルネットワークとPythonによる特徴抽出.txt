<p><a href="http://blog.christianperone.com/2015/08/convolutional-neural-networks-and-feature-extraction-with-python/" rel="nofollow" title="" class="ext-link">Deep learning – Convolutional neural networks and feature extraction with Python</a> （2015-08-19） by <a href="https://twitter.com/tarantulae" rel="nofollow" title="" class="ext-link">Christian S. Perone</a></p><p>畳み込みニューラルネットワーク（または<a href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="nofollow" title="" class="ext-link">ConvNet</a>）は、生物学から着想を得た多層パーセプトロン（MLP）の変形です。畳み込みニューラルネットワークには種類の異なる様々な層があり、各層は通常のMLPとは異なる働きをします。ConvNetについて詳しく学びたい方には、<a href="http://cs231n.github.io/convolutional-networks/" rel="nofollow" title="" class="ext-link">CS231n 視覚認識のための畳み込みニューラルネットワーク</a>のコースをお勧めします。以下の図は、畳み込みニューラルネットワークのアーキテクチャを表しています。</p><p><img class="wp-image-2890" src="http://blog.christianperone.com/wp-content/uploads/2015/08/neural_net2.jpeg" alt="A regular neural network." width="449" height="220"><br>
<em>訳：入力層→隠れ層1→隠れ層2→出力層</em></p><p>標準的なニューラルネットワーク（CS231nのWebサイトより）</p><p><img class="wp-image-2894" src="http://blog.christianperone.com/wp-content/uploads/2015/08/cnn.jpeg" alt="A ConvNet network achitecture (from CS231n website)." width="453" height="161"></p><p>畳み込みニューラルネットワークのアーキテクチャ（CS231nのWebサイトより）</p><p>この図で分かるように、ConvNetは3次元の量および3次元の量への変換によって機能します。CS231nのチュートリアル全てをここで繰り返すつもりはありませんが、もし興味があれば、この続きを読む前にチュートリアルを一読してください。</p><p>私が気に入って使っているディープラーニング用のPythonのパッケージの1つが<a href="https://github.com/Lasagne/Lasagne" rel="nofollow" title="" class="ext-link">Lasagne</a>と<a href="https://github.com/dnouri/nolearn" rel="nofollow" title="" class="ext-link">nolearn</a>です。LasagneはTheanoをベースにしているので、GPUのスピードアップにより非常に大きな違いが出ます。さらに、ニュートラルネットワークの構築に宣言的アプローチを使えるのでとても便利です。nolearnライブラリは、ニューラルネットワークのパッケージ（Lasagneを含む）周辺のユーティリティを集めたものです。これは、ニューラルネットワークのアーキテクチャを構築する際、層の検査などを行う時にとても役に立ちます。</p><p>この投稿では、畳み込み層とプーリング層を用いたシンプルなConvNetアーキテクチャの構築方法をご紹介したいと思います。また、ConvNetを使ってどのように特徴抽出機構をトレーニングし、サポートベクターマシン（SVM）やロジスティック回帰といった異なるモデルに与える前の特徴をどのように抽出するかという方法もご紹介します。多くの場合、事前トレーニングされたConvNetモデルを使い、特徴を抽出するために、ImageNetのデータセットでトレーニングされたConvNetから最終的な出力層を取り除きます。これは普通、転移学習と呼ばれています。というのも、異なる問題用の特徴抽出機構として、他のConvNetの層を使うことができるからです。ConvNetの最初の層のフィルタはエッジ検出器として機能するので、他の問題用の一般的な特徴検出機構として使うことができます。</p><p><a href="http://yann.lecun.com/exdb/mnist/" rel="nofollow" title="" class="ext-link">MNISTデータセット</a>とは手書きの数字を分類する最も古典的なデータセットの1つです。ここではPython用にpickle化したバージョンを使いますが、まず、必要なパッケージをインポートしましょう。</p><p>ご覧のとおり、描画のためのmatplotlib、MNISTデータセットをダウンロードするPythonのネイティブモジュール、numpy、theano、lasagne、nolearnと、モデル評価用のscikit-lean関数がインポートされます。</p><p>その後、MNISTの読み込み関数を定義します（これはLasagneチュートリアルで使ったものとほぼ同じ関数です）。</p><p>ここではMNISTのpickle化されたデータセットをダウンロードし、それを3つの異なるデータセット（train、validationとtest）に分割しています。その後、画像コンテンツをreshapeし、後でLasagne 入力層に入力する準備をします。GPU/theanoにはデータ型に制限があるので、数値配列型をuint8に変換します。</p><p>MNISTデータセットを読み込み、inspectする準備ができました。</p><p>上記のコードにより下記のイメージが出力されます（IPython Notebookを使っています）。</p><p><img class="wp-image-2897 size-full" src="http://blog.christianperone.com/wp-content/uploads/2015/08/5.png" alt="An example of a MNIST digit (5 in the case)." width="252" height="252"></p><p>MNISTの数の例（この場合は5）</p><p>さあConvNetアーキテクチャを定義し、GPU/CPUを使ってトレーニングしましょう（私のGPUは安物ですが、とても役立っています）。</p><p>パラメータ<em>層</em>の中では、層の名称/型でタプルの辞書を定義し、そして、この層のパラメータを定義します。ここでのアーキテクチャは2つの畳み込み層とプーリング、全結合層（密層）、そして出力層を使っています。層の間にはドロップアウトもあります。ドロップアウト層はランダムに入力値を0に設定して過剰適合を防ぐための正則化項です（下記の画像を参照してください）。</p><p><img class=" wp-image-2899" src="http://blog.christianperone.com/wp-content/uploads/2015/08/dropout.jpeg" alt="Dropout layer effect (from CS231n website)." width="520" height="278"><br>
ドロップアウト層の効果（CS231nのWebサイトより）</p><p><em>トレーニング</em>メソッドを呼び出した後、nolearnパッケージが学習プロセスのステータスを示します。質素なGPUの搭載された私のマシンでは、下記のような結果になりました。</p><p>最終的な正確性は0.98526でした。10エポックのトレーニングにしてはかなりいいパフォーマンスです。</p><p>これでデータセットの全テスト結果を予測するために、このモデルを使用することが可能となりました。</p><p>そこから、またニュートラルネットワーク分類のパフォーマンスをチェックするために、混同行列をプロットすることができます。</p><p>上記のコードは、次のような混同行列をプロットします。</p><p><img class="size-full wp-image-2903" src="http://blog.christianperone.com/wp-content/uploads/2015/08/cm.png" alt="Confusion Matrix" width="267" height="244"><br>
混同行列</p><p>ご覧のように、対角項に分類がより密集しており、分類器のパフォーマンスが上々であることを表しています。</p><p>次は最初の畳み込み層から32のフィルタを視覚化します。</p><p>上記のコードは、次のようなフィルタを描画します。</p><p><img class="size-full wp-image-2904" src="http://blog.christianperone.com/wp-content/uploads/2015/08/32filters_1stlayer.png" alt="The first layer 5x5x32 filters." width="349" height="349"><br>
最初の層、5x5x32フィルタ</p><p>ご覧のように、nolearnの <code>plot_conv_weights</code>が指定した層に存在する全てのフィルタを生成します。</p><p>今度はいよいよtheanoでコンパイルした関数を作成し、あなたが意図する層の所までアーキテクチャに入力値をフィードフォワードします。出力層を求めるための関数と出力層の前にある密層を求めるための関数を取得します。</p><p>ご覧のように、（出力層と密層を求めるための）<code>f_output</code>と<code>f_dense</code>という2つのtheano関数を得ました。注意してほしいのは、ここで層を得るために、“deterministic”という追加パラメータを使用しているということです。これはフィードフォワードパスに影響するドロップアウト層を避けるためです。</p><p>ここでサンプルのinstanceを入力フォーマットに変え、出力層を求めるためのtheano関数にフィードします。</p><p>ご覧のように、f_output関数は平均858マイクロ秒かかりました。instanceの出力層の活性化を描画することができます。</p><p>上記のコードは次のようにプロットされます。</p><p><img class="size-full wp-image-2905" src="http://blog.christianperone.com/wp-content/uploads/2015/08/output_activations.png" alt="Output layer activations." width="373" height="256"><br>
出力層の活性化</p><p>ご覧のように、この手書き数字は、7と認識されました。「ネットワークのどの層を求めるにもtheano関数を作成できる」ということが、とても有効であることが分かります。というのも（以前やったように）、出力層の1つ前の密層の活性化を求めるために関数を作ることができ、その活性化を特徴として活用でき、分類器ではなく、特徴抽出機構としてニューラルネットワークを使用することができるからです。続いて、密層のための256ユニットの活性化をプロットしてみましょう。</p><p>上記のコードは、以下のようなプロットを作成します。</p><p><img class="size-full wp-image-2906" src="http://blog.christianperone.com/wp-content/uploads/2015/08/dense_activations.png" alt="Dense layer activations." width="367" height="256"><br>
密層の活性化</p><p>この256の活性化の出力値を、ロジスティック回帰やSVMといった線形分類器で入力する特徴として使用できます。</p><p>チュートリアルを楽しんでいただけましたでしょうか？</p>
