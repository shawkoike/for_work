<p><a href="https://probablydance.com/2017/02/26/i-wrote-the-fastest-hashtable/" rel="nofollow" title="" class="ext-link">I Wrote The Fastest Hashtable</a> （2017-02-26） by <a href="https://probablydance.com/" rel="nofollow" title="" class="ext-link">Malte Skarupke</a></p><p>要素の削除についても測定してみましょう。ここでも、キーを整数にして3つのテストを、キーを文字列にして3つのテストを行いました。使ったのは4バイト値、32バイト値、1024バイト値です。4バイト値の図は前掲のとおりです。32バイト値の図はほとんど同じなので省略します。1024バイト値の図は以下のようになります。</p><p><img data-attachment-id="7322" data-permalink="https://probablydance.com/2017/02/26/i-wrote-the-fastest-hashtable/erase_1024/" data-orig-file="https://probablydance.files.wordpress.com/2017/02/erase_1024.png?w=650" data-orig-size="1231,622" data-comments-opened="1" data-image-meta='{"aperture":"0","credit":"","camera":"","caption":"","created_timestamp":"0","copyright":"","focal_length":"0","iso":"0","shutter_speed":"0","title":"","orientation":"0"}' data-image-title="erase_1024" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2017/02/erase_1024.png?w=650?w=300" data-large-file="https://probablydance.files.wordpress.com/2017/02/erase_1024.png?w=650?w=650" class="alignnone size-full wp-image-7322" src="https://probablydance.files.wordpress.com/2017/02/erase_1024.png?w=650" alt="erase_1024" srcset="https://probablydance.files.wordpress.com/2017/02/erase_1024.png?w=650 650w, https://probablydance.files.wordpress.com/2017/02/erase_1024.png?w=150 150w, https://probablydance.files.wordpress.com/2017/02/erase_1024.png?w=300 300w, https://probablydance.files.wordpress.com/2017/02/erase_1024.png?w=768 768w, https://probablydance.files.wordpress.com/2017/02/erase_1024.png?w=1024 1024w, https://probablydance.files.wordpress.com/2017/02/erase_1024.png 1231w" sizes="(max-width: 650px) 100vw, 650px"><br>
<em>注釈：<br>
削除<br>
整数キー、1024バイト構造体値<br>
（縦軸）ナノ秒/要素<br>
（横軸）要素の数</em></p><p>大きく違う点は、dense_hash_mapがかなり遅くなったことです。これは、大きな値タイプでテストした他の図の時と同じ問題です。他のテーブルは、単純に要素が削除されたと見なし、デストラクタ（私の構造体ではno-op）を呼び出します。一方、dense_hash_mapは”空の”キーと値のペアでその値を上書きしますが、1024バイトのデータを持っている場合にはそれが大きな操作となるのです。</p><p>他に上の図から分かる大きな違いは、flat_hash_mapからの削除が他のテーブルの場合よりもはるかにギザギザの激しいグラフになっており、線がかなり上昇してノードベースコンテナの場合とほぼ同じくらいコストが高くなっているということです。この理由は、flat_hash_mapはある要素が削除される際に各要素を移動する必要があり、各要素が1028バイトのデータの時にコストが高くなっているからだと思います。</p><p>文字列削除のグラフは、お見せする必要がほとんどないくらい整数削除のグラフと似ていますが、以下のとおりです。</p><p><img data-attachment-id="7330" data-permalink="https://probablydance.com/2017/02/26/i-wrote-the-fastest-hashtable/erase_string/" data-orig-file="https://probablydance.files.wordpress.com/2017/02/erase_string.png?w=650" data-orig-size="1054,563" data-comments-opened="1" data-image-meta='{"aperture":"0","credit":"","camera":"","caption":"","created_timestamp":"0","copyright":"","focal_length":"0","iso":"0","shutter_speed":"0","title":"","orientation":"0"}' data-image-title="erase_string" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2017/02/erase_string.png?w=650?w=300" data-large-file="https://probablydance.files.wordpress.com/2017/02/erase_string.png?w=650?w=650" class="alignnone size-full wp-image-7330" src="https://probablydance.files.wordpress.com/2017/02/erase_string.png?w=650" alt="erase_string.png" srcset="https://probablydance.files.wordpress.com/2017/02/erase_string.png?w=650 650w, https://probablydance.files.wordpress.com/2017/02/erase_string.png?w=150 150w, https://probablydance.files.wordpress.com/2017/02/erase_string.png?w=300 300w, https://probablydance.files.wordpress.com/2017/02/erase_string.png?w=768 768w, https://probablydance.files.wordpress.com/2017/02/erase_string.png?w=1024 1024w, https://probablydance.files.wordpress.com/2017/02/erase_string.png 1054w" sizes="(max-width: 650px) 100vw, 650px"><br>
<em>注釈：<br>
削除<br>
文字列キー、整数値<br>
（縦軸）ナノ秒/要素<br>
（横軸）要素の数</em></p><p>整数削除の場合と非常に似ています。値のサイズを1024バイトにした場合は、このグラフの前のグラフとそっくりになりますので、そちらを再度ご覧ください。</p><p>最後のテストは「挿入、削除、再び挿入」です。前に、挿入と削除をランダムな順序で行ったテストです。1028バイトの要素1000万個で実行してみたらメモリが使い果たされてしまったため、要素数は1万個に減らしました。また、要素数が少ない時の方がグラフの作成時間ははるかに短くなります。32バイトの値タイプから見てみましょう。</p><p><img data-attachment-id="7342" data-permalink="https://probablydance.com/2017/02/26/i-wrote-the-fastest-hashtable/insert_and_erase_32/" data-orig-file="https://probablydance.files.wordpress.com/2017/02/insert_and_erase_32.png?w=650" data-orig-size="1001,571" data-comments-opened="1" data-image-meta='{"aperture":"0","credit":"","camera":"","caption":"","created_timestamp":"0","copyright":"","focal_length":"0","iso":"0","shutter_speed":"0","title":"","orientation":"0"}' data-image-title="insert_and_erase_32" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2017/02/insert_and_erase_32.png?w=650?w=300" data-large-file="https://probablydance.files.wordpress.com/2017/02/insert_and_erase_32.png?w=650?w=650" class="alignnone size-full wp-image-7342" src="https://probablydance.files.wordpress.com/2017/02/insert_and_erase_32.png?w=650" alt="insert_and_erase_32.png" srcset="https://probablydance.files.wordpress.com/2017/02/insert_and_erase_32.png?w=650 650w, https://probablydance.files.wordpress.com/2017/02/insert_and_erase_32.png?w=150 150w, https://probablydance.files.wordpress.com/2017/02/insert_and_erase_32.png?w=300 300w, https://probablydance.files.wordpress.com/2017/02/insert_and_erase_32.png?w=768 768w, https://probablydance.files.wordpress.com/2017/02/insert_and_erase_32.png 1001w" sizes="(max-width: 650px) 100vw, 650px"><br>
<em>注釈：<br>
挿入、削除<br>
整数キー、32バイト構造体値<br>
（縦軸）ナノ秒/挿入<br>
（横軸）挿入の数</em></p><p>今回はflat_hash_mapがdense_hash_mapにまさっています。値のサイズを更に大きくすると、この差は広がります。</p><p><img data-attachment-id="7345" data-permalink="https://probablydance.com/2017/02/26/i-wrote-the-fastest-hashtable/insert_and_erase_1024/" data-orig-file="https://probablydance.files.wordpress.com/2017/02/insert_and_erase_1024.png?w=650" data-orig-size="1006,528" data-comments-opened="1" data-image-meta='{"aperture":"0","credit":"","camera":"","caption":"","created_timestamp":"0","copyright":"","focal_length":"0","iso":"0","shutter_speed":"0","title":"","orientation":"0"}' data-image-title="insert_and_erase_1024" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2017/02/insert_and_erase_1024.png?w=650?w=300" data-large-file="https://probablydance.files.wordpress.com/2017/02/insert_and_erase_1024.png?w=650?w=650" class="alignnone size-full wp-image-7345" src="https://probablydance.files.wordpress.com/2017/02/insert_and_erase_1024.png?w=650" alt="insert_and_erase_1024.png" srcset="https://probablydance.files.wordpress.com/2017/02/insert_and_erase_1024.png?w=650 650w, https://probablydance.files.wordpress.com/2017/02/insert_and_erase_1024.png?w=150 150w, https://probablydance.files.wordpress.com/2017/02/insert_and_erase_1024.png?w=300 300w, https://probablydance.files.wordpress.com/2017/02/insert_and_erase_1024.png?w=768 768w, https://probablydance.files.wordpress.com/2017/02/insert_and_erase_1024.png 1006w" sizes="(max-width: 650px) 100vw, 650px"><br>
<em>注釈：<br>
挿入、削除<br>
整数キー、1024バイト構造体値<br>
（縦軸）ナノ秒/挿入<br>
（横軸）挿入の数</em></p><p>非常に大きな値タイプでは、私のテーブルがdense_hash_mapにまさっています。一方、今回は初めのうちはノードベースコンテナが私のハッシュテーブルを上回っていますが、次第に私のテーブルが追い付いているようです。その理由は、今回のテストではreserveを呼び出していないからです。よって、最初の挿入時にテーブルは再割り当てを何度も行う必要があるのでフラットコンテナではコストが非常に高くなり、ノードベースコンテナではコストが比較的低くなっているのです。しかし、数個の要素を削除、挿入するにつれて再割り当てのコストは償却され、私のテーブルがunordered_mapを上回っています。ある地点になればmulti_indexにもまさるでしょう。事前にreserveした場合は直ちにmulti_indexを上回っています。</p><p><img data-attachment-id="7351" data-permalink="https://probablydance.com/2017/02/26/i-wrote-the-fastest-hashtable/reserve_insert_and_erase_1024/" data-orig-file="https://probablydance.files.wordpress.com/2017/02/reserve_insert_and_erase_1024.png?w=650" data-orig-size="1075,585" data-comments-opened="1" data-image-meta='{"aperture":"0","credit":"","camera":"","caption":"","created_timestamp":"0","copyright":"","focal_length":"0","iso":"0","shutter_speed":"0","title":"","orientation":"0"}' data-image-title="reserve_insert_and_erase_1024" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2017/02/reserve_insert_and_erase_1024.png?w=650?w=300" data-large-file="https://probablydance.files.wordpress.com/2017/02/reserve_insert_and_erase_1024.png?w=650?w=650" class="alignnone size-full wp-image-7351" src="https://probablydance.files.wordpress.com/2017/02/reserve_insert_and_erase_1024.png?w=650" alt="reserve_insert_and_erase_1024.png" srcset="https://probablydance.files.wordpress.com/2017/02/reserve_insert_and_erase_1024.png?w=650 650w, https://probablydance.files.wordpress.com/2017/02/reserve_insert_and_erase_1024.png?w=150 150w, https://probablydance.files.wordpress.com/2017/02/reserve_insert_and_erase_1024.png?w=300 300w, https://probablydance.files.wordpress.com/2017/02/reserve_insert_and_erase_1024.png?w=768 768w, https://probablydance.files.wordpress.com/2017/02/reserve_insert_and_erase_1024.png?w=1024 1024w, https://probablydance.files.wordpress.com/2017/02/reserve_insert_and_erase_1024.png 1075w" sizes="(max-width: 650px) 100vw, 650px"><br>
<em>注釈：<br>
reserve、挿入、削除<br>
整数キー、1024バイト構造体値<br>
（縦軸）ナノ秒/挿入<br>
（横軸）挿入の数</em></p><p>これは予想外でした。というのも、事前にreserveしたとしても、私のコンテナはやはり要素を移動する必要があり、それは1028バイトのデータでは非常にコストが高くなるはずだからです。私のコンテナが依然速い理由として唯一考えられるのは、占有率がかなり低く、衝突がめったに発生しないことです。このテストを文字列で測定すると、私のコンテナは予想どおり遅くなり、multi_indexが肩を並べてきます。</p><p><img data-attachment-id="7355" data-permalink="https://probablydance.com/2017/02/26/i-wrote-the-fastest-hashtable/reserve_insert_erase_string/" data-orig-file="https://probablydance.files.wordpress.com/2017/02/reserve_insert_erase_string.png?w=650" data-orig-size="989,558" data-comments-opened="1" data-image-meta='{"aperture":"0","credit":"","camera":"","caption":"","created_timestamp":"0","copyright":"","focal_length":"0","iso":"0","shutter_speed":"0","title":"","orientation":"0"}' data-image-title="reserve_insert_erase_string" data-image-description="" data-medium-file="https://probablydance.files.wordpress.com/2017/02/reserve_insert_erase_string.png?w=650?w=300" data-large-file="https://probablydance.files.wordpress.com/2017/02/reserve_insert_erase_string.png?w=650?w=650" class="alignnone size-full wp-image-7355" src="https://probablydance.files.wordpress.com/2017/02/reserve_insert_erase_string.png?w=650" alt="reserve_insert_erase_string" srcset="https://probablydance.files.wordpress.com/2017/02/reserve_insert_erase_string.png?w=650 650w, https://probablydance.files.wordpress.com/2017/02/reserve_insert_erase_string.png?w=150 150w, https://probablydance.files.wordpress.com/2017/02/reserve_insert_erase_string.png?w=300 300w, https://probablydance.files.wordpress.com/2017/02/reserve_insert_erase_string.png?w=768 768w, https://probablydance.files.wordpress.com/2017/02/reserve_insert_erase_string.png 989w" sizes="(max-width: 650px) 100vw, 650px"><br>
<em>注釈：<br>
reserve、挿入、削除<br>
文字列キー、整数値<br>
（縦軸）ナノ秒/挿入<br>
（横軸）挿入の数</em></p><p>文字列挿入の他のグラフは上掲のものと似た感じになります。32バイトの値タイプの挿入では、この最後のグラフのようになります。1024バイトの値タイプの挿入では、reserveを呼び出した場合と呼び出さなかった場合のいずれも、同じことを整数をキーとして実行した際のグラフのようになります。</p><p>かなり多数の測定を行いました。ハッシュテーブルを測定することは驚くほど複雑です。同一の占有率やデフォルトの設定で全てのテーブルを測定すべきかはまだ十分確信があるわけではありません。今回はデフォルト設定で測定しています。その上、様々なキー、様々な値サイズ、様々なテーブルサイズ、reserve呼び出しの有無など、実に多様なケースが存在します。そして行うべきテストがたくさんあるのです。このブログ記事に何千ものグラフを掲載することもできたのですが、ある程度以上はやり過ぎになるため、まとめに入ります。</p><p>私のテーブルを使う場合は、コンストラクタ、コピーコンストラクタ、ハッシュ関数、等値関数、そしてアロケータで例外を投げるようにした方が安全です。ムーブコンストラクタやデストラクタで例外を投げることは許可されていません。その理由は、私としては要素を移動して不変部分を維持する必要があったからです。ムーブコンストラクタで例外を投げる方法は、私は把握していません。</p><p>ソースコードはGitHubにアップロードしてありますので、<a href="https://github.com/skarupke/flat_hash_map/blob/master/flat_hash_map.hpp" rel="nofollow" title="" class="ext-link">こちら</a>からダウンロードできます。Boost Software Licenseの下で利用頂くことができます。ソースコードは単一のヘッダファイルで、ska::flat_hash_mapとska::flat_hash_setの両方を含んでいます。インターフェースはstd::unordered_mapとstd::unordered_setのものと同一です。</p><p>power_of_twoバージョンのテーブルを使いたい場合は、1つ厄介な作業があります。その方法については本記事の前の方で説明していますので、参照するには「ska::power_of_two_hash_policy」で検索してください。</p><p>私の実行環境におけるmax_load_factorのデフォルト値は0.5であるということも備考として書いておきます。この値は0.9まで上げても安全です。ただし、テーブルはおそらくその数値に達する前に再割り当てを行うということに留意してください。テーブルは、探索回数の上限に達するので70％使用済みになる前に再割り当てを行う傾向があります。しかし、そのことを考慮しておかないと予期せぬ時にテーブルが再割り当てを行うかもしれませんから、max_load_factorの値を上げておけば、パフォーマンスをほとんど損なわずにメモリを少し節約できるのです。</p><p>今回、実際に最速のハッシュテーブルを書くことができたように思います。ルックアップの速さは明らかに一番ですし、挿入と削除についても非常に高速です。新たに取り入れた最大の秘訣は、探索回数に上限を設定することです。探索回数をlog2(n)に制限すると、最悪のケースでのルックアップ時間がO(n)ではなくO(log(n))になります。これで実際に違いが出てきます。探索回数制限はロビンフッドハッシュ法では大いに効果があり、内部ループでの巧みな最適化が可能になるのです。</p><p>このハッシュテーブルは、hash_mapとhash_setの両バージョンとして、Boost Software Licenseの下での利用が可能です。ご活用ください。</p>
