<p><a href="http://dak1n1.com/blog/14-http-load-generate" rel="nofollow" title="" class="ext-link">How to Generate Millions of HTTP Requests</a> (2012-04-22) by <a href="https://twitter.com/dak1n1" rel="nofollow" title="" class="ext-link">Stefanie Forrester</a></p><p><small>(注記：6/9、いただいた翻訳フィードバックを元に記事を修正いたしました。)</small></p><p>今回の記事は毎秒300万ものリクエストを処理できるほど強力で高性能なWebクラスタの構築についてのパート1になります。まず初めに、あまり多くはありませんが、私がこれまで使用したことのあるロードジェネレータツールをいくつか紹介します。私のようにてこずって時間をかけてしまわないよう、今回の記事が理解の手助けになれば幸いです。</p><p>ロードジェネレータはテストを目的とした数種類のトラフィックを発生させるプログラムです。それによって高負荷においてサーバがどのように動いているか、そのサーバの弱点はどこなのか、などが見えてきます。負荷テストを通じてサーバの限界を知ることは、サーバのレジリエンシーを測定する最適な方法であり、あらゆる問題に対する準備の手助けにもなります。</p><p>負荷テストをする際に頭に入れておくべき重要なことはLinuxには限られたソケットしかないということです。これはカーネルをハードコーディングしたことによる制限であり、<a href="http://aleccolocco.blogspot.com/2008/11/ephemeral-ports-problem-and-solution.html" rel="nofollow" title="" class="ext-link">エフェメラルポート問題</a>として知られています。/etc/sysctl.conf内で（ある程度は）拡張が可能ではありますが、基本的にはLinuxで一度に開けるソケットの数はおよそ64,000個しかありません。そのため、負荷テストをする際に1つの接続から可能な限りリクエストを送るようにして、ソケットを最大限に活用する必要があります。それに加えて、負荷の生成を行うマシンが複数台必要になります。そうしなければ、使用可能なソケット数が上限に達してしまい、十分な負荷を発生させられなくなります。</p><p>最初は「ab」、つまりApache Benchから使用してみました。これは私の知る限り最もシンプルで一般的に使われているHTTPベンチマークツールです。さらにこれは、Apacheに付属しているものなので、おそらくどのシステムにも既に搭載されていると思います。しかし残念なことに私が使用したところ、毎秒たった900のリクエストしか得られませんでした。他で2,000ものリクエストを得られる結果を見たこともありますが、「ab」はあまりこの作業に向いていないとすぐに断言できました。</p><p>次は「httperf」を使用してみました。このツールはより強力ではありますが、それでも比較的単純で機能的に限界があります。毎秒どのくらいのリクエストを生成するかを知るということは単純に数を数える作業とは違って簡単ではありません。何回か試して、やっと毎秒数百以上のリクエストを得ることができました。以下がその例です。</p><p>以下では10万のセッションを生成します。レートは毎秒1,000です。各セッションがそれぞれ5回のコールを実行し、そしてそれは2秒ごとにバーストします。</p><p>結果として、これらの設定で毎秒6,622の接続が得られました。</p><p>（合計10万の接続が毎秒2万の固定レートで生成されました。）</p><p>「httperf」には潜在能力があり、わずかながら「ab」より多くの機能を持っていますが、今回のプロジェクトに使用するにはまだ不十分な性能です。分散したやり方で複数の負荷テストノードをサポートできるものが必要となります。従って、次に試すものはJMeterです。</p><p>これは完全な機能を備えたWebアプリケーションのテストスイートで、実生活におけるユーザの振る舞いについてはどんな類いのものでも再現できます。例えばJMeterのプロキシを使って自分のWebサイトを訪れ、自由にクリックしたりログインしたりと、ユーザがしそうな操作をいろいろと行います。そしてそれらの操作をJMeterにテストケースとして記録します。するとJMeterは、こちらの指定した”ユーザ”数で、それらのアクションを繰り返し実行します。これは非常に面白かったです。<a href="http://jmeter.apache.org/usermanual/test_plan.html" rel="nofollow" title="" class="ext-link">設定</a>は「ab」や「httperf」よりもだいぶ複雑ですけどね。</p><p>このテストを実行したところ、すぐに毎秒14,000リクエストを達成しました。これは間違いなく、よい方向に向かっていると思いました。</p><p>私は<a href="http://jmeter-plugins.org/" rel="nofollow" title="" class="ext-link">JMeter-Plugins</a>からプラグインをいくつか追加しました。そして「Stepping Threads」と「HTTP RAW」リクエストを使ったところ、ついに毎秒3万のリクエストを生成することができたのです。しかしそこで頭打ちだったので、次を試すことにしました。こちらのリンク先に、私が以前作成した<a href="http://pastebin.com/54vJTNVE" rel="nofollow" title="" class="ext-link">JMeterの設定</a>を載せています。もし誰かの役に立てれば嬉しいです。完璧には程遠いものですが、出発点さえ定まればいい、ということもありますよね。</p><p>これは明らかに良いツールでした。使い始めてすぐに、私はこのツールで毎秒4万リクエストを達成したのです。JMeterのように実行するテスト用に操作を記録できますし、SSLやHTTP、WebDAV、SOAP、PostgreSQL、MySQL、LDAP、Jabber/XMPPなどの多くのプロトコルをテストできます。またJMeterと違って複雑なGUIがないので悩むこともありません。XMLの設定ファイルと、選択した分散ノードへのSSH鍵がいくつかあるだけです。このツールの簡潔さと効率性、そしてロバストネスとスケーラビリティは、私にとってどれも負けず劣らず魅力的でした。このツールは非常にパワフルだと感じました。設定を誤ることなく数百万のHTTPリクエストを生成するのです。</p><p>それに加えて、TsungはHTMLで実行したテストについてグラフを作成し、詳細な報告を上げてくれます。テスト結果は分かりやすいですし、画像があるので上司に見せることだってできるのです。</p><p>3部構成の記事のパート1のラストとして、これ以降はこのツールについて書きたいと思います。以下の設定についての説明をご覧ください。または<a href="http://dak1n1.com/blog/12-nginx-performance-tuning/" rel="nofollow" title="" class="ext-link">次のページ</a>へスキップして頂いても結構です。</p><p>まず必要なのが、EPELリポジトリ（Erlang用）です。先に進む前に、<a href="http://dak1n1.com/blog/3-getting-more-from-yum-with-rpmforge-and-epel-repos/" rel="nofollow" title="" class="ext-link">これをセットアップ</a>しておきましょう。それが完了したら、負荷の生成に使用する各ノードで必要となるパッケージをインストールします。まだノード間のパスワードレスのSSH鍵を設定していないようでしたら、それも行いましょう。</p><p>最新のTsungを、GithubまたはTsungのWebサイトからダウンロードします。</p><p>展開してコンパイルします。</p><p>設定の例を~/.tsung. にコピーします。これはTsungの設定ファイルとログファイルの位置です。</p><p>ご自分の仕様に合わせてこのファイルを編集することもできますし、私の設定をそのまま使っていただいても結構です。以下は私が思考錯誤して設定したもので、7つの分散ノードで使用すると、今や毎秒500万のHTTPリクエストを生成します。</p><p>最初のうちは非常に難しく感じますが、一度理解してしまえばとても簡単です。</p><p>それぞれの意味を正しく理解できれば、この便利なエイリアスを作成して、すぐにTsungのレポートを確認することができるようになります。</p><p>それでは、Tsungを使ったテストを開始しましょう。</p><p>テストが終了したらレポートを確認します。</p><p><img src="http://dak1n1.com/images/tsung-thumb.png" alt="tsung-thumb" width="700" height="639" scale="0"></p><p>さて、これで十分に優れた負荷テストツールが手に入ったので、残りのクラスタ構築を計画することが可能です。</p><p>このパート1に続く2つの記事では、皆さんのWebサーバで最速のパフォーマンスを得るための方法と、クラスタソフトウェアのLVSを導入する方法をご紹介します。</p><p><a href="http://dak1n1.com/blog/12-nginx-performance-tuning/" rel="nofollow" title="" class="ext-link">このシリーズのパート2、「Tuning Nginx for Best Performance」 はこちらからどうぞ。</a></p>
