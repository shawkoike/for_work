On dynamic arrays (2016-06-26) By Alex Dzyoba私はSkienaの『Algorithm Design Manual』(訳注：『アルゴリズム設計マニュアル』 上巻・下巻) を読んでいました。ところでこの本は素晴らしい本で、連結リストと配列についてこんな比較をしていました(chapter 3.1.3)。Skiena氏は包括的な比較をしてくれているのですが、残念ながら最後のポイントについての重きの置き方が十分ではありません。私はシステムプログラマとして、「メモリアクセスパターンや効率的なキャッシュ、効率的なCPUパイプラインの利用が大きな影響力を持ち得る・持つ」ということを知っており、ここではそれを示したいと思っています。簡単なテストをしてみて、連結リストと動的配列のデータ構造での基本的な操作(挿入や検索など)のパフォーマンスを比較してみましょう。コンピュータ・サイエンスの場における完璧なツールとして、私はJavaを使うことにします。JavaにはLinkedListとArrayListの両方があります。これらはそれぞれ連結リストと動的配列を実装しており、両方が同じListインターフェイスを実装しています。テストには以下のものを含みます。ソースは私のCS playgoundリポジトリのds/list-perf ディレクトリSources are at my CS playground in ds/list-perf ディレクトリにあります。これはMavenプロジェクトなので、mvn packageするだけでjarを入手可能です。テストは極めてシンプルで、例えば以下がランダム挿入のテストです。これはListインターフェイスを利用して動作しており(そうです、ポリモーフィズムです！)、何も変更せずともLinkedListとArrayListの両方を渡すことができます。テストは先ほど書いた通りの順番(割り当て→挿入→検索→削除)で複数回実行され、全ての結果の最小値/中央値/最大値を計算します。さあ、説明はこれで十分でしょうから、実行してみましょう！ぱっと見て分かる通り、LinkedListが劣っています。しかし、素晴らしい箱ひげ図をご覧になって下さい。
LinkedListとArrayListでの割り当てと削除
LinkedListとArrayListでの挿入
LinkedListとArrayListでの検索そして、全てのテストをまとめたリンクもあります。全ての操作において、LinkedListが恐ろしく劣っています。唯一の例外が先頭への挿入ですが、それでも動的配列の最悪のケースと勝負しているだけです。このケースにおいて、動的配列は配列全体を毎回コピーしなければならないからです。これを説明するために、実装について少し深く見ていきます。Java 8のOpenJDKのソースを使います。ArrayListとLinkedListのソースはsrc/share/classes/java/utilにあります。JavaのLinkedListは、Node内部クラスを通じた双方向リストとして実装されています。では、シンプルな割り当てテストの状況下で何が起こっているのかを見てみましょう。これは、addメソッドを
呼び出し、さらにaddメソッドはJDKのlinkLastメソッドを呼び出します。基本的に、LinkedListでの割り当ては定数時間の操作となります。LinkedListクラスは末尾のポインタを保持しているため、挿入のために必要なのは「新しいオブジェクトの割り当て」「2つのポインタの更新」のみとなります。これがそんなに遅くなるはずがないのです！ では、なぜ実際は遅くなっているのでしょう？ArrayListと比較してみましょう。JavaのArrayListは実のところ、「初期設定として10個までの容量を持ち、容量を増やす際には毎回1.5倍に増やす」という動作をする動的配列なのです。//overflow-conscious codeという記述も実におかしです。なぜこのようになっているのかという理由は、こちらで読むことができます。自身のリサイズはArrays.copyOfを通じて行われており、これはJavaのネイティブメソッドであるSystem.arraycopyを呼び出します。ネイティブメソッドの実装はJDKの一部ではないため、これはJVM固有の機能となります。HotSpotのソースを探し出し、見てみましょう。簡潔にまとめると以下の通りです―この機能はTypeArrayKlass:copy_arrayメソッド内にあり、これはCopy:conjoint_memory_atomicを呼び出します。このメソッドはアラインメントを探しますが、見ての通りメソッド内にはコピーメソッドのlong、int、short、bytes(アラインメントがない場合)向けのバリエーションがあります。int向けのメソッドであるconjoint_jints_atomicを見てみますが、これはpd_conjoint_jints_atomicのラッパであり、OSとCPUに固有のものとなります。Linux用のバリエーションを探してみると、_Copy_conjoint_jints_atomicへの呼び出しが見つかります。最後に待ち受けているのはアセンブリの獣です！ポイントは、VM言語が遅いことにあるのではなく、ランダムメモリアクセスがパフォーマンスを低下させていることにありました。conjoint_jints_atomicの肝はrep; smovl1です。そして、CPUが本当に好むのものがあるとすれば、それはrep命令です。これに対して、CPUはパイプラインやプリフェッチ、キャッシュなど、この命令のために構築された全ての物―ストリーミング計算と予測的メモリアクセスを利用することができます。«Modern Microprocessors. A 90 Minute Guide!»をお読みください。これの意味するところは、アプリケーションに対してrep smovlは実際には線形時間の操作ではなく、やや定数時間寄りの操作である、ということです。最後のポイントを見ていきましょう。100万個の要素のリストについて、先頭に100、1000、10000個の要素を挿入してみましょう。私のマシンでは、以下のサンプルが得られました。10倍にするごとに、計算も10倍になっていますね。これは10 * O(1)だからです。熟練の開発者はエンジニアであり、そういった人々はコンピュータサイエンスはソフトウェアエンジニアリングではないというのを御存じでしょう。理論上は良いものが、全てのファクターを考慮しないことにより実践では悪くなるということもあります。実世界で成功するためには、下部を支えるシステムとその動作に関する理解がとても重要になり、影響力を持ちます。そしてこれは私だけの意見ではなく、数年前2からRedditにこんなリンクがありました―「Bjarne Stroustrup: Why you should avoid LinkedLists」というものです。私は彼の論旨に同意しています。しかし、勿論、気を確かに持って、誰かや何かを盲目的に信じることのないようにしましょう。計測、計測、計測です。私の今までで一番のお気に入りであるJames Mickensの『The Night Watch』を添えてお別れしたいと思います。
