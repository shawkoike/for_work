How does a relational database work （2015-08-19） by Christophe Kalenzaga
クライアントマネージャは、クライアントとの通信を扱います。クライアントとは、（Web）サーバであったり、もしくはエンドユーザ、またはエンドアプリケーションであったりします。ここではJDBC、ODBC、OLE-DBといった良く知られる一連のAPIを介してデータベースにアクセスできる様々な方法が提供されています。また、データベースアクセスのための専用のAPIも提供されています。データベースと接続する手順は以下の通りです。データベースの威力は、このクエリマネージャにあります。書き方のひどいクエリはここで変換されて、素早く実行できるコードになるのです。そしてコードは実行されて、結果がクライアントマネージャに返されます。処理は以下のように複数のステップで行われます。ここでは、最後の2点については重要度が低いので、詳しくは説明しません。このパートを読んだ後、さらに理解を深めたい方には、以下の資料がお薦めです。各SQL文はパーサに送られ、構文の正しさがチェックされます。クエリに誤りがあった場合は、パーサが拒否します。例えば、”SELECT …”とするべきところで”SLECT …”と書いてあると、処理はそこで終了します。パーサはさらに、キーワードが正しい順序になっているかもチェックします。例えば、WHEREがSELECTの前にあるような文も拒否します。次に、クエリに含まれるテーブルとフィールドを解析します。パーサはデータベースのメタデータを使って以下の点をチェックします。次に、クエリ内のテーブルに対して読み込み（または書き込み）の権限があるかをチェックします。繰り返しますが、このようなテーブルへのアクセス権はDBAが設定しています。この解析中に、SQLクエリは内部表現（多くはツリー）に変換されます。全ての点で問題がなければ、内部表現はクエリリライタへ送られます。この段階で、クエリの内部表現が得られています。リライタの目的は以下の通りです。リライタは、クエリに対して既知のルールのリストを実行します。クエリがルールのパターンに一致した場合は、ルールが適用されクエリは書き換えられます。以下は網羅的なものではありませんが、（オプションの）ルールのリストです。例を見てみましょう。これは以下のように書き換えられます。こうして書き換えられたクエリは、クエリオプティマイザに送られます。さあ、面白い部分に入ってきました！データベースの最適化について触れる前に、まず統計について見ておく必要があります。統計なしではデータベースは役に立たないからです。指示を出さなければデータベースはデータ分析をしませんし、（非常に）精度の低い想定をします。データベースが必要とする情報とはどのようなものでしょうか。まず手短に、データベースとオペレーティングシステムのデータ格納方法について説明します。データ格納にはページまたはブロック（初期値で4～8キロバイト）と呼ばれる最小単位が用いられます。つまり1KBしか必要ではなかったとしても、1ページ分が使用されるということです。ページが8KB確保する場合、7KBは無駄になります。統計の話に戻りましょう。データベースに対し統計を収集するよう指示を出すと、下記のような値を算出します。上記のような統計値を参考にして、オプティマイザはクエリのディスクI/Oや、CPUとメモリの使用量を推定します。各列の統計はとても重要です。PERSONというテーブルを2列、すなわちLAST_NAMEとFIRST_NAMEに結合する必要があるとします。統計値から、データベースは「FIRST_NAMEの異なる値は1 000しかなく、LAST_NAMEには1 000 000の異なる値がある」と把握しているので、LAST_NAME,FIRST_NAMEという順番でデータを結合します。FIRST_NAME,LAST_NAMEの順ではないのは、LAST_NAMEが同じ値になる可能性が低いため、比較する値が少なくて済むからです。大抵の場合、LAST_NAMEの最初の2～3文字を比較すれば十分です。これは基本的な統計です。ヒストグラムと呼ばれるより高度な統計値を算出させることもできます。ヒストグラムは、列内の値の分布についての情報を表す統計です。下記に例を挙げます。このような追加の統計値によってデータベースはより良いクエリプランを導き出すことができます。特に等値の述語（例：WHERE AGE = 18）や、範囲を問う述語（例：WHERE AGE &gt; 10 and AGE &lt;40）はそうです。データベースがこれらの述語に関連した行の数量についてよりよく分かるからです（注： この概念を専門的に言うと「選択性」です）。統計値はデータベースのメタデータの中に格納されます。例えば、（非パーティションの）テーブルの統計は下記のような箇所にあります。以前、各テーブルで数億規模の行を扱うプロジェクトに私が関わっていた時、全データの10%だけ計算するという選択をして時間が大変節約できたことがあります。しかしこれは実際のところ悪い判断で、Oracle 10Gが選択した10%のテーブルの列は、全体と比較して全く違うものでした（列の数が100M程度であればこういうことは起こりにくいでしょう）。この誤った統計値のせいで、30秒で終わるはずのクエリは8時間かかり、原因を探すのは大変な作業でした。統計値がどれほど重要かこの例からお分かりになるでしょう。注： もちろん各データベースに特有の高度な統計があります。興味があれば、データベースのドキュメントを読んでみてください。参考までに、私なりに統計の使用法の理解に努めた範囲で、オフィシャルなドキュメントの中で最高なのはPostgreSQLのものでした。

最新のデータベースはクエリの最適化に全てコストベース・オプティマイザ（またはCBO）を利用しています。この概念は、全ての処理にコストを加味して、結果を得るため一番安価な一連の処理を使い、クエリのコストを削減するベストな方法を見つけるというものです。コスト・オプティマイザの機能を理解するためには、タスクの複雑性を「感じる」ことのできる例を挙げるのがいいでしょう。このパートでは、2つのテーブルを結合する一般的な手法を3つ提示します。シンプルなクエリによる結合でも、最適化するのは大変だということがすぐに分かると思います。それから、実際のオプティマイザの仕事ぶりを見ることにしましょう。今回の結合に関しては時間計算量に着目しますが、データベースオプティマイザはCPUコスト、ディスクI/Oコストと、必要メモリを算出します。時間計算量とCPUコストの違いは、時間のコストはかなり大雑把だということです（私のような怠け者にはぴったりです）。CPUコストの場合、加算や”if文”、乗算、反復処理や、その他いろいろな要素を考慮しなくてはなりません。例えば下記のようになります。時間計算量を用いると（少なくとも私にとっては）楽ですし、それによってCBOの概念を理解できます。私はよくディスクI/Oのことについて言及しますが、それは重要な概念だからです。大抵の場合ディスクI/Oこそがボトルネックであり、CPU使用率ではないということを覚えておいてください。B+ツリーについての項でインデックスについても説明しましたが、その場合インデックスはソート済みです。ご参考まで、他にもビットマップインデックスなどのインデックスもあります。CPU、ディスクI/Oやメモリの観点では、B+ツリーのインデックスと同等のコストではできません。更に、多くの最新のデータベースは、実行プランのコストを改善できる場合、現在のクエリのためだけに動的にテンポラリのインデックスを作成することができます。結合演算子を適用する前に、まずはデータを取得しなくてはなりません。ここではデータ取得方法について説明します。注：全てのアクセスパスにおける本当の問題はディスクI/Oなので、時間計算量についてはあまり触れません。実行プランを読んだことがあるなら、フルスキャン（または、単にスキャン）という言葉を見かけたことがあるかもしれません。フルスキャンとはデータベースが全てのテーブルやインデックスを読み込むことです。ディスクI/Oの観点から言うと、テーブルのフルスキャンはインデックスのフルスキャンよりも明らかに高価です。さらに、インデックス・レンジスキャンなどの他のタイプのスキャンもあります。”WHERE AGE &gt; 20 AND AGE &lt;40″などのような述語を用いる時の例として用いられます。もちろんインデックス・レンジスキャンを使うためには、AGEフィールドのインデックスを持っていなくてはなりません。さて、レンジクエリの時間のコストはlog(N) +Mのような値になるということに触れました。Nはこのインデックスのデータの数量で、Mはレンジ内の行の数量の予測値です。NとMの値はどちらも、統計値のおかげで分かりました（注：MはAGE &gt;20 AND AGE&lt;40という述語の選択性です）。更に、レンジスキャンでは、全部のインデックスを読み込む必要がないので、フルスキャンに比べてディスクI/Oの観点からはより安価であると言えます。インデックスから1つの値だけが必要ならばユニークスキャンが使えます。データベースがインデックスを用いている場合は大抵、インデックスに関連付けられた行を探さなくてはなりません。そのためには、行番号によるアクセスを使います。例えば、以下のようになります。年齢を列に持つインデックスがある場合、オプティマイザはそのインデックスを使って28歳の人を全て探し、それからテーブルに関連した行を問い合わせます。インデックスには年齢についての情報しかなく、lastnameとfirstnameも知る必要があるからです。次に、下記のようにしてみます。この場合はPERSONのインデックスが用いられ、TYPE_PERSONと結合されますが、PERSONというテーブルは行番号ではアクセスできないので、このテーブルでは情報を問い合わせません。少量のアクセスに関してはうまく機能しますが、この処理の本当の問題はディスクI/Oです。行番号による大量のアクセスが必要なら、データベースはフルスキャンを選択するかもしれません。全てのアクセスパスに関してここでは紹介していません。もっと知りたければOracleのドキュメントを参照してください。他のデータベースとは違う用語を使っているかもしれませんが、基本的なコンセプトは同じです。

データの入手方法が分かったところで、それらを結合しましょう。3つの主な結合演算子を紹介しましょう。マージ結合、ハッシュ結合、そしてネスト・ループ結合です。しかしその前に、新しい用語を紹介しておきます。内部リレーションと外部リレーションです。リレーションとは、以下のようなものです。2つのリレーションを結合させるとき、結合のアルゴリズムはその2つを異なる方法で扱います。ここから先は、次のような仮定で説明していきます。例えば、A JOIN Bとは、Aが外部リレーション、Bが内部リレーションのときにAとBの間を結合するということです。ほとんどの場合、A JOIN BのコストはB JOIN Aのコストとは同じになりません。
この項では、外部リレーションがN要素を持ち、内部リレーションがM要素を持っていると想定しましょう。実際のオプティマイザは、統計からNとMの値を知っていることを覚えておいてください。注：NとMはリレーションの基数を表す一番簡単なのは、ネステッド・ループ結合です。これは、以下のようなものになります。ここに、疑似コードを記載します。これは二重の反復なので、時間計算量はO(N*M)となります。ディスクI/Oについて考えてみます。外部リレーションのN行の各データについて、内部のループは内部リレーションからM行を読む必要があります。このアルゴリズムは、ディスクからN+N*M行を読み込む必要があります。しかし、内部リレーションが小さい場合、リレーションをメモリの中に入れ、読みこみをM+N 行だけに抑えるできます。この調整では、メモリの中に入りやすいよう、内部リレーションは最小である必要があります。時間計算量に関しては違いが生じませんが、ディスクI/Oに関しては両方のリレーションを一度だけ読みこんだ方がはるかにいい結果になります。もちろん、内部リレーションはインデックスと置き換えることもできます。ディスクI/Oのためにはその方がいいでしょう。このアルゴリズムはとてもシンプルなので、さらに別の方法も紹介しておきましょう。これは、内部リレーションが大きすぎてメモリに入らない場合に、よりディスクI/Oに有利な方法です。
それは、以下のようなものです。以下のようなアルゴリズムを用いることができるかもしれません。この例では時間計算量は変動しませんが、ディスクアクセスの回数は減ります。注：各ディスクアクセスは、先ほどのアルゴリズムよりも多くのデータを集めます。しかし、それらはシーケンシャルアクセスなので関係ありません（機械式ディスクの本当の問題は、最初のデータを得るまでの時間です）。ハッシュ結合はもっと複雑ですが、多くの場合ネスト・ループ結合よりもコストが低くなります。ハッシュ結合の概念とは、以下のようなものです。時間計算量に関しては、問題をより単純にしてくれる前提を仮定する必要があります。時間計算量は(M/X) * (N/X) + cost_to_create_hash_table(M) + cost_of_hash_function*Nという式で表されます。ハッシュ関数が十分に少数サイズのバケットを生成するならば、時間計算量はO(M+N)で計算できます。ハッシュ結合の別のバージョンでは、メモリの節約は利くけれども、ディスクI/Oには優しくないものがあります。今回は：マージ結合は、結果をソートされた状態で出力する唯一の結合です。注：簡素化したマージ結合では、内部表（インナーテーブル）、外部表（アウターテーブル）とも存在しません。つまり、どちらも同じ役割をするということです。しかし実際の実行では異なります。例えば、データの複製を行う時などです。マージ結合は2つのステップに分けられます。1.（オプションとして）ソート結合の実行：入力した両方の値は結合キー上でソートされます
2. マージ結合演算：ソートされた入力値は同時にマージされますソートマージソートについては、すでに触れましたが、今回のケースでは（メモリを問題としないのであれば、最善ではありませんが）優れたアルゴリズムにおけるマージソートについて扱っていきます。中にはデータセットがすでにソートされている場合もあります。以下がその例です。マージ結合
このパートはすでに見てきたマージソートでのマージにとても似ています。ですが、今回は2つのリレーションから全ての要素を取り出す代わりに、値が同じ要素だけを取り出します。考え方は以下のとおりです。この手順は2つのリレーションがソートされているので、うまくいきます。そのため、それぞれのリレーションを”戻る”必要はありません。このアルゴリズムは簡易化されたバージョンです。とういうのも、同じデータが両方の配列で（言い換えれば複数が適合している場合に）何度も現れるケースを扱うことができないからです。実際のバージョンは、このような場合だけ、より複雑になります。簡易化されたバージョンを選択したのは、このためです。2つのリレーションがすでにソートされている場合、時間計算量はO(N+M)になります。一方で2つのリレーションにソートが必要な場合は、時間計算量はソートする時間がかかるので、O(N*Log(N) + M*Log(M))で表されます。CSオタクのための、複数適合する場合を扱う実行可能なアルゴリズムが以下になります（注：このアルゴリズムに100%自信があるわけではありません）。結合に最適な型があれば、それは複数型ではないでしょう。これはとても難しい問題です。なぜなら以下のようにたくさんの要因が働いているからです。さらに知りたい場合は、DB2、ORACLEまたはSQL サーバのドキュメントを読んでください。

結合演算の種類を3つ見てきました。では、1人の情報を全て表示するのに5つのテーブルを結合するとしましょう。例えば以下のような情報を表示します。言い換えれば、以下のクエリに関して瞬時に応える必要があるということです。クエリのオプティマイザとして、このデータを処理するベストな方法を見つけなければいけません。しかし、以下の2つの問題が生じます。結合の選択肢は3種類（ハッシュ結合、マージ結合、ネスト結合）あり、それぞれインデックスを0個、1個、2個使います（言うまでもなく、インデックス自体にいくつも種類があります）。以下の図は、4つのテーブルで3つの結合を使った数種類のプラン例です。ということで、以下のことが考えられます。非ギークの方向けに計算してみると、27,216個だけのプランがありうるということになります。もし、B+ツリーのインデックスを0～2個利用するマージ結合の可能性を追加した場合、プランの選択肢は210,000になります。クエリはとっても簡単だって、私言いましたよね？この単純な例では、多くの選択肢が残ってしまいます。しかし、実際のクエリは、他のリレーショナル演算子を持っています。例えば、OUTER JOIN、CROSS JOIN、 GROUP BY、 ORDER BY、 PROJECTION、UNION、INTERSECT、DISTINCTなどです。つまり、さらに多くの選択肢があるということです。では、データベースはどう対処しているのでしょうか？

リレーショナルデータベースは、私が今説明したような複数の方法を試みます。オプティマイザの本来の役割は、時間に制約のある中で解を見つけることです。オプティマイザは大抵の場合、最適解は見つけられませんが、”良い”解なら見つけられます。クエリが少なければ、総あたり方式が使えます。しかし、無駄な計算を避けるようにする方法もあります。ですから、中くらいのクエリの場合でも総あたり方式が使えます。これをダイナミックプログラミングと呼びます。この方法の裏に隠されているアイデアは、多くの実行されるプランがよく似ているということにあります。以下のプランをご覧ください。これらは同じ(A JOIN B)のサブツリーです。つまり、各プランで毎回このサブツリーのコストを計算するのではなく、一度だけ計算をし、計算されたコストを保存し、別のプランで同じサブツリーが出てきた時に再利用します。堅苦しく言うと、重複問題に直面していると言えます。部分的に余計な計算を避けるため、メモ化をするのです。この方法を使えば、(2*N)!/(N+1)!の計算量だったのが、”たった”の3Nまで減らすことができます。先ほどの4つの結合の例で言うと、順序が336から81にまで減らせます。例えば、結合数が8のクエリだとすると（それほど大きい数ではありませんが）、57,657が6,561になります。これが既にご紹介した、私がクラスの授業で発見したコンピュータサイエンスのプロ向けのアルゴリズムです。このアルゴリズムに関しては、ここでは説明を省きます。もし、ダイナミックプログラミングの知識が既にある人か、アルゴリズムが得意な人であれば読んでみてください（私は忠告しましたよ！　）。もっと多数のクエリの場合でもダイナミックプログラミングは使えますが、選択肢を減らすためにルール（またはヒューリスティック）を追加しましょう。しかし、大量のクエリや素早く答えを出したい場合は（すごく速いクエリではなく）、別のアルゴリズムを使います。それが、貪欲アルゴリズムです。この方法は、ルール（またはヒューリスティック）に従い、増分法でクエリのプランを作成します。このルールで貪欲アルゴリズムを使えば、１回毎に問題に対する最適解を見つけます。この方法では、1つのJOINだけでクエリプランを始めます。それから、それぞれの段階で、同じルールを使って、クエリプランに新しいJOINを追加します。簡単な例で説明しましょう。5つのテーブル（A、B、C、D、E）で4つの結合があるクエリだとします。問題を簡易化するのに、使える結合の中からネスト結合を使うことにしましょう。例えば、”最低のコストの結合を使う”というルールを使いましょう。初めに無作為にAを選んだら、次は同じアルゴリズムをBに適応し、次にC、次にD、最後にEと適応していくことができます。こうすれば、最低コストのプランを保つことができます。ところで、このアルゴリズムには名前があります。最近傍法です。詳細は省きますが、良いモデリングやN*log(N)のソートでは、この問題は簡単に解決することができます。このアルゴリズムのコストはO(N*log(N))で、ダイナミックプログラミングではO(3N)です。例えば20の結合がある膨大なクエリの場合は、26と3,486,784の差が出ます。これは大きな差ですよね！このアルゴリズムでの問題点は、2つのテーブル間でベストな結合を見つけ出せば、その後その結合に新しい結合を追加した場合でもベストなコストを導き出せると思い込んでしまうことです。しかし、それは違います。結果を改善していくには、別のルールを使った複数の貪欲アルゴリズムを実行し、ベストなプランを保ってください。[もうすでにアルゴリズムに飽き飽きしてしまっていたら、このパートは飛ばしてください。ここで話す内容は、この後の記事の内容にはあまり関わってきません。]ベストなプランを見つけるという課題は、多くのコンピュータサイエンスの研究者がよく対面するトピックです。より重要な問題やパターンのために、より良い解はないかと彼らはしばしば模索しています。例えば、以下のような例が挙げられます。なお、ダイナミックプログラミングに取って代わる、膨大なクエリを処理できる他のアルゴリズムが研究されています。貪欲アルゴリズムはヒューリスティックアルゴリズムと呼ばれる、より大きなカテゴリーに所属します。貪欲アルゴリズムはルール（またはヒュールスティック）に従って、前段階で見つけた最適解を維持し、現段階での最適解を見つけるために前回のものを”アペンド”します。一部のアルゴリズムではルールに従い、段階ごとにそれを適用しますが、前段階で見つけた最適解をいつも維持するとは限りません。これをヒューリスティックアルゴリズムと呼びます。例えば、遺伝的アルゴリズムはルールに従いますが、最終ステップでの最適解は維持されるとは限りません。:回数を繰り返せば繰り返すほど、より良い結果が得られます。これは魔法でしょうか？　いえ、これは自然の法則です。適者のみが生存できるのです！参考までに言うと、遺伝的アルゴリズムはPostgreSQLで実装されています。しかし、これがデフォルトで使用されているのかどうかは私には分かりませんでした。他にも下記のようなデータベースで使われているヒューリスティックアルゴリズムがあります。焼きなまし法、反復改良法、2段階最適化などです。しかし、これらが企業向けのデータベースで使われているのか、もしくは研究向けのデータベースでのみ使われているのかは私には分かりません。

[この項目はスキップしても構いません。それほど重要な内容ではありません]
しかしここで述べている諸々のことは非常に理論的です。私は研究者ではなく開発者なので、具体的な例が好きなのです。SQLiteオプティマイザがどのように機能するのか見てみましょう。SQLiteは軽量なデータベースなので、選択肢を制限するために例外ルールを用いながら、貪欲アルゴリズムに基づいて単純な最適化を使います。つまり、ちょっと待ってください、このアルゴリズムを前に見たことがありますね。実に奇遇ですね。他のオプティマイザがどのように機能するのか見てみましょう。IBMのDB2は他の全ての企業向けデータベースと同様ですが、私がビッグデータに移行する前に実際に使用していたデータベースなので、これに焦点を絞ってみることにします。公式ドキュメンテーションによると、DB2オプティマイザでは7つの異なるレベルのオプティマイザが使えます。DB2が貪欲アルゴリズムとダイナミックプログラミングを使用していることが分かります。もちろん、クエリオプティマイザがデータベースのメインパワーなので、貪欲アルゴリズムとダイナミックプログラミングは使用するヒューリスティックを共有しません。参考までに言うと、最適化レベルの初期値は5です。この初期値が設定されることにより、オプティマイザは次のような特徴を持ちます。この初期値が設定されていると、DB2は結合順序のヒューリスティクによって制限されたダイナミックプログラミングを使用します。他の状態（GROUP BY、DISTINCT等）は単純なルールによって扱うことができます。

プランの作成には時間がかかるので、ほとんどのデータベースは、同一クエリプランの無用な再計算を避けるために、クエリプランキャッシュにプランを保存しています。これは素晴らしいことです。というのも、データベースは無効となったプランの更新タイミングを知る必要があるからです。これには、閾値を設定するという考え方あります。これは、テーブルの統計がこの閾値以上になった場合は、テーブルに関連するクエリプランがキャッシュから削除されるという方法です。

この段階では既に、実行プランの最適化を終えています。プランは実行可能なコードにコンパイルされます。そして、十分なリソース（メモリやCPU）があれば、クエリエグゼキュータによって実行されます。プランの演算子（JOINやSORT BYなど）は順番に、もしくは同時に実行されます。どのように実行するかはエグゼキュータによります。データの取得もしくは書き出しを行うために、クエリエグゼキュータはデータマネージャに働きかけます。これは次のパートで説明します。
