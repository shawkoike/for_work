Pipes and Filters by Peter Sobotパイプラインは、最近のソフトウェアエンジニアリングにおいて、非常に便利な（そして驚くほど活用されていない）アーキテクチャパターンです。ソフトウェアでデータの流れを制御するためにパイプとフィルタを用いる考え方は、最初のUNIXシェルが作られた1970年代からあります。もしターミナルエミュレータでパイプ”|”を使ったことがあるなら、”パイプとフィルタ”を活用できていることになります。以下の例を見てみましょう。このパイプラインをbashで実行すると、LinuxのマスコットであるペンギンのTuxのASCIIアートが返され、辞書の中から”purple”を含む一番長い単語を言います。実は、この数行のコードが実行されると、かなり多くのことが行われます。Enterキーを押した瞬間、以下のステップが走るのです。このタスクにパイプラインを使用するのは、非常に簡単なように思えます。ここで行われている全てのタスクはデータをフィルタリングしています。元のデータセットが各ステップで変更されています。各プロセスはそれぞれのはたらきをしており、UNIX哲学の教えを的確になぞらえています。どのプロセスも簡単に他のものと入れ替えることができるでしょう。bashが自動的に行うパイプラインの機能を可視化すると、以下のようになります。パイプラインのもう1つの利点は、本質的にパフォーマンスが優れている点です。先ほど実行したコマンドの修正バージョンを使い、パイプライン中の各フィルタコンポーネントのメモリとCPUの使用量を見てみましょう。（余談ですが、私は自分のシェルに内蔵されているtimeコマンドの使用を避けるため、ここでは/usr/bin/timeを呼び出しています。内蔵のtimeコマンドは詳しい統計を表示する-lオプションをサポートしていないのです。もしあなたがLinuxを使用しているのであれば、-vオプションを使うといいでしょう。同じように統計を表示します。stdinがパイプを指した状態のまま、2&gt; (cat, grep他).time.txtの文で、stderrをファイルにリダイレクトします）このコマンドを実行し、最大常駐セットサイズと自発的及び非自発的コンテキストスイッチの回数を確認すると、重要なことがいくつか見えてきます。

この例に挙げているパイプラインは大変シンプルですが、これらのプロセスのどれか1つでも複雑な計算をしていたら、複数のプロセッサ上で自動的に並列処理することもできます。パイプラインってすごいでしょう？　確かにパイプラインは素晴らしいです。メモリやCPU時間を効率的に使用し、データのアベイラビリティに基づいて黙って自動的に実行のスケジューリングもします。また作成するのも非常に簡単です。なのに、できることならいつでも使いたいと思わないのはなぜでしょう？　答えは、エラーハンドリングのせいです。パイプラインのどこか一部で間違いが起きたら、パイプライン全体が完全に機能しなくなります。私がPythonで書いたコマンドを追加して、このパイプラインを試してみましょう。fail.pyは標準入力を標準出力にそのまま表示させますが、50パーセントの確率で行を読む前にクラッシュします。fail.pyのソース：この場合、何が起こるでしょうか？　fail.pyが入力を読んでいる途中で失敗すると、stdinとstdoutのパイプは閉じます。これによってパイプラインが半分に切断されます。失敗したプロセスからさらに先へ行くと各プロセスがどうなるのかを見ていきましょう。その結果は？Tuxは先ほどのように”unimpurpled”と言っていません。間違っていますね。コマンドパイプラインの出力が正しくないのです。フィルタの1つがクラッシュしても反応が戻ってきて、その後のパイプラインの全てのステップが、尚も予想通りに実行されました。さらに悪いことに、パイプラインのリターンコードを確認すると以下のようになります。bashは親切にもパイプラインは正常に実行されたと報告しています。bashはパイプラインの最後のプロセスの終了ステータスのみ報告するためです。パイプラインの中でより早く問題を見つけ出す唯一の方法は、比較的知られていないbashの$PIPESTATUS変数を確認することです。この配列が、前の連結したパイプにおけるあらゆるプロセスのリターンコードを保存し、先ほどクラッシュしたフィルタはここでしか確認することができません。これは従来のUNIXのパイプを使う上で大きな欠点の1つです。パイプラインがまだデータを処理している間にエラーを検知するには、何らかの形で失敗した処理を見つけ、他のプロセスにメッセージを送る帯域外のシグナルが必要となります（1つのフィルタに対し複数の入力パイプがあればこれは簡単ですが、UNIXのパイプだけを使用していたら難しくなります）。良い感じです。ASCIIアートでペンギンを描くためのメモリ効率の良いパイプラインを作れます。でもこんな質問が聞こえてきそうです。いい質問です。データを非常に小さな塊に分けられる場合や処理を徐々に終わらせられる場合は、パイプを使うと非常に便利です。例をいくつか挙げてみましょう。例えば、とても高品質な音声フォーマットである.flacのファイルでいっぱいのフォルダがあるとしましょう。これらのファイルを自分のMP3プレイヤーに入れたいのですが、そのMP3プレイヤーは.flacをサポートしていません。そして、どういうわけかコンピュータは10MBのRAMしか使えないのです。ここでパイプラインを使ってみましょう。このコマンドは今まで見てきたものよりも少し複雑ですね。まず、whileループの条件式にreadコマンドがある、ビルトインのbashコンストラクトを使っています。この条件式では、入力された各行を読み込み（lsの結果をパイプで送っています）、1行ごとに内部のコードを1回実行します。そして、内部のループでsongをデコードするためのflacを呼び出し、songをMP3にエンコードするためのlameを呼び出します。このパイプラインはどのくらいメモリ効率が良いのでしょうか？　このコードを115MBのflacファイルでいっぱいのフォルダに対して実行してみると、使用したメモリはたったの1.3MBでした。では、あるWebアプリケーションを利用するために、自分のお気に入りのWebフレームワークを使っているとしましょう。ユーザがそのWebアプリケーションにフォームをサブミットする場合、バックエンドでは非常にコストの高いプロセスを実行しなければなりません。フォームデータに対してはサニタイジングを行い、外部のAPIを使って検証し、PDFファイルとして保存する必要があります。これら全てのプロセスは重すぎるので、Webサーバでは実行できません（その通り、この例は少し不自然ですが、今まで私が見てきたユースケースから大きく外れてはいません）。ではここで、パイプラインを使ってみましょう。ユーザがmy_webserverにフォームをサブミットするとすぐ、stdoutにJSONの文字列を送ります。こんな感じの文字列です。パイプラインにおける次のプロセスのline_sanitizerでは、各行に対して以下のコードを実行します。その次のプロセスではフォームから入力された組織が存在するかどうかを検証します。そして最後のプロセスでは、残った文字列をPDFファイルに書き込みます。これでお分かりかと思いますが、たった数行のコードで大量のデータを処理することが可能な、非常にメモリ効率の良い非同期のパイプラインができました。でも、この例では疑問が1つ残ります。もしエラーが発生したら、どう処理するのか？　という疑問です。Eric IdleがこのWebサイトにフォームをサブミットしたとして、サイトがそのフォームを受け付けなかったら、どのようにエラーが通知されるのでしょうか？　とてもUNIXっぽいやり方ですが、以下のように名前付きパイプを作ってエラー処理を行うという方法があります。どんなプロセスでもカスタマイズされたerrorという名前のパイプから読み込みが可能で、パイプラインの各プロセスはエラーになる入力値をパイプに出力します。エラーについての電子メールを送信するリーダを、そのパイプにつけることも可能です。そして、line_sanitizerが文字列に対してエラーを返す場合は、このように動きます。このパイプラインは、通常とは少し違いますね（赤線がstderrの出力を表します）。

UNIXのパイプは便利ですが、もちろん欠点もあります。全てのソフトウェアがUNIXのパイプの枠組みを直接使えるわけではなく、最新式のWebトラフィックで見られるスループットにUNIXのパイプがうまく合うわけではないのです。しかし、違う方法が使えます。マシン間で基本的なFIFOキューを使うことを可能にした、最新式の”ワークキュー”ソフトウェアパッケージが、ここ数年で次々と作られてきました。beanstalkdやceleryといったパッケージは、プロセス間で任意のワークキューを作成できます。これらのパッケージは従来のUNIXのパイプを簡単にシミュレート可能で、多くのマシンに分散されているという大きな利点もあるのです。一方で、非同期のタスク処理に極めて適しており、メッセージを送信しようとしているプロセスがキューによってブロックされることはありませんが、UNIXのパイプではできた暗黙の実行制御ができません。サービスは、コルーチンというよりも、メッセージングシステムやワークキューとして動いています。そこで、同期性の欠如や分散型パイプラインシステムに対処するため、Redisベースで信頼性のある分散型同期パイプラインのライブラリを自分で作り、pressureと名付けてみました。pressureを使うと異なるプロセス間でパイプをセットアップすることが可能ですが、パイプのバッファを保つ機能と複数のマシン間で使える機能が加えられています。安定したメッセージブローカとしてRedisを使うことによって、このライブラリは全ての内部プロセスのコミュニケーションを処理し、OSやプラットフォームに依存しないものになりました（Redisには他にも、信頼性やレプリケーションといった数多くの役立つ機能があります）。pressureのリファレンス実装はPythonにあり、まだ初期段階です。性能を見るため、この投稿の初めから使ってきたパイプラインの例を、pressureのUNIXのパイプアダプタを使うことでレプリケートしてみましょう（putやgetは、従来のUNIXのパイプとRedisで保たれる分散型pressureキューの間のブリッジとして動く、Cプログラムのコードです）。最初の注意点は、このメソッドにおいては何メガバイトものファイルをフィルタリングしているので、極めて重い処理になるということです。最終的には235,912メッセージをRedisで送ることになり、処理に4分ほどかかります（catのすぐ後、かつRedisにデータを送る前にgrepを実行する場合は、この1,200倍よりも速い処理速度となります）。どうであれ、最終的には、求めている正しい答えが得られます。しかし、Redisのコマンドラインツールであるredis-cliを実行してみると、妙なプロパティが見られる場合があります。大量のデータ入力をしているにもかかわらず、パイプラインでは非常に少ないメモリしか使われていないことになっているのです。pressureはまだアルファ版であり、広範囲に渡る製品デプロイメントには間違いなく時期尚早です。とは言っても、ぜひ使ってみてください。ソフトウェアにおいてパイプラインは、リソースの使用量を低減させる手段になり得る、非常に便利なツールです。パイプラインは必要時に演算をするためだけにコルーチンとして動き、リアルタイムのオーディオ処理のような特定のアプリケーションにとっては極めて重要なツールになります。pressureは複数のマシンで信頼性を持ってパイプラインを簡単に使う方法を提供します。ソフトウェアアーキテクチャの問題を解決するためにパイプとフィルタの枠組みを使い、これがどんなに簡単で効果的なものかを体験してみてください。
