Lessons from Building a Node App in Docker by John Lees-Miller以下に紹介するのは、Dockerを使ってnode.js用のWebアプリケーションを開発、およびデプロイする際に、私が四苦八苦しながら学んだ秘訣やコツです。このチュートリアル記事では、Dockerでsocket.ioのチャットサンプルを白紙の状態から本番状態へとセットアップしていきます。このプロセスを通じて、そうした秘訣などを簡単に習得していただければ幸いです。特に、以下のような内容について見ていきます。このチュートリアルは、読者の皆さんがDockerやnode.jsにある程度、慣れ親しんでいることを前提としています。「Dockerとは何ぞや」という方は、私が以前に作成したDockerについてのスライド（Hacker Newsでの議論はこちら）を見ていただいてもいいですし、その他にも、探せば多くの解説記事が見つかるはずです。今回は、ゼロからの作業です。最終的なコードはgithub上で閲覧可能で、ステップごとにタグが付けられています。最初のステップのコードがこちらにありますので、参考にされたい方はご覧ください。Dockerがなければ、まずはNodeやその他のdependenciesをホストにインストールし、npm initを実行して新規パッケージを作成することから始めるでしょう。この作業は避けては通れませんが、最初からDockerを使えば話は変わります（これらのものをホストにインストールしなくていいというのは、Dockerを使う大きなポイントです）。その場合、始めにNodeがインストールされた「起動コンテナ」を作成し、それを使ってアプリ用のnpmパッケージをセットアップします。ここで用意する必要があるのはDockerfileとdocker-compose.ymlの2ファイルで、これらには後からもっと手を加えます。まず、起動用のDockerfileから見てみましょう。このファイルは比較的、短いですが、いくつか重要なポイントがあります。では次に、起動構成ファイル、docker-compose.ymlに移ります。これはDockerfileから構築される単一のサービスを定義したもので、現時点の動作はreadyをechoしexitするのみです。volumeの行の.:/home/app/chatは、ホスト上のアプリケーションフォルダ.をコンテナ内の/home/app/chatフォルダにマウントするようDockerに指示しているため、ホストのソースファイルに加えられた変更はコンテナ内部に自動で反映されますし、逆もまたしかりです。このことは開発時のテスト-編集-リロードサイクルを短くするのに非常に重要となりますが、npmがdependenciesをインストールする際にある問題を生みます。それについては後ほど触れます。ここまでは非常に順調です。docker-compose upを実行すると、Dockerは指定されたとおりにDockerfile内でnodeをセットアップしてイメージを作成し、そのイメージを有するコンテナを立ち上げてechoコマンドを実行します。すべてが問題なく設定されていることが分かりますね。これで、同じイメージから作成されたコンテナ内で対話型シェルを実行し、それを使用して最初のパッケージファイルをセットアップすることができるようになります。ファイルはホスト上にあるため、バージョン管理を行えます。ここまでの結果のコードをgithubで確認してみてください。次のステップは、アプリのdependenciesのインストールです。docker-compose upを最初に実行した時にアプリの使用準備が整うよう、dependenciesはDockerfileを経由してコンテナ内にインストールされるようにします。これを行うにはDockerfileでnpm installを実行する必要がありますが、その前に、それがイメージに読み込むpackage.jsonとnpm-shrinkwrap.jsonファイルを取得しなければなりません。変更は以下のようになります。変更点はわずかですが、ここでも重要なポイントがいくつかあります。最後のポイントは、コンテナの$HOME/chatをホストのアプリケーションフォルダにバインドしているため、開発中のイメージを使う時にはいくつかの問題を引き起こします。残念ながらnode_modulesフォルダがホスト上に存在しないため、このバインドがインストールしたnode_modulesを見事に「非表示」にしてしまうのです。この問題にはいくつかの解決策がありますが、一番スマートだと思うのはnode_modulesを含むようバインド内でボリュームを使う方法です。これをするには、docker-composeファイルの最後尾に1行を付け加えればいいだけです。作業としては単純ですが、裏では複雑なことが行われています。1. ビルド中、npm installがイメージ内の$HOME/chat/node_modulesにdependencies（次のセクションで追加します）をインストールします。イメージ由来のファイルには青で色付けしています。

2. 後でcomposeファイルを使ってイメージからコンテナを立ち上げる際、Dockerはまず$HOME/chat以下にあるコンテナ内のホストからアプリケーションフォルダをバインドします。ホスト由来のファイルには赤で色付けしています。

厄介なのは、イメージのnode_modulesはバインドによって非表示となっているため、コンテナ内においてホスト上で見えるのは空のnode_modulesフォルダのみだということです。3. ただし、まだ終わりではありません。Dockerは次に$HOME/chat/node_modulesのコピーを含むボリュームをイメージ内に作成し、コンテナにマウントします。これによりホスト上では、バインドからnode_modulesが隠された状態になり影響を受けなくなります。

これで希望どおりになりました。ホスト上のソースファイルはコンテナ内部にバインドされているため、高速な変更が可能です。また、コンテナ内部でdependenciesが利用できるため、それらを使ってアプリケーションを実行することもできます。（補足事項：これらの依存ファイルが、実際にボリューム内のどこに保存されるのか不思議に思われるかもしれません。端的に言えば、Dockerが管理するホスト上の別のディレクトリに保存されています。詳しくはボリュームに関するDockerの文書をご覧ください。）それではイメージを再構築して、パッケージをインストールしましょう。チャットアプリにはexpress@4.10.2が必要なので、それをnpm installし、--saveでpackage.jsonに依存関係を保存します。必要に応じてnpm-shrinkwrap.jsonをアップデートしてください。なお、ここでは具体的なバージョンを指定する必要はなく、npm install --save expressを実行して最新のバージョンを取得するだけで構いません。package.jsonとshrinkwrapは、次にビルドが実行された時に、そのバージョンで依存関係を保持します。npmのshrinkwrap機能を使う理由は、package.jsonでは直接の依存関係があるバージョンの修正はできるものの、あやふやに指定された可能性のある依存関係のバージョンについては修正ができないからです。もし、あなたや他の誰かが将来的にイメージを再構築する場合、（shrinkwrapを使わない限り）それが間接的な依存関係の異なるバージョンをプルダウンし、アプリケーションを破壊しないという保証はありません。経験上、これは皆さんが想像するよりもはるかに頻繁に起こることのように思えるため、私はshrinkwrapの使用を推奨しています。Rubyには優れた依存管理マネージャのBundlerがありますが、比較すると、npm-shrinkwrap.jsonはGemfile.lockのようなものかと思います。最後に注目したいのは、ここでは1回限りのdocker-compose runとしてコンテナを実行しているため、インストールした実際のモジュールは消滅します。しかし次にdocker buildを行うと、Dockerはpackage.jsonとshrinkwrapに変更があること、そしてnpm installの再実行が必要であることを検出します。これはとても重要なことで、必要なパッケージはその後、イメージにインストールされます。ここまでの結果のコードはgithubをご覧ください。やっとアプリケーションをインストールする準備ができました。まずは残りのソースファイル、つまりindex.jsとindex.htmlをコピーします。それから、前のセクションでやったようにnpm install --saveを使ってsocket.ioのパッケージをインストールしてください。これでDockerfileでは、node index.jsのイメージを使ってコンテナを起動した時に、どのコマンドを実行するのかをDockerに伝えることができるようになりました。なお、DockerfileからのコマンドをDockerが実行するように、ここでdocker-composeファイルからダミーのコマンドを削除しておいてください。最後に、ホスト上のコンテナの3000番ポートを開放するようdocker-composeに指示すれば、ブラウザでアクセスできるようになります。最後のビルドをすれば、docker-compose upによる実行の準備が完了です。これで（Macの場合は、boot2docker–vmからホストに3000番ポートを転送させるために少しばかりいじる必要があります）、http://localhost:3000で実行しているのが確認できるはずです。ここまでの結果のコードはgithubをご覧ください。やっとアプリをdocker-composeの開発環境下で実行させることができました。素晴らしいですね。では、次なるステップは何かを見ていきましょう。本番環境にアプリケーションイメージをデプロイしたい場合、アプリケーションソースを前述のイメージにビルドすることになります。これを行うには、npm installの後、コンテナにアプリケーションフォルダをコピーすればいいだけです。これでDockerは、ソースファイルに変更があった時ではなく、package.jsonまたはnpm-shrinkwrap.jsonに変更があった場合のみnpm installを再実行します。なお、rootとしてファイルをコピーするCOPYの問題については、ここでも回避が必要です。これで、ホストからのボリュームなしに、スタンドアロンでコンテナを実行できるようになります。docker-composeは、composeファイル内でコードの重複を避けるため、複数のcomposeファイルを構成できますが、今回のアプリケーションは非常にシンプルなので、単純に2つめのcomposeファイル、docker-compose.prod.ymlを追加して、本番環境でアプリケーションを実行させます。以下により、「本番モード」でアプリケーションが実行できます。同様に、例えばソースファイルに変更があった時にコンテナ内を自動リロードするnodemonの下でアプリケーションを実行させれば、コンテナを開発用に特化できます（ただしDocker Machineを使ったMacでは、virtualboxのsharedフォルダがinotifyでは動かないため､完全に動作するとは言えません。この状況が早く改善されるといいのですが）。また、コンテナでnpm install --save-dev nodemonを実行し再構築すれば、開発用途としてより適切な設定のコンテナ内でデフォルトのproductionコマンド、node index.jsをオーバーライドすることが可能です。なお、nodemonに関しては、パス上ではなくnpmの依存関係としてインストールされるので、フルパスを与える必要があります。npmスクリプトをセットアップしてnodemonを実行することもできますが、私自身はそのアプローチで問題に遭遇しました。npmスクリプトを実行しているコンテナでは、npmがTERMシグナルをDockerから実際のプロセスに転送しないため、シャットダウンに10秒間ほどかかる傾向があります（デフォルトのタイムアウト）。したがって直接コマンドを実行させた方が、より良い結果が得られるようです。（追記：この問題はnpm 3.8.1以上で修正されたようです。これで、npmスクリプトをコンテナで使えるようになりますね！）docker-composeファイルを特化すれば、同一のDockerfileやイメージを複数の環境にわたって使用できるようになります。本番環境にdevDependenciesをインストールするため、スペース的には最も効率的とは言えませんが、開発環境と本番環境のより良い等価性にとっては、わずかな犠牲ではないかと思います。ある賢人がかつて言ったように、「test as you fly, fly as you test（飛ぶようにテストし、テストするように飛ぶ）」ということです。そういえば今回はテストをしていませんが、実行するのは簡単です。（補足事項：--silentを指定してnpmと実行すると、余分な出力が取り除かれます。）github上の最終的なコードはこちらです。ここまで読んでくださった方は、ぜひ私のtwitterもフォローしていただければ幸いです。また、Overleafでは求人も募集していますよ:)原稿のチェックをしてくれたMichael MazourとJohn Hammersleyに感謝します。
