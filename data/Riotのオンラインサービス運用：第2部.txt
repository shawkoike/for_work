<p><a href="https://engineering.riotgames.com/news/running-online-services-riot-part-ii" rel="nofollow" title="" class="ext-link">Running Online Services at Riot: Part II</a> (No date) by <a href="https://github.com/KAllan357" rel="nofollow" title="" class="ext-link">Kyle Allan</a></p><p><img src="https://engineering.riotgames.com/sites/default/files/articles/51/rcluster1header.jpg" alt="" class="c-header__image"></p><p>Riotのインフラチームに所属しているKyle AllanとCarl Quinnです。本稿は連載しているブログの第2部です。この連載では、私たち、Riotが世界中でどのようにバックエンド機能をデプロイし運用しているのかを詳しく説明しています。なお、本稿では、デプロイメントのエコシステムの初めの主要コンポーネントとなる、コンテナのスケジューリングについて論じていきます。</p><p>Jonathanの執筆した<a href="http://postd.cc/running-online-services-riot-part-i/">連載第1部</a>では、Riotがデプロイメントに取り組んできた歴史と、私たちが直面した困難について説明しました。具体的に言うと、ソフトウェアをデプロイする際に私たちが経験したさまざまな問題がどのように大きくなっていったかについて述べました。主な原因は、League of Legendsをサポートするためにインフラをどんどん追加したため、 “アプリケーションごとに手作業のサーバプロビジョニング” が必要になったことでした。Dockerと呼ばれるツールが、私たちのサーバデプロイメントのやり方を変えました（<a href="engineering.riotgames.com/news/thinking-inside-container-dockercon-talk-and-story-so-far">他のもの</a>もありますが、中でもDockerが一番影響を与えました）。その結果、Admiralが誕生しました。これは私たちが開発したソフトウェアで、クラスタのスケジューリングと管理を行う内部ツールです（ちょうど昨日知ったことなのですが、VMwareに同じ名前の似たようなソフトウェアがありました。賢人は皆同じように考えるものなのですね）。</p><p>ここで注意しておきたいのは、アプリケーションのデブロイメントの開発には、まだまだ終わりがないということです。常に進化し続けることなので、私たちも次の段階の準備をしなければなりません（後述しますが、DC/OSの導入などの可能性もあります）。本稿では、どのような経緯で現時点に至ったか、また、なぜ私たちが現在のような選択をしているかをお話しします。この話から、みなさんにも何か学ぶことがあれば幸いです。</p><p>Dockerがリリースされ、Linuxのコンテナ化の技術がより広く知られるようになると、私たちは、インフラのコンテナ実装を行うことで、利益が得られると考えました。Dockerコンテナのイメージは、一度で作成でき、開発、テスト、そして本番環境にデプロイされる、不変的でデプロイ可能な成果物を提供します。さらに、本番環境に実行されるイメージの依存性は、テスト中の状態がそのまま保証されます。</p><p>本稿の趣旨においては、もう1つのメリットがとりわけ重要です。Dockerは、スケジューラを利用してコンテナをホストに（うまくいけば賢い方法で）割り当てることで、デプロイメントのユニット（コンテナ）と、コンピュートのユニット（ホスト）の分離を可能にします。これで、サーバとアプリケーションの結合が解消されます。つまり、既定のコンテナは、何台のサーバ上でも実行可能なのです。</p><p>Dockerのイメージにパッケージされ、いつでも、何台のサーバ上でもデプロイ可能な私たちのバックエンドのサービスは、変化にすぐに対応していく必要があります。例えば、新しいプレイヤ機能を追加したり、トラフィックを重くする機能をスケールアウトさせたり、更新や修正を素早く公開することです。コンテナ内のサービスを本番環境へデプロイすることを考える際に、解決しなければならない以下の3つの大きな課題があります。この記事ではそれらを取り上げていきます。</p><p>これら3つの問いに対する答えは、<em>スケジューラ</em>、つまりクラスタ層で動作し、コンテナストラテジを実行するようなサービスが必要だということです。スケジューラはクラスタを維持する際のキーコンポーネントで、コンテナが正しい場所で動作することを保証し、コンテナが停止した時には再起動します。例えば、ロードを管理するために6つのコンテナインスタンスを必要とするHextech Craftingのようなサービスを起動したいと思うかもしれません。スケジューラはこれらのコンテナをサポートするために十分なメモリとCPUリソースを有するホストを見つけ、コンテナを実行し続けるのに必要な動作を全て実行する役割を担います。これらのサーバのうちの1台が停止すると、スケジューラは影響を受けたコンテナのために代わりのホストを見つける担当でもあります。</p><p>スケジューラを利用しようと決めた時には、素早くプロトタイプする能力を必要としていました。これはコンテナ化されたサービスが本番でうまく動くかどうかを知るためです。さらに、私たちの環境で既存のオープンソースのオプションが動作することや、メンテナーが改造を受け入れてくれることを確保する必要がありました。</p><p>Admiralとして誕生したスケジューラを作成する前に、私たちは既存のクラスタマネージャとスケジューラの状況を調べました。Dockerホストのクラスタにまたがるコンテナのスケジューリングをしていたのは誰なのでしょうか。またどのようにそれを実行していたのでしょう。その技術が私たちの問題も解決してくれるのでしょうか。</p><p>最初の調査で、いくつかのプロジェクトに注目しました。</p><p><a href="http://mesos.apache.org/" rel="nofollow" title="" class="ext-link">Mesos</a> + <a href="https://mesosphere.github.io/marathon/" rel="nofollow" title="" class="ext-link">Marathon</a></p><p><a href="https://github.com/google/lmctfy" rel="nofollow" title="" class="ext-link">LMCTFY</a> =&gt; <a href="http://kubernetes.io/" rel="nofollow" title="" class="ext-link">Kubernetes</a></p><p><a href="https://github.com/coreos/fleet" rel="nofollow" title="" class="ext-link">Fleet</a></p><p>私たちはRESTを介してDocker APIと通信するような小規模のコマンドラインツールのプロトタイプを作成しました。そして、デプロイメントをうまく組み合わせるために、このツールがどのように使えるのかを実証することに成功しました。その後、独自のスケジューラを作る方針を決めたのです。調査したシステムの優れた部分のいくつかを取り入れました。この中にはKubernetesのpodとMarathonの制約システムの背景にある核となる概念も含みます。私たちのビジョンは、これらシステムの構造と機能性を手掛かりとし、可能であれば影響を与え、将来、この中の1つと最終的には収束しようと思っています。</p><p>私たちは、基本デプロイのためのJSONベースのメタデータ言語CUDLを作成したあとで、Admiralを書き始めました。CUDLとは「ClUster Description Language」（クラスタ記述言語）の意味です。これはAdmiralがRESTful APIで使用する言語になりました。CUDLの主なコンポーネントは以下の2つです。</p><p>クラスタとパックは、specとliveという2つの異なるアスペクトを持ちます。それぞれのアスペクトは、コンテナライフサイクルの異なる段階について表現しています。</p><p>specは、期待される状態を表します。</p><p>liveは、実現された状態を表します。</p><p>Admiralは<a href="https://golang.org/" rel="nofollow" title="" class="ext-link">Go</a>で書かれており、本番環境のデータセンタで実行される際に、コンパイルされDockerコンテナにパッケージ化されます。Admiralには内部にサブシステムがいくつかあり、その大部分は以下の図に示されています。</p><p><img alt="" src="https://engineering.riotgames.com/sites/default/files/rcluster2_admiral_arch.png" style="height:400px; width:800px"><br>
ユーザ側から見ると、Admiralとのインタラクションはコマンドラインツールadmiralctlを使って行われます。このツールは、REST APIを介してAdmiralと通信します。ユーザはadmiralctlを用いてAdmiralの全ての機能にアクセスすることができます。その際に使う標準的なコマンドは、スケジュールすべき新しい<em>spec</em>のパックを送信するPOST、古いパックを削除するDELETE、現在の状態を入手するGETです。</p><p>本番環境では、AdmiralはHashiCorpの<a href="https://www.consul.io/" rel="nofollow" title="" class="ext-link">Consul</a>を使って<em>spec</em>の状態を格納します。重大な障害に備えて、Consulのバックアップは定期的に取っています。万一データが完全に失われた場合には、Admiralは個々のDockerデーモンから取得した<em>live</em>の状態の情報を使って、<em>spec</em>の状態を部分的に再構築することも可能です。</p><p><strong>リコンサイラ</strong>は、Admiralの中心に位置づけられ、スケジューリングのワークフローを進める際の鍵となるサブシステムです。リコンサイラは周期的に実際の<em>live</em>の状態と期待される<em>spec</em>の状態を比較して、相違があった場合には、<em>live</em>の状態を<em>spec</em>の状態に再び一致させるために必要な動作をスケジュールします。</p><p>liveの状態とそのドライバパッケージは、<em>live</em>のホストとコンテナの状態をキャッシュすることでリコンサイラをサポートし、REST APIを介してクラスタホストにおける全てのDockerデーモンとの通信を提供します。</p><p>Admiralのリコンサイラは、<em>spec</em>のパックに対して操作を行い、実質的に<em>live</em>のパックに変換します。<em>spec</em>のパックがAdmiralに提出されると、リコンサイラが動作し、Dockerデーモンを使ってコンテナを生成、起動します。このメカニズムを通じて、リコンサイラは、前述した大きなスケジューリング目的のうち初めの2つを達成するのです。リコンサイラが<em>spec</em>のパックを受け取ると、以下のように動作します。</p><p>Dockerホストでコンテナを起動する例をざっと見てみましょう。この例では、私のローカルのDockerデーモンをDockerホストとして使い、Admiralサーバのローカルインスタンスとやり取りしてみます。</p><p>まず、<code>admiral pack create &lt;cluster name&gt; &lt;pack file&gt;</code>コマンドを使って、パックを起動します。このコマンドは特定のクラスタをターゲットとして、<em>spec</em>のパックのJSONをAdmiralサーバに提出します。</p><p><img alt="" src="https://engineering.riotgames.com/sites/default/files/rcluster2_gif1_cropped.gif" style="height:427px; width:694px"><br>
お気付きでしょうが、コマンドを実行するとほぼ即時に、コンテナが私のマシン上で起動されています。このコンテナは、以下に示されているパックファイルのパラメータを使って起動されました。</p><p>次に、<code>admiral pack create</code>を呼び出したあと、<code>show</code>コマンドを使って、Admiralによって生成された<em>live</em>のパックを見ることができます。ここでは、コマンドは<code>admiral pack show &lt;cluster name&gt; &lt;pack name&gt;</code>となります。</p><p><img alt="" src="https://engineering.riotgames.com/sites/default/files/rcluster2_gif2.gif" style="height:427px; width:694px"><br>
最後に、コンテナ内のサービスに接続すれば、パックが機能していることを確認できます。<code>admiral pack show</code>コマンドで得た情報を使い、簡単なcurlコマンドを組み立ててサービスに接続することができます。</p><p><img alt="" src="https://engineering.riotgames.com/sites/default/files/rcluster2_gif3.gif" style="height:427px; width:694px"><br>
Admiral内では、リコンサイラが常に稼働しており、クラスタのliveの状態が期待されるspecの状態に常に一致するようにしてくれます。これによって、クラッシュが原因でコンテナが動作しなくなって終了したり、ハードウェア障害が原因でサーバ全体が使用不能になったりした時に、復旧することが可能となります。リコンサイラは状態が確実に一致するように動作するので、プレイヤのプレイが中断されることは決してありません。この機能によって、前述した最後の3番目の問題が解決されます。つまり、コンテナが予期せず終了した時に素早く復旧できるので、その影響が最小限に抑えられるのです。</p><p>以下の画面では、<code>admiral pack create</code>コマンドで起動された既存のコンテナを示しています。次に、そのコンテナの実行を強制終了しています。すると、<em>live</em>の状態が<em>spec</em>の状態と一致しないことをリコンサイラが認識するので、数秒以内に（別のIDを持った）新しいコンテナがリコンサイラによって起動されています。</p><p><img alt="" src="https://engineering.riotgames.com/sites/default/files/rcluster2_gif4.gif" style="height:427px; width:694px"></p><p>コンテナを最適に割り当てるため、スケジューラはホストのクラスタを認識する必要があります。この問題の解決に際しては、鍵となる2つのコンポーネントがあります。</p><p><strong>リソース</strong> – サーバが使えるリソースの表現。メモリ、CPU、I/O、ネットワーキングなど。</p><p><strong>制約</strong> – パックに伴う条件のセット。パックを配置できる場所に関して、制限の詳細をスケジューラに伝える。例えば、パックのインスタンスを以下の場所に配置した方がよいかもしれない。</p><p>ホスト上のリソースを定義することで、スケジューラがコンテナを配置する場所を柔軟に決められるようにしています。また、パックの制約を定義することで、クラスタに対する特定パターンを強制できるようにスケジューラの選択肢を制限しています。</p><p>Riotにとって、Admiralはデプロイ技術を進化させ続けるために不可欠なソフトウェアです。Dockerとスケジューリングシステムのパワーを活用することで、バックエンド機能を以前よりずっと素早くプレイヤに提供できるようになりました。</p><p>本稿では、Admiralの機能の一部を詳しく見て、マシンのクラスタ全体にわたってコンテナをスケジュールしている方法をご紹介しました。Jonathanが<a href="http://postd.cc/running-online-services-riot-part-i/">第1部の記事</a>で言及しているように、オープンソースの世界は、これによく似たモデルへと急速に移行しました。弊社は今後、Admiralで行っている作業を移行し、<a href="https://dcos.io/" rel="nofollow" title="" class="ext-link">DC/OS</a>のデプロイに重点を置いていく予定です。DC/OSは、コンテナのワークロードをスケジュールするための主要なオープンソースアプリケーションとなっています。</p><p>似たような開発の経験がある方や、この話題に補足したい点のある方は、ぜひ本稿のコメント欄にご記入ください。</p>
