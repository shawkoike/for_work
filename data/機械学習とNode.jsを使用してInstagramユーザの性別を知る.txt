<p><a href="http://totems.co/blog/machine-learning-nodejs-gender-instagram/" rel="nofollow" title="" class="ext-link">Using Machine Learning and NodeJS to detect the gender of Instagram Users</a> (2014-09-25) by <a href="https://twitter.com/spolu" rel="nofollow" title="" class="ext-link">Stanislas Polu</a></p><p>Polytechniqueおよびスタンフォード大学を卒業後、TOTEMSを共同設立しました。TOTEMSでは技術的業務を指揮するほか、未来のウェブサーバ、Breachを構築しています。大したことではありませんよ!</p><p>この記事の目的は、機械学習ソリューションを大規模に展開するための実用的なガイドを提供することです。全てのものが正しいと立証されたわけでもありませんし、また最適であるとも限りません。私たちが実際に展開した際には、いくつかのトレードオフもありました。アカデミックな環境であれば必要とされるであろうあらゆる論拠の積み上げを必ずしも行うことなく、随時簡便な方法で済ませたところもあり、それについてはおわびします。そのような箇所は投稿を通じて明確に示しながらも、この記事が皆さんの役に立つことを願っています。</p><p>少し背景から説明します。TOTEMS AnalyticsはInstagramの（ハッシュタグと関連のあるオーディエンスやコミュニティの）解析を行います。この1年で、Instagramのオーディエンスに関する統計情報への需要はかつてないほどクライアントから寄せられています。そこで私たちは6カ月前、プラットフォーム上に見つけられるソーシャルシグナルに基づく性別分類器を構築することに時間を費やそうと決めました。（InstagramはAPIでユーザの統計情報を公開していません）。プロジェクトには2人月の工数をかけました。名前の抽出や人口調査といった基本的な方法を試したあと（成功率は0.65にとどまり、ランダムな分類の成功率0.5をかろうじて上回る程度でした）。私たちは、比較的シンプルなニューラルネットワークアプローチを思い付きました。これによりクライアントに、他のどこにも見つけることができない独自の情報を提供できます。そして、この実装方法をシェアすることにより、皆さんもシンプルな機械学習の技術を活用して、自分でクライアントおよびユーザのエクスペリエンスを強化し、差別化できるだろうと私たちは考えたのです。</p><p>私たちのプラットフォームは1秒につきおよそ400ユーザのプロフィールを読み出したり、リフレッシュしたりします（これはAWSを利用したInstagramのAPIサーバにコロケーションされている4台の高帯域サーバで管理されています）。受信したプロフィールは断片化されたMySQLテーブルに格納され、オーディエンス（フォローする人とされる人の関係）およびコミュニティ（特定のハッシュタグへの貢献者）に関する集約された情報を計算します。これにより、私たちが作ろうとしている性別分類器の必須条件は次のようになりました。</p><p>訓練全体を通して、おそらくこれが最も重要な部分です。分類器を作成する際、元々足りていないデータを導き出したいという場合が見受けられます。しかし、訓練データセットとして使うためには、適切に分類された、かなり大きなデータセットが必要です。私たちの場合、Instagramアカウントの莫大な人口の性別を判定する必要がありました。私たちはこの性別情報が他のプラットフォーム上で簡単に入手可能であることが分かっていました。特にほとんどのユーザが自分の性別を公開しているFacebook[1] などがそうです。FacebookのURLを含む（たくさんありました）Instagramのプロフィールに絞ることで事態は進展しました。</p><p>私たちは、適切なFacebookプロフィールへのURLではないものを除外するために、数行の単純な正規表現を書き、目に留まるユーザID全てを調べました。そして、妥当な場合は、更にその人たちのフォロワーまでも確認しました。数億のInstagramユーザ（当時のユーザ基盤の大半でした）を検証した結果、私たちは、関連がある場合はいつでもInstagramのユーザ名とFacebookプロフィールの連携を抽出することができました。次のステップでは、情報が利用できる場合にFacebookの性別情報を抜き出します。57万件のプロフィールを訓練データセットとしました。</p><p>ニューラルネットワークを構築する前に、どの入力シグナルを使用するかについて理解を深める必要がありました。以下のようなアプローチが私たちの目的に適していると考えられました。</p><p>ここでの大きな問題は、入力シグナルのスペースが非常に大きく（全てのN-gram一式、もしくは全単語一式）、全てのプロフィールに合う（ほとんどの分類器から求められる）一貫した固定サイズの入力ベクトルをデザインするのが困難である点です。</p><p>この問題に対する興味深いソリューションは、相互情報量を頼りに入力スペースを整え[2]、性の確率変数を使って相互情報量[3]が上位N個のN-gramもしくは全単語を選ぶことです。直観的に、2つの確率変数間の相互情報量は、この2つの変数のうちの1つが分かっていればもう一方についての不確実性をどれだけ減らせるかを測ります。以下のように相互情報量を計算しました。</p><p>訓練データセットに含まれるユーザからの最近の投稿のキャプションに使用されたハッシュタグと全単語、N-gramを抽出し、上記の計算を実行しました。</p><p>好奇心から、使用されたハッシュタグを基に女性として分類される条件付き確率に従ってハッシュタグを並べました。これらは女性ユーザと最も関連性の強いハッシュタグです。</p><p>男性ユーザと最も関連性の強いハッシュタグも計算しました。</p><p>最後に、男性と女性のどちらからも使われる上位のハッシュタグ1万個を生成しました。</p><p>このリストを使って、ユーザが最近投稿したキャプションの中で男性と女性のどちらからもよく使われるハッシュタグがあるか（ないか）を示している、任意サイズ（1k, 2k, 4k, 10k）で固定サイズのバイナリ入力ベクトルが生成できました。この作業をN-gramと全単語で繰り返し、どちらの入力シグナルがより効率的かはニューラルネットワークを構築してから評価することにしました。</p><p>直観的に、男性か女性かの条件付き確率は、相互情報量よりも効果的な指標であるように見えますが（これらのリストは確かにそれを良く表しています）、相互情報量は特徴を見つける確率を考慮に入れています（男性と女性のどちらからも使われる上位の単語が、いかに条件付き確率によって分類された単語よりも確率が高く、回数がはるかに大きいかを見てください）。つまり、関連が高いが確率が低い単語よりも、関連が低くて確率がはるかに高い単語を分類器が持っている方がより効率的なのです。前者はユーザの分類には全く役に立たないでしょう。</p><p>私たちは評判の良いレファレンス[4][5]に基づき、Node.jsを使って独自のニューラルネットワークを実装しました。小さな訓練データセットから始め、Javascriptのガベージコレクタの限界に達する（あまりに頻繁に止まってしまう）までサイズを徐々に増やしていき、C++でNode.jsのネイティブアドオンとしてリライトしました（こちらから利用可能です：<a href="https://github.com/totemstech/neuraln" rel="nofollow" title="" class="ext-link">https://github.com/totemstech/neuraln</a>）。</p><p>ニューラルネットワークは複数の層で構成された図です。第1層は分類されるべき入力ベクトル値に設定されます。ここで入力ベクトル値に当たるのは、ユーザの最近の投稿において男性と女性のどちらからも使われる上位N個のハッシュタグやN-gramです。それぞれの層は重みの値によって他の層とリンクしていて、1つの層にあるノードはどれも次の層の全ノードとリンクしています。入力層と出力層の間には複数の層があることがあり、これらを中間層といいます。最後に、外層は出力ベクトルを表しますが、出力ベクトルのサイズは導き出される値に依存しています。</p><p>そのためニューラルネットワークは、その層構造から”layers_[l]”（各層にあるノードの数）と定義され、各層の間の重みの値は”W_[l][i][j]”と定義されます。他のメンバは割愛しますが、ニューラルネットワークはまさにこのようにして定義されるのです。</p><p>また、ネットワーク内の各ノードは、その活性化関数によって定義されます。この関数は、ノードが前の層から受け取った入力の合計を踏まえて、次の層に出力するものを定義します。これは入力ベクトルによって値が設定されている入力層を除く全ての層に当てはまります。私たちは実装においてノードの活性化関数のために以下のコードを使用します。</p><p>ニューラルネットワークを表す適切なデータ構造ができたので、訓練できるようにする必要があります。私たちが類型化したネットワークはフィードフォワード型ネットワークで、値は各ノードで次の層にフィードする活性化関数を使いながら、重みに従って入力ベクトルから出力ベクトルへ伝搬されます。そうしたネットワークの訓練はバックプロパゲーション[6]に依存しています。</p><p>バックプロパゲーションそのものは、1回のブログ投稿[7]に相当し、書籍[4]で非常に良く説明されていますので、詳しく理解したいという方は参照されることをお勧めします。覚えておくべきことは、バックプロパゲーションは、エラー（出力された値と訓練データセットから期待されている値の違い）をネットワークの勾配に従って伝搬することによって、ニューラルネットワークの重みの更新を可能にするということです。ところで、その勾配を計算するには活性化関数が微分可能である必要があります。バックプロパゲーションは1970年に発明されましたが、やっと実用化されたのは1986年で、ニューラルネットワークのより幅広い使用が可能になりました。それ以来、ニューラルネットワークの訓練において信頼の置けるソリューションとなりました。</p><p>バックプロパゲーションを使用することで、私たちは訓練データセットの要素を繰り返し、望ましい値に達するまでエラー率を減らすことができます。私たちは実装において、計算された出力”res”と、期待されていた出力”train[i]”の間にある二次エラーの合計を計算し、訓練データセット全体を通して平均化します。この計算は、独立引数として通用する目標値”error”に達するまで繰り返されます。</p><p>機能的なニューラルネットワークと訓練アルゴリズムが揃ったので、次のステップは異なるネットワーク構造と入力シグナルをテストして、最も期待できるシグナルを見つけることでした。以下は、最初の結果です。</p><p>ここで注目されるのは、中間層（パーセプトロンと言います）のないネットワークは線型分類器であることです。その予測は、入力された特徴のシンプルな線形結合に基づきます。これらのネットワークがエンコードするモデルの単純さを考えると、その効率の良さに大変驚かされました。</p><p>一番良い結果は、１つの隠れ層（中間層）を持つネットワークから得られました。この結果から、大きい（10k）ハッシュタグベースの入力ベクトルを使用することで最善の結果を得られるだろうと私たちは推測しました。特に、より大きい訓練データセットを使用できるならなお更です。</p><p>私たちは200k要素の訓練データセットを使っていくつかのネットワークを訓練することができました。このような大きいデータセットの訓練は、私たちが用意したサーバで最大5時間かかるため、そのプロセスは極めて苦痛になっていきました。200k要素の訓練データセットを使用しながら、私たちは成功率を0.83まで高めることができました。</p><p>最後に、ブースティング[8]からヒントを得て、それぞれ200k要素を持つ2つの全く異なる訓練データセットを使って男性ネットワークおよび女性ネットワークの訓練実験を行いました。そして両方のネットワークを使って、指定された入力に強い反応を示した方のネットワークを選択することで分類しました。これは、ここで説明してきた非広範な実験的アプローチ以外の何にも根差さない、純粋に使用可能なソリューションです。しかし私たちにとっては、これが一番うまくいきました。このテクニックを使って、70k要素のテストセットで最初の目標値に近い0.88という成功率を達成することができたのです。</p><p>ライブラリにシリアライゼーション（「to_string」）とデシリアライゼーション（コンストラクタ）関数を追加して、生成された分類器を製品に組み込みました。フィードフォワード式ニューラルネットワークの性質として優れているのは、ネットワークがメモリに読み込まれてしまえば、分類は非常に高速に行われることです。インフラストラクチャに分類器を追加しても、集約サーバの読み込みに明白な影響はありませんでした。</p><p>この投稿を準備するにあたって、ネットワークの構造を視覚化するために、ニューラルネットワークのシリアライズされたフォーマットをSVGで表すためのスクリプトをいくつか追加しました。これらのスクリプトを、この数カ月使用してきた作成中のネットワーク（男性および女性）で実行してみました。</p><p>この可視化の結果を以下に示します（クリックすると拡大します）。「重い」リンク、つまり0.8を超える絶対重量を持つリンクのみを表示しています。正の重量は青の線で、負の重量は赤の線で示されています。リンクが重くなるほど、色が濃くなります（半透明のリンクは0.8に近く、それ以外は絶対重量より重いリンクです）。</p><p><a href="http://totems.co/wp-content/uploads/2014/09/visu_nn_threshold_0_8.png" rel="nofollow" title="" class="ext-link"><img src="http://totems.co/wp-content/uploads/2014/09/visu_nn_threshold_0_8.png" alt="visu_nn_threshold_0_8" width="1632" height="620" class="alignnone size-full wp-image-11149"></a></p><p>結果として現れた構造のシンプルさには驚きましたが、ここに表示されていない低重量のリンクが重要な役割を果たしている可能性に気付きました。特に、この図に進入リンクを持たない一定数の中間層ノードが重要な出力リンクを持っていると思えるからです。</p><p>別の驚くべき側面は、2つのネットワークの類似性です。どちらも主に、結果に正の影響を与える中間層ノードをフィードする正のコンポーネントを持っています。そして、正と負の混合コンポーネントは結果に負の影響を与える中間層をフィードします。前者のコンポーネントは推進因子の役割を果たし、後者のコンポーネントは阻害因子の役割を果たしているようです。</p><p>作成中の機械学習ソリューションを展開する私たちの実験について説明してきましたが、これが、オンラインや教科書で公開されている多数の理論的リソースを解説する、有益な実例として役立つことを願っています。このニューラルネットワークを構築して訓練するために使用し、現在TOTEMSで使用されているコードは、当社のGitHubアカウント: <a href="https://github.com/totemstech/neuraln" rel="nofollow" title="" class="ext-link">https://github.com/totemstech/neuraln</a>でオープンソースとして公開されています。純粋なJavaScriptネットワークの実装でC++実装のスピードが足りないという製作状況で役立てていただければと思います。</p><p>-stan</p><p>[1] Facebook Graph API <a href="https://developers.facebook.com/docs/graph-api/reference/v2.1/user" rel="nofollow" title="" class="ext-link">https://developers.facebook.com/docs/graph-api/reference/v2.1/user</a><br>
[2] Dicriminating gender on Twitter – The MITRE Corporation <a href="https://www.mitre.org/sites/default/files/pdf/11_0170.pdf" rel="nofollow" title="" class="ext-link">https://www.mitre.org/sites/default/files/pdf/11_0170.pdf</a><br>
[3] 相互情報量 – ウィキペディア <a href="http://ja.wikipedia.org/wiki/%E7%9B%B8%E4%BA%92%E6%83%85%E5%A0%B1%E9%87%8F" rel="nofollow" title="" class="ext-link">http://ja.wikipedia.org/wiki/%E7%9B%B8%E4%BA%92%E6%83%85%E5%A0%B1%E9%87%8F</a><br>
[4] Artificial Intelligence: A Modern Approach – S.Russel, P.Norvig <a href="http://www.amazon.com/Artificial-Intelligence-Modern-Approach-Edition/dp/0136042597" rel="nofollow" title="" class="ext-link">http://www.amazon.com/Artificial-Intelligence-Modern-Approach-Edition/dp/0136042597</a><br>
[5] Brain.js – @hartur <a href="https://github.com/harthur/brain" rel="nofollow" title="" class="ext-link">https://github.com/harthur/brain</a><br>
[6] バックプロパゲーション– ウィキペディア <a href="http://ja.wikipedia.org/wiki/%E3%83%90%E3%83%83%E3%82%AF%E3%83%97%E3%83%AD%E3%83%91%E3%82%B2%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3" rel="nofollow" title="" class="ext-link">http://ja.wikipedia.org/wiki/%E3%83%90%E3%83%83%E3%82%AF%E3%83%97%E3%83%AD%E3%83%91%E3%82%B2%E3%83%BC%E3%82%B7%E3%83%A7%E3%83%B3</a><br>
[7] How the backpropagation algorithm works – M.Nielsen  <a href="http://neuralnetworksanddeeplearning.com/chap2.html" rel="nofollow" title="" class="ext-link">http://neuralnetworksanddeeplearning.com/chap2.html</a><br>
[8] ブースティング（機械学習）– ウィキペディア <a href="http://ja.wikipedia.org/wiki/%E3%83%96%E3%83%BC%E3%82%B9%E3%83%86%E3%82%A3%E3%83%B3%E3%82%B0" rel="nofollow" title="" class="ext-link">http://ja.wikipedia.org/wiki/%E3%83%96%E3%83%BC%E3%82%B9%E3%83%86%E3%82%A3%E3%83%B3%E3%82%B0)</a></p>
