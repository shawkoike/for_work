<p><a href="http://jpetazzo.github.io/2014/06/23/docker-ssh-considered-evil/" rel="nofollow" title="" class="ext-link">If you run SSHD in your Docker containers, you're doing it wrong!</a>（2014-06-23）by <a href="http://jpetazzo.github.io/" rel="nofollow" title="" class="ext-link">Jerome Petazzoni</a></p><p>Dockerを使い始めた人がよくする質問といえば、「どうすればコンテナに入れますか？」です。その質問に対して、「コンテナ内でSSHサーバを起動すればいいよ」と答える人たちがいますが、これは非常にマズいやり方です。なぜその方法が間違いなのか、そして代わりにどうすればよいのかをこれから紹介します。</p><p><em>注：本記事へのコメントやシェアは、<br>
<a href="http://blog.docker.com/2014/06/why-you-dont-need-to-run-sshd-in-docker/" rel="nofollow" title="" class="ext-link">Dockerブログ</a>にアップされた標準版から行ってください。よろしくお願いします。</em></p><p>…もちろん、コンテナ自体がSSHサーバである場合は除きます。</p><p>SSHサーバを起動したくなる気持ちは分かります。それはコンテナの”中に入る”簡単な方法だからです。この業界の人ならほぼ全員がSSHを一度は使ったことがあります。多くの人がSSHを日常的に使用し、公開鍵や秘密鍵、パスワード入力の省略、認証エージェント、そして時にはポート転送やその他の細かいことにまで精通しています。</p><p>以上のことを考慮すると、コンテナ内でSSHを起動しろというアドバイスが出るのも妥当だと言えます。しかし、それについてはよく考える必要があるでしょう。</p><p>例えば、RedisやJava WebサービスのDockerイメージを構築するとします。そこで、いくつか質問させてください。</p><p>SSHが使われるのは、おそらく、バックアップやログのチェック、またはプロセスの再起動やコンフィグの微調整をするためでしょう。もしかすると、gdbやstraceのようなツールでサーバをデバッグするためにも用いられるかもしれません。しかし、SSHなしでこれらのことを行う方法があるので、のちほど紹介します。</p><p>大抵の場合は、鍵やパスワードをイメージの中に組み込むか、ボリュームの中に格納するかのどちらかだと思います。では、鍵やパスワードをアップデートしたい時はどうしますか。鍵やパスワードをイメージの中に組み込む場合は、イメージを再構築して再デプロイし、コンテナを再起動する必要があります。このやり方でも大して煩わしいわけではありませんが、簡潔だとは言えません。はるかに優れたソリューションは、これらの認証情報をボリュームに格納し、ボリュームの中で管理することです。これは良い方法ですが、深刻な欠点もあります。この場合、コンテナにボリュームへの書き込み権限を与えてはいけません。さもないと、コンテナが認証情報を破損するかもしれないからです（その結果、コンテナへのログインができなくなってしまいます）。認証情報が複数のコンテナで共有されている場合は、さらに面倒なことになるでしょう。そんな時、コンテナ内にSSHさえなければ、心配事が1つ減るはずですよね？</p><p>SSHサーバは安全ですが、それでも、セキュリティ上の問題が発生した場合は、SSHを使っている<em>全ての</em>コンテナをアップグレードする必要があります。つまり、<em>全ての</em>コンテナを再構築、および再起動しなくてはなりません。たとえ無害なmemcachedのサービスを使うだけでも、セキュリティ勧告に従って最新の安全対策をする必要があります。なぜなら、コンテナの攻撃対象領域は不意に拡大するからです。この場合も、コンテナ内にSSHさえなければ、<em>心配事を分散</em>できるはずですね？</p><p>それだけでは不十分です。Dockerは1つのプロセスを監視するため、SSHサーバに加え、<a href="http://mmonit.com/monit/" rel="nofollow" title="" class="ext-link">Monit</a>や<a href="http://supervisord.org/" rel="nofollow" title="" class="ext-link">Supervisor</a>のようなプロセスマネージャが必要です。複数のプロセスが必要な場合は、トップレベルにプロセスマネージャを1つ追加して他のプロセスをカバーできるようにしなくてはなりません。しかしこれでは、無駄のないシンプルなコンテナがずいぶんと複雑になってしまいます。アプリケーションの終了時（正常終了の場合もクラッシュの場合も）には、Dockerからではなく、プロセスマネージャから情報を得なくてはなりません。</p><p>小規模な会社ではそれほど大きな問題にはなりません。しかし、大規模な会社で、コンテナにアプリケーションを格納する役割をあなたが担っているとしたら、リモートアクセスポリシーに責任を持つのは、おそらくあなた以外の人でしょう。また会社には、誰がアクセス権を持ち、どのように、そしてどんな種類のオーディットトレイルが必要なのかを定めた厳格なポリシーがあるかもしれません。そのようなケースでは、コンテナにSSHサーバを置くようなことは、絶対にしないほうがいいでしょう。</p><p>データは<a href="https://docs.docker.com/userguide/dockervolumes/" rel="nofollow" title="" class="ext-link">ボリューム</a>に置くべきです。そして、別のコンテナを実行しましょう。<code>--volumes-from</code>オプションをつけて、そのコンテナと事前に作ったコンテナのボリュームを共有します。そうすれば新たなコンテナがバックアップを担い、必要なデータにアクセスできます。</p><p>その上、利点もあります。バックアップまたは長期保存するデータをストレージに送るために新たなツール（例えば、<code>s3cmd</code>やそれに類似するもの）をインストールしなければならない場合、メインサービスを担うコンテナの代わりに、専用のバックアップコンテナで、そのインストールのジョブを行えることです。このほうが簡潔ですね。</p><p><a href="https://docs.docker.com/userguide/dockervolumes/" rel="nofollow" title="" class="ext-link">ボリューム</a>を使いましょう。そうです、またボリュームです。特定のディレクトリにログを保存するとして、そのディレクトリがボリュームだとしたら、(例の<code>--volumes-from</code>を使って)”ログを調査する”別のコンテナを起動しましょう。ここで必要なことを全て実行します。</p><p>先ほどと同じように、専門のツール（<code>ack-grep</code>か何か）が必要な場合、メインコンテナを初期状態に保ちながら、別のコンテナにそのツールをインストールできるわけです。</p><p>事実上、シグナルを送ればあらゆるサービスを再起動できます。<code>/etc/init.d/foo restart</code>や<code>service foo restart</code>といったコマンドを打つと、ほとんどの場合、特定のシグナルがプロセスに送られるでしょう。<code>docker kill -s <signal></signal></code>を使って、シグナルを送信できます。</p><p>シグナルを受け付けないサービスもありますが、そういったサービスは特別なソケットでコマンドを受け付けます。TCPソケットであれば、シグナルをネットワーク経由で接続することになりますし、UNIXソケットであれば、ボリュームを使うことになります。またボリュームが登場しましたね。コントロールソケットが特定のディレクトリ配下になるように、コンテナとサービスを立ち上げてください。そのディレクトリとは、ボリュームのことです。その上で、ボリュームにアクセスする新たなコンテナを起動すれば、ソケットを使えるようになります。</p><p>複雑な手順だと思うかもしれませんが、決してそうではありません。<code>foo</code>というサービスが<code>/var/run/foo.sock</code>にソケットを作成し、正常に再起動するために<code>fooctl restart</code>を実行する必要があるとしましょう。その場合はサービスを<code>-v /var/run</code>で単に起動してください（またはDockerfileに<code>VOLUME /var/run</code>を追加するという方法もあります）。再起動したい時は、<code>--volumes-from</code>オプションをつけてコマンドをオーバーライドしつつ、同じイメージを実行すればいいのです。つまり以下のような感じになります。</p><p>とてもシンプルですね。</p><p>もしコンフィグに永続的な変更を加えるのであれば、イメージ内で行うべきです。そうしないと、新たなコンテナを起動した時に古いコンフィグが残っていて、変更が失われてしまうことになります。そうなるとSSHアクセスを実行することができませんよね。</p><p><em>「でも、例えば、新たなバーチャルホストを追加するような時、サービスの実行中に、コンフィグを変更しないとならないんです」</em>という方もいるでしょう。</p><p>そのようなケースは、あれを使ってください。そうです、ボリュームです。コンフィグはボリュームにあり、そのボリュームは”コンフィグ編集”専用のコンテナと共有されているはずです。このコンテナ内では使いたいツールを使えます。つまりSSHとお好みのエディタ、またはAPIコールを受け付けるWebサービスや、外部ソースから情報を取得するcrontabなど、何でも使えるのです。</p><p>繰り返しになりますが、こうすることで心配事を分散させることができます。あるコンテナはサービスを実行し、別のコンテナはコンフィグを更新する役割を担うというようなことです。</p><p><em>「でも、異なる値をテストするために一時的な変更をしたいだけなんです」</em>と言いたい人もいるかもしれませんね。</p><p>その場合は、次のセクションを確認してみてください。</p><p>この時ばかりは、<em>どうしても</em>コンテナ内にシェルを導入する必要があります。なぜならば、gdbやstraceを実行したり、コンフィグを微調整したりしなければならないからです。</p><p>この場合、<code>nsenter</code>が必要です。</p><p><code>nsenter</code>は名前空間（<code>n</code>ame<code>s</code>pace）に入る(<code>enter</code>)ことを可能にする、ちょっとしたツールです。正確に言えば、<code>nsenter</code>は既存の<a href="http://blog.dotcloud.com/under-the-hood-linux-kernels-on-dotcloud-part" rel="nofollow" title="" class="ext-link">名前空間</a>に入ること、あるいは新たな名前空間でプロセスを作成することを可能にします。「さっきから言っている名前空間って何ですか？」と疑問に思った方のために補足しておきますが、名前空間とは、コンテナを構成する基本要素の1つです。</p><p>簡単に説明すると、<b><code>nsenter</code>を使うことで既存のコンテナにシェルを導入できます。</b>コンテナがSSHや特別な目的を持ったデーモンを実行していなくても、それは可能です。</p><p>GitHubの<a href="https://github.com/jpetazzo/nsenter" rel="nofollow" title="" class="ext-link">jpetazzo/nsenter</a>を読んでください。早い話が、次のコマンドを実行すればいいのです。</p><p>すると、<code>nsenter</code>が<code>/usr/local/bin</code>にインストールされ、すぐに使用できます。<code>nsenter</code>は、（<code>util-linux</code>パッケージの）ディストリビューションに含まれている場合もあります。</p><p>まず、入りたいコンテナのPIDを指定します。</p><p>そしてコンテナに入ります。</p><p>するとコンテナ内にシェルが導入されます。これだけです。</p><p>特定のスクリプトやプログラムの実行を自動化したい場合は、それらを引数として<code>nsenter</code>に追加してください。シンプルなディレクトリの代わりにコンテナを利用するという点を除けば、<code>nsenter</code>の動作は<code>chroot</code>と少し似ています。</p><p>リモートホストからコンテナに入る必要がある場合は、（少なくとも）2つの方法があります。</p><p>1番目の方法はとても簡単です。しかし、Dockerホストへのrootアクセスが必要です（したがってセキュリティの観点からは、いい方法とは言えません）。</p><p>2番目の方法は、SSHの<code>authorized_keys</code>ファイルの中で<code>command=</code>パターンを使用するやり方です。”クラシックな” <code>authorized_keys</code>ファイルについてはご存じだと思いますが、以下のような感じになります。</p><p>（もちろん、実際のキーはこれよりもずっと長く、通常、何行にも及びます）</p><p>特定のコマンドを実行させることもできます。SSHキーを使ってリモートホストからシステム上の使用可能なメモリをチェックできるようにしたいが、完全なシェルアクセスを許可したくない場合、<code>authorized_keys</code>ファイルに次のように記述してください。</p><p>すると、指定したキーで接続した時、シェルが導入される代わりに、freeコマンドが実行されます。それ以上のことは行われません。</p><p>（厳密に言えば、<code>no-port-forwarding</code>を追加したほうがいいでしょう。詳しくはmanページの<code>authorized_keys(5)</code>を参照してください）</p><p>この仕組みの重要なポイントは、役割を分けることにあります。アリスは、コンテナ内にサービスを置きますが、リモートアクセスやロギングなどには関与しません。ベティは、特殊な状況でのみ使用されるSSHレイヤを（不可解なトラブルをデバッグするために）追加します。シャーロットは、ロギングの管理をします。こんな感じです。</p><p>コンテナ内でSSHサーバを実行するのは本当に大間違いなのでしょうか。正直に言うと、それほど悪いことではありません。Dockerホストにアクセスできない時は、非常に便利な手段です。しかし、コンテナ内にシェルを導入しなければならないという点は変わりません。</p><p>今回は、コンテナ内でSSHサーバを実行しなくてもいい方法をいくつか紹介しました。これらの方法であれば、これまでのように必要な機能を全て手に入れることができ、その上、はるかに簡素なアーキテクチャを構築できます。</p><p>Dockerの利用者は、自分にとって最適なワークフローを選ぶことができます。しかし、”コンテナを小さなVPSにしよう”といった時流に乗る前に、解決方法は他にもあるということを覚えておいてください。これで、情報に基づいた判断が下せるはずです。</p>
