<p><a href="https://codewords.recurse.com/issues/six/image-processing-101" rel="nofollow" title="" class="ext-link">Image Processing 101</a>  by <a href="https://twitter.com/piratefsh" rel="nofollow" title="" class="ext-link">Sher Minn Chong</a></p><p>この記事は、<a href="https://www.recurse.com" rel="nofollow" title="" class="ext-link">Recurse Center</a>の季刊プログラミング・ジャーナルである<a href="https://codewords.recurse.com" rel="nofollow" title="" class="ext-link">Code Words</a>で公開されたものです。</p><p>Recruse Centerでは、私は、画像処理の勉強に時間を費やしていました。独学をし始めた頃は、何をするものなのか全く理解しておらず、ただ、文字や輪郭、模様などを識別するのに役立ち、これらで面白いことができる、ということくらいの知識しかありませんでした。</p><p>私の情報源は、主にWikipediaや書籍、公開されている大学の講義ノートです。これらの資料に慣れ親しんでくるにつれ、画像処理の世界における基礎を伝えられる「入門向け画像処理」を望むようになりました。</p><p>これが、この記事を書こうと思ったきっかけです。</p><p>この記事は、Pythonが扱えるということを前提に書いています。その他の事前知識は必要ありませんが、NumPyや行列計算に慣れていると理解しやすいでしょう。</p><p>使用するのは、Python版OpenCV、Python 2.7<sup id="fnref:1"><a href="#fn:1" class="footnote-ref">1</a></sup>、iPython Notebookです。MacOSでOpenCVをセットアップする方法は、<a href="https://github.com/piratefsh/image-processing-101#installation" rel="nofollow" title="" class="ext-link">こちら</a>を参照してください。</p><p>ここで使用した全てのコードや画像は、GitHub上に<a href="https://github.com/piratefsh/image-processing-101" rel="nofollow" title="" class="ext-link">実行可能なiPython notebook</a>として掲載してあります。また、<a href="http://piratefsh.github.io/image-processing-101/" rel="nofollow" title="" class="ext-link">iPython notebookオンライン</a>でも確認することができます。</p><p>画像処理を学ぶ際は、画像をインラインで表示することができる、iPython notebookの環境下で行うことを強くお勧めます。そうすることで、コードが実際に何をしているのかのフィードバックを簡単に得ることができるのです。</p><p>画像処理とは、特定の効果（例えば、グレースケール画像）をもたらすために画像を加工したり、操作したりすることです。また、コンピュータを使って、画像から情報を取り出したりすること（画像内にある円を数えるといったようなこと）も、画像処理です。</p><p>画像処理は、コンピュータビジョンとも深く関係しており、これらの境界線はとても曖昧です。しかし、深刻に考える必要はありません。私たちがここで学ぼうとしているのは、画像を加工する方法や、これらの方法を使って、いかに画像情報を集めることができるかということです。</p><p>この記事では、画像処理の簡単な構成要素について話していきながら、いくつかのコードや、基本的な操作手順を紹介していきます。コードは全てPythonで書かれており、強力な画像処理・コンピュータビジョンのライブラリである、<a href="http://opencv.org/" rel="nofollow" title="" class="ext-link">OpenCV</a>を使っていきます。</p><p>まずは、インポートから行います。ここでは、<code>cv2</code>、<code>numpy</code>、そして（主に簡単に画像を表示するために）少しだけ<code>matplotlib</code>を使用します。</p><p>では、始めていきましょう！　最初に、現在表示されている画像のフォーマットを知るために、画像を読み込む必要があります。</p><p>OpenCVでは、画像は3次元のNumPy配列で表されています。1つ1つの画像は、ピクセルの行列で構成されており、各ピクセルはその色を表す値の配列によって表現されています。</p><p>この画像の場合の配列は、以下のようになります。</p><p>結果：</p><p><code>[72 99 143]</code>といった数値は、それぞれ1つのピクセルにおける青、緑、赤（BGR）の3色の値を表しています。ちなみに、OpenCVでは、画像はBGRフォーマットで読み込まれる初期設定となっていますが、Matplotlibの場合はRGBで読み込まれます。Matplotlibで画像を表示させるために、BGRフォーマットをRGBに変換しなくてはなりません。Matplotlibに画像を渡す前にこの処理をしないとどうなるかは、ご自身で考えてみてください。</p><p><img width="500" src="https://codewords.recurse.com/images/six/image-processing-101/image-matplotlib.png"></p><p>ちょっと、待ってください。この問題に、なぜBGRとRGBが関係してくるのでしょう？</p><p>デジタルの世界では、色は、<strong>RBGカラーモデル</strong>を使って表現されるのが一般的です。このカラーモデルに従って、赤や緑、青の光が様々な形で合わさることで、可視スペクトル上に幅広い色を表現するのです。各色はチャンネルと呼ばれており、ペンキの色を混ぜて出来る色とは少し異なります。以下がRGBカラーモデルでの発色です。</p><p><img src="https://codewords.recurse.com/images/six/image-processing-101/rgb.png"><br>
<em>Wikipediaから引用<sup id="fnref:3"><a href="#fn:3" class="footnote-ref">2</a></sup></em></p><p>細かい説明はこれくらいにしておきます。色の合成についての詳しい説明は、<a href="http://www.wikiwand.com/ja/RGB#/.E5.8A.A0.E6.B3.95.E6.B7.B7.E5.90.88.E3.81.AB.E3.81.8A.E3.81.91.E3.82.8B.E5.8E.9F.E8.89.B2" rel="nofollow" title="" class="ext-link">Wikipediaの当該部分</a>をご覧ください。</p><p>ほとんどのシステムでは、RGB値は0から255の領域で表現されるようになっています。数値が高ければ高いほど、その色チャンネルの明度は高くなります。例えば、<code>[255, 51, 0]</code>は赤みがかった色だと推測することができます。なぜなら、Rチャンネルの数値が最高値だからです。また<code>[51, 102, 0]</code>が、緑がかった色と推測できるのは、Gチャンネルの数値が最高値だからです。</p><p>RGBの他に役立つカラーモデルが、<strong>HSVカラーモデル</strong>です。赤や緑、青の色度で色を表現する代わりに、<strong>色相</strong>（虹色のカラーチャートのどの領域に位置するか）、<strong>彩度</strong>（色の「鮮やかさ」）、そして<strong>明度</strong>（明るさとも言い、どの程度の光が取り入れられているか）で表現されます。</p><p><img src="https://codewords.recurse.com/images/six/image-processing-101/hsv.png"><br>
<em>Wikipediaから引用<sup id="fnref:4"><a href="#fn:4" class="footnote-ref">3</a></sup></em></p><p>HSVカラーモデルは、いずれかの色チャンネルの1つで、画像の色を考える際に役立ちます。例えば画像の中で、青い色相の領域に同調する部分を探すのに適しています。</p><p>HSVの変化形がHSLカラーモデルで、色相、彩度、輝度から成り立っています。HSVによく似ていますが、彩度と3つ目のチャンネル（明度 対 輝度）の定義が異なります<sup id="fnref:2"><a href="#fn:2" class="footnote-ref">4</a></sup>。</p><p>グレースケール画像についても話していきましょう。最も暗い色（黒）を表す0、最も明るい色（白）を表す255といった、ピクセルの明るさを表現する256階調のスケールで、1つの色チャンネルしか持っていないのが、グレースケール画像です。</p><p>画像をグレースケールに変換すると、以下のような2次元の配列になります。</p><p>結果：</p><p>階調を変更することで、どのように色が変化するのか、<a href="http://colorizer.org/" rel="nofollow" title="" class="ext-link">カラーピッカー</a>を使って遊んでみるとよいでしょう。特に、HSVチャンネルの1つを変更した時のRGB値の変化を見るのは、面白いと思います。</p><p><strong>演習：</strong></p><p>ここで学んだことから、画像の平均色を割り出すことができます！　赤、緑、青の各チャンネルの平均値を割り出せば、ピクセルの色の平均値であるRGB値が求められます。では、<code>np.average()</code>を使ってこのRGB値を割り出した例を見ていきましょう。</p><p>結果：</p><p>Matpotlbに色を表示するために、このRGB値が追加された100 x 100ピクセルの小さな画像を作成する必要があります。</p><p>画像の平均色は何色でしょう？</p><p>画像情報を集める際、まず、興味のある特徴ごとに分割する必要があります。これを<strong>セグメンテーション</strong>と呼びます。画像セグメンテーションは、分析を容易にすることを目的に、意味を持たせるために画像を部分ごとに表示する処理のことです<sup id="fnref2:3"><a href="#fn:3" class="footnote-ref">2</a></sup>。</p><p>画像セグメンテーションの一番簡単な方法は、<strong>閾値処理</strong>です。閾値処理の基本的な考え方は、ピクセルのチャンネル値がある閾値を超えた場合は、画像の各ピクセルを白いピクセルに、超えなかった場合は、黒いピクセルに置き換えるという考えです。通常は、画像を<strong>2値画像、</strong>つまりシングルチャンネル画像に変換します。グレースケール画像は、シングルチャンネル画像の一例です。</p><p>結果：</p><p><img width="500" src="https://codewords.recurse.com/images/six/image-processing-101/image-binary-threshold.png"><br>
こうすると、明度の異なる部分を選ぶのが簡単になります。また、グレースケールではない画像にも利用できます。更に、色チャンネルを使って画像をセグメント分けすることも可能です。色の閾値処理はHSVで最も効果的です。HSVの色相チャンネルについて先ほど説明しましたが、赤から緑、緑から青、青から赤紫と移っていくスケールのどこにピクセルの色はあるのでしょうか？</p><p>閾値より低い値を探さなくても、<code>cv2.inRange()</code>を使えば、一定の色相の領域内に納まる部分を画像から見つけることができます。</p><p>結果：</p><p><img src="https://codewords.recurse.com/images/six/image-processing-101/piet.png"><br>
<em>元の画像</em></p><p><img src="https://codewords.recurse.com/images/six/image-processing-101/piet-thresh.png"><br>
<em>青い色相の閾値処理</em></p><p><strong>演習：</strong>どうやったら、この絵から赤、または黄の部分を取り出せるでしょうか。また、もし色の全色相を0から255で表すことができるとしたら、赤、または黄にどの範囲を使えばいいでしょうか。</p><p>色を区別できるようになったので、面白いことができます。例えば2値画像をマスクとして使ってみましょう。マスクとは、ビット演算で使われるゼロとゼロ以外の値の行列のことです。マスクを使うと、画像を切ったり、画像のある部分を”マスク”で隠したりできます。マスクは通常、ゼロの行列（消したい部分）と、ゼロ以外の行列（残したい部分）です。</p><p>それでは、屋外で撮った景色の画像から空を消したバージョンが欲しいとしましょう。その場合は、最初に、青い色相の領域に含まれるピクセルを見つけます。そうすると、1枚の画像の中から青い空の部分を区別できるようになるのです。空以外の部分の画像を取り出すには、<code>bitwise_not</code>を使って値が逆になるようにします。そうすると青以外の部分を残すマスクができます。マスク上で<code>bitwise_and</code>を使うと、画像の青以外の部分だけが残ります。</p><p>結果：</p><p><img src="https://codewords.recurse.com/images/six/image-processing-101/upstate-original.png"><br>
<em>元の画像</em></p><p><img src="https://codewords.recurse.com/images/six/image-processing-101/upstate-mask.png"><br>
<em>閾値を適用（マスク）</em></p><p><img src="https://codewords.recurse.com/images/six/image-processing-101/upstate-masked.png"><br>
<em>マスクを適用した画像</em></p><p>写真にノイズが多い場合があります。どういう意味かというと、セグメント分けの邪魔になる、小さい変則的な要素が画像に含まれている場合があるということです。この小さいノイズを取り除くためには、<strong>ガウスぼかし</strong>を使って画像の前処理をする方法がよく使われます。ぼかしは、明度差の大きい場合や、ピクセル間で激しい変化がある場合に、それらをスムーズにするものだと思ってください。</p><p>ガウスぼかしは、画像内の各ピクセルを変換することで効果を出します。これは、画像を正方形（n×n）の<strong>カーネル</strong>で<strong>畳み込む</strong>ことで行われます。畳み込みは、周りにあるn×nのピクセルの値に応じて、あるピクセルに操作を適用することだと思ってください。操作はカーネルによって決められます。つまり、5×5のカーネルでガウスぼかしを適用すると、全てのピクセルに対し周りの5×5のピクセルが考慮され、平均値を出す計算が行われます。そうして、新しくぼかされた色がピクセルに与えられるのです。ガウシアンカーネルサイズが大きいほど、画像のぼかしは強くなります。</p><p><img src="https://codewords.recurse.com/images/six/image-processing-101/oy.jpg"><br>
<em>元の画像（600px×450px）</em></p><p><img src="https://codewords.recurse.com/images/six/image-processing-101/oy-gaussian-blur-5.jpg"><br>
<em>5×5のカーネルでぼかしを適用</em></p><p><img src="https://codewords.recurse.com/images/six/image-processing-101/oy-gaussian-blur-15.jpg"><br>
<em>15×15のカーネルでぼかしを適用</em></p><p>ガウスぼかしは、画像にノイズが多く、閾値を適用する前に全ての変則的な要素をスムーズにしたい場合、特に有効です。</p><p>結果：<br>
<img src="https://codewords.recurse.com/images/six/image-processing-101/oy-no-blur-thresh.jpg"><br>
<em>元の画像に閾値を適用</em></p><p><img src="https://codewords.recurse.com/images/six/image-processing-101/oy-gaussian-blur-5-thresh.jpg"><br>
<em>5×5のカーネルでぼかした画像に閾値を適用</em></p><p>上は、ぼかしていない画像に閾値を適用した場合と、5×5のカーネルでぼかした画像に閾値を適用した場合を比較した例です。ぼかした方が、閾値の適用される塊のラインが明確になり、使いやすくなります。</p><p>単純化して2値化したバージョンの画像を作れるようになったので、関心のある特徴だけを区別することができます。例えば、下の画像から個々のコインを区別するにはどうしたらいいでしょうか。</p><p>このセクションでは、特徴でセグメント分けするために、<strong>輪郭</strong>と<strong>外接矩形</strong>を使う方法を説明します。</p><p><img width="600" src="https://codewords.recurse.com/images/six/image-processing-101/coins/coins-orig.jpg"><br>
<em>元の画像</em></p><p>最初に、画像をグレースケールに変換し、そこにガウスぼかしを適用して単純化とノイズの除去を行います。これは前処理の一般的な形式で、画像を扱う際は、大抵の場合、これを最初に行います。</p><p>それから、前処理を行った画像に2値化閾値処理を適用します。コインが明るい場所に置かれているため、閾値は明るい背景部分を関心のある特徴として取り出します。ですから、コインを取り出すために2値画像を反転させます。</p><p>結果：</p><p><img width="600" src="https://codewords.recurse.com/images/six/image-processing-101/coins/coins-binary.png"><br>
<em>前処理を行った2値画像</em></p><p>輪郭とは、境界線上で同じ色や明度を持つ全ての連続する点をつないだ曲線のことです。これは、形状の分析<sup id="fnref2:4"><a href="#fn:4" class="footnote-ref">3</a></sup>だけでなく、物体や特徴の検出をする際にも便利です。<code>cv2.findContours()</code>を使うと、それぞれのコインの輪郭を検出できます。これを<code>cv2.RETR_EXTERNAL</code>フラグの中で関数に渡すと、外郭だけが返されます。つまり、コイン表面の細かいディテールの輪郭までは取り出しません。</p><p>この外郭によって、それぞれのエリアを検出できるので、コインより小さなものをフィルタで取り除くことができます。実際に撮影される写真が完璧ということは、なかなかありません。ですから、ノイズや異物を取り除くために、このようなチェックが必要となることがよくあります。輪郭エリアを得るためには、<code>cv2.contourArea()</code>を使います。</p><p><code><br>
number of coins: 8<br>
</code></p><p>結果：</p><p><img width="600" src="https://codewords.recurse.com/images/six/image-processing-101/coins/coins-contour.jpg"><br>
<em>2値画像から得られたコインの輪郭</em></p><p>外接矩形とは、輪郭を含むことができる最も小さな長方形のことです。画像から個々のコインをセグメント分けするのに使うことができます。<code>cv2.boundingRect()</code>メソッドでは、長方形の左上の角のx座標とy座標、及びに幅と高さの値を外接矩形として返すことを覚えておいてください。また、8枚のコインを個別に取り出すために、外接矩形を使うこともできます。</p><p>結果：</p><p><img width="600" src="https://codewords.recurse.com/images/six/image-processing-101/coins/coins-bounding.jpg"><br>
<em>輪郭の外接ボックス</em></p><p>私たちが行った閾値による2値化のように、色や明度によるセグメンテーションでは十分ではない場合があります。多色使いの物体をセグメンテーションする必要がある場合はどうすればよいでしょうか。不均一な照明の下にある、青と黄のストライプのボウルについて考えてみましょう。ちなみに、その色は全体的に均一ではありません。</p><p>このような画像に使えるのが<strong>境界</strong>を見つけ出す方法である<strong>エッジ検出</strong>です。エッジは画像において輝度や明度が変化している部分の、点の集まりであると定義されます。通常これは、異なる物体間の境界を意味します。エッジ検出は画像処理の基本的な要素であり、特徴検出や特徴処理をする際に、まずここから始めることがよくあります<sup id="fnref:5"><a href="#fn:5" class="footnote-ref">5</a></sup>。</p><p>エッジ検出にはちょっとした計算が必要ですが、そこにはあまり触れないでおきましょう。エッジ検出の背景にある基本的な考え方は、画像内の輝度の変化は測定可能であるということです。この変化を<strong>勾配</strong>と言います。勾配の<strong>大きさ</strong>（変化がどのくらい急激に起きているか）と<strong>方向</strong>を測定することができます。点が集まっている箇所の、変化の大きさが所定の閾値を超えた場合、それが境界であると考えられます。</p><p><a href="https://www.wikiwand.com/en/Canny_edge_detector" rel="nofollow" title="" class="ext-link">キャニー法のアルゴリズム</a>は一般的なエッジ検出アルゴリズムであり、正確で鮮明なエッジを検出できます。以下のサンプルは、キャニー法のOpenCVの実装例で、同じ画像を閾値で2値化した画像と比較したものです。不均一な照明の下にある画像であるため、単純な閾値処理でボウルとカップの両方を捉えることはできないことに留意してください。</p><p><img width="600" src="https://codewords.recurse.com/images/six/image-processing-101/cups/cups-orig.jpg"><br>
<em>元の画像</em></p><p>標準的な技法として、画像を閾値処理する前にグレースケールとガウスぼかしで処理します。画像上部のティーカップを単純な閾値処理では捉えられないことに留意してください。ティーカップを捉えられるように閾値を調整して高い値にしたとしても、ボウルを捉えられなくなってしまいます。</p><p>結果：</p><p><img width="600" src="https://codewords.recurse.com/images/six/image-processing-101/cups/cups-thresh.png"><br>
<em>閾値を80に設定した2値画像。ティーカップを捉えられない。</em></p><p><img width="600" src="https://codewords.recurse.com/images/six/image-processing-101/cups/cups-thresh-hi.png"><br>
<em>閾値を200に設定した2値画像。ティーカップは捉えられるが、ボウルを捉えられない。</em></p><p>閾値処理ではなく、キャニー法で処理してみましょう。<code>cv2.Canny()</code>関数が2つの閾値をとることに留意してください。このアルゴリズムは、<a href="http://www.wikiwand.com/en/Canny_edge_detector#/Double_Threshold" rel="nofollow" title="" class="ext-link">二重の閾値</a>と呼ばれるものです。勾配の大きさが<code>threshold2</code>よりも大きい場合は、強い境界と判断されます。<code>threshold2</code>よりも小さく<code>threshold1</code>よりも大きい場合も、他の強い境界に接していれば、弱い境界であっても境界と考えられます。</p><p>結果：</p><p><img width="600" src="https://codewords.recurse.com/images/six/image-processing-101/cups/cups-edges.png"><br>
<em>キャニー法</em></p><p>キャニー法を使うと、単純な閾値処理では検出できないような画像の特徴を抽出する際に、より良い結果が得られます。</p><p>境界は非常に鮮明であり、面白い効果を生んでいますが、これによってどんなことができるでしょうか。</p><p>対象となる物体が線や円などの標準的な形態であれば、ハフ変換を利用して検出できます。</p><p><a href="https://www.wikiwand.com/ja/%E3%83%8F%E3%83%95%E5%A4%89%E6%8F%9B" rel="nofollow" title="" class="ext-link">直線を検出するハフ変換</a>は、複数の点を通る、直線の可能性のある線の候補を挙げることによって処理を行います。各線は<code>r</code>と<code>theta</code>の極座標の観点から、<code>r = x * cos (theta) + y * sin (theta)</code>と定義されます。もし直線の可能性があるものが、他にも十分な数の点を通っていれば、それは直線だと考えられます。</p><p>以下に、直線を検出するハフ変換の実例を挙げます。</p><p>結果：</p><p><img src="https://codewords.recurse.com/images/six/image-processing-101/cups/cups-edges.png"><br>
<em>エッジ</em></p><p><img src="https://codewords.recurse.com/images/six/image-processing-101/cups/cups-lines.jpg"><br>
<em>エッジから直線が検出される。</em></p><p><a href="https://www.wikiwand.com/en/Circle_Hough_Transform" rel="nofollow" title="" class="ext-link">円を検出するハフ変換</a>でも同じような処理を行います。ただし、<code>( x - a ) ^ 2 + ( y - b ) ^ 2 = r ^ 2</code>で定義される円の候補の要素となる<code>a</code>、<code>b</code>、<code>r</code>の全ての値を求めます。検索範囲が非常に広いので、範囲を限定するために理想的な境界を設定する必要があります（例えば、最小または最大の半径値を設定します）。</p><p>以下に円を検出するハフ変換の実例を挙げます。</p><p>結果：</p><p><img src="https://codewords.recurse.com/images/six/image-processing-101/cups/cups-edges.png"></p><p><em>エッジ</em><br>
<img src="https://codewords.recurse.com/images/six/image-processing-101/cups/cups-circles.jpg"><br>
<em>エッジから検出された円</em></p><p>ボウルから検出された円が1つだけであることに留意してください。これは円と円の距離<code>minDist</code>を最短に指定したからです。この距離は最低でも50ピクセル必要です。</p><p>実に素晴らしいですね。これで基本が分かったと思います。自分の画像処理のプロジェクトを考え始める上で、絶好のスタート地点に立てたのではないかと思います。まだプロジェクトを考えていないとしても、多様なパラメータを使って様々なOpenCVの機能を試してみるだけで、もっと使い方に慣れることができます。</p><p>こうした機能の処理について、より深く掘り下げたい方は（例えば、エッジ検出の実際の仕組みなど）、自分が選んだ言語で実装することで多くのことが学べます。例えば私は、<a href="https://github.com/piratefsh/image-processing" rel="nofollow" title="" class="ext-link">JavaScriptインプリメンテーション</a>を使ってみるまで、エッジ検出について十分に理解していませんでした。どうか数学を怖がらないでください。疑似コードを読めば大抵の場合、アルゴリズムの背景にある理論をよく理解できるでしょう。</p><p>Recurse CenterのファシリテーターであるJohn Workmanに感謝します。彼のおかげで画像処理について興味を持つようになりました。また、<a href="https://github.com/piratefsh/set-solver" rel="nofollow" title="" class="ext-link">Set Solver</a>では画像処理に関する多くの技術を学びましたが、そこで一緒に仕事をしたJesse GonzalezとMiriam Shiffmanに感謝します。</p><p>投稿で使用した写真は、但し書きがあるものを除いて私が所有するものです。</p><p><em><a href="https://piratefsh.github.io/" rel="nofollow" title="" class="ext-link">Sher Minn Chong</a>は、昼はフロントエンドを手掛けるWebデザイナーで、夜は画像処理とPythonに熱心に取り組んでいます。<a href="https://www.recurse.com/" rel="nofollow" title="" class="ext-link">Recurse Center</a>の2015年秋の第1期に参加しました。</em></p><p><em>編集：<a href="https://vpge.stanford.edu/people/timnit-gebru" rel="nofollow" title="" class="ext-link">Timnit Gebru</a></em></p>
