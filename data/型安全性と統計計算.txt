<p><a href="http://www.johnmyleswhite.com/notebook/2016/12/12/type-safety-and-statistical-computing/" rel="nofollow" title="" class="ext-link">Type Safety and Statistical Computing</a> （2016-12-12） by <a href="http://www.johnmyleswhite.com/" rel="nofollow" title="" class="ext-link">John Myles White</a></p><p>私は大ざっぱに言って、統計学のコミュニティはコンピュータサイエンスの概念にもっと触れた方が恩恵を得られると考えています。その考えを基に、本記事では、統計計算システムの振る舞いに関する規範論の展開に<a href="https://en.wikipedia.org/wiki/Type_safety" rel="nofollow" title="" class="ext-link">型安全性</a>の概念を用いる可能性を説明します。また、そのような規範論によって、現行システムの誤用のされ方を明確にできることも論じます。それとともに、統計向けのより型安全な言語を実装しようという現実的提案に立ちはだかる数々の難題についても述べていきます。</p><p><a href="http://www.cis.upenn.edu/~bcpierce/courses/629/papers/Saraswat-javabug.html" rel="nofollow" title="" class="ext-link">Vijay Saraswat</a>は、型安全な言語を以下のように定義しています。</p><p>個人的にはこの簡潔さは気に入っているのですが、いくつかの例を使って上記の定義を説明すれば多くの読者の皆さんに役立つでしょう。</p><p>まずは、コンピュータが結局は1つのハードウェアにすぎないことを思い出してください。（a）ビットに対する演算を実行することができ、（b）データをビットとして表現する他のハードウェアへのアクセスを許可されているハードウェアです。結局のところ、ハードウェアレベルでは、テキストファイルや音声ファイル、画像ファイルは単なるビットなのです。</p><p>あらゆる種類のデータは最終的に単なるビットの連続として表現されるので、そのようなビットの一解釈（例えば音声ファイルのFFTを計算する演算）にのみ意味を成す関数を、別の方法で解釈されるよう意図されたビットセット（例えばゲティスバーグ演説を表現するテキストファイル）に適用することが理論上は常に可能です。オーディオファイルであると判断したテキストファイルのFFTを合理的に解釈できないそうにないという事実は、その計算そのものが出来ないということにはなりません。</p><p>コンピュータサイエンスでこの問題を解決する典型的な方法は、各データについてより多くの情報をシステムに導入することです。具体的には、ゲティスバーグ演説を表現するビットを、「そのビットは文字列を表現しているので、音声や映像ではなくテキストと見なすべきである」ということを示す型と結びつけるのです。概して、型を持つプログラミング言語は、型情報を使って、ある種類のデータを処理するよう設計されたメソッドを、同じ方法では正しく処理できない非互換の種類のデータに適用できないよう保証することが可能です。</p><p>データに不適切な演算が実行されないことを保証するために型情報を使う言語は、ある程度、型安全性を志向しています。以下では、データを統計的に分析する既存のツールが概して型安全でないことを論じますが、統計向けの型安全な言語を作るのは大変な難題であろうことにも言及します。</p><p>3つの設定で整数のベクトルの平均を計算してみましょう。以下の設定は順に、「実行されている計算によって、計算の実行を求めている人の目的に応じた正しい結果が出る」という考えが正しいと証明するには、より強い仮定が必要となるように選んでいます。</p><p>最初のケースでは、整数のベクトルがあると仮定しましょう。具体的には、<code>v = [6, 6, 8, 7, 5]</code>というベクトルで、定義にはJulia風の記法を使っています。</p><p>この整数ベクトルの算術平均を純粋な記述統計量として計算したいとします。その計算は<code>descriptive_mean(v)</code>と表しましょう。算術平均は実数のベクトルに関する明確に定義された概念です。したがって、単純にベクトル内の数値を合計したものをそのベクトルの長さで割る関数は正しい記述統計量を返す、と考えていいでしょう。さらに、そのアルゴリズムの手法を取るコードによってどんな整数ベクトル（Julia風の記法で<code>Vector{Int}</code>とします）でも正しく扱われる、と信頼することができます。</p><p>記述統計量を計算するだけでなく、推測統計量を計算したいということもよくあります。推測統計量においては、分析されている数値のベクトル自体は調査の主対象ではありません。より大きな母集団から抽出された、調査の主対象を代表する無作為標本と見なせるという理由で分析されているにすぎません。</p><p>普通、任意の<code>Vector{Int}</code>を妥当な無作為標本と見なすことはできません。<code>v = [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]</code>というベクトルを渡されたとすると、このベクトルは本当に確率分布から抽出された無作為標本なのかと疑ってみるべきなのです。</p><p>言い換えると、正しい推測量として平均を計算するには、分析するデータが<code>Vector{Int}</code>より<code>IIDRandomSample{Int}</code>のような型を持つ必要があるということです。そのような型が存在すれば、<code>inferential_mean(v)</code>は型<code>IIDRandomSample{Int}</code>のデータにしか適用できないよう要求することで、型安全性の第1段階を実現できるかもしれません。</p><p>既存の統計計算システムで実行される多くの計算は、統計計算で使われている型システムでは通常コード化されていない仮定をした場合にのみ妥当であるということが、上記の例で明確になれば幸いです。このケースでは、<code>descriptive_mean(v)</code>と<code>inferential_mean(v)</code>は常に同じ出力を返します。型システムは、「<code>inferential_mean(v)</code>は他の観察されていない量の推定量として妥当な状態を持っていた」と仮定できるかのみをチェックするからです。しかし、<code>inferential_sem(v)</code>のような計算は、実際には、<code>IIDRandomSample{Int}</code>に対して、<code>KDependentRandomSample{Int}</code>などの場合とは違う結果を返します。そしてこうした異なる振る舞いは、次の例で提案するような規範になると思います。</p><p>より複雑なケースで、推測統計量としての単なる平均より複雑な計算をしたい場合はどうなるでしょうか。さらに、起こりそうな誤差の範囲を<code>inferential_mean_with_error_bound(v)</code>として得たいとしたら？　その場合は、数値のベクトルについてより強い仮定をする必要があります。なぜなら、<code>IIDRandomSample{Int}</code>を扱っていると仮定するだけではもはや不十分となるからです。</p><p>実は、標本平均の分布がだいたい正規分布になるぐらいベクトルの長さが大きい、ということも保証する必要があるのです。だいたい正規分布であるという仮定は通常、ベクトルの各要素の抽出元となった特定の分布にも、ベクトルの長さにも依存します。しかし、普通はその情報にアクセスできないので、こうした仮定を表現するのに信頼を持って型を使うことは通常できません。誤差範囲の正しさのためには型の妥当性が不可欠なのですが。</p><p>概して、統計的分析において必要となる仮定を全て型システムにコード化することは多分絶望的であり、結局は、統計理論の現在扱っている領域の境界線上にある確率論を型システムが理解する必要があるという話になりがちです。そういうわけで、任意の統計プログラムが十分正しいと証明するために型を使うことはた易い問題ではないという結論になりそうです。仮定をコード化した型を使って統計プログラムの明白なミスをいくつも発見できることは明らかなものの、捉えがたい深刻なミスは他にもたくさんあるのです。</p><p>以上3つの例が、統計計算における概念としての型安全性にまつわる難題を説明できていれば幸いです。上述のエラー束縛の問題から、型システムは応用統計学で必要となるような種類の仮定を表現することがどうしてもできない、と結論づける人もいるかもしれません。ただし、あらゆる仮定をコード化することができないからといって、いくつかの仮定をコード化しようと試みることが無駄だとは決めてかからない方がいいでしょう。</p><p>統計計算のためにより充実した型システムを開発すべきであると私が考える理由をもっと肯定的に論じるため、形式化すると役立ちそうに思われる概念を以下にいくつか挙げてみます。</p><p>多くの限界がありそうだとはいえ、仮定をより明示的にして、誤った仮定を少なくともユーザが全て示さなくても妥当でない分析が行われないようにすることで、型システムは統計計算をより安全にできる可能性があると、以上の例で明らかになれば幸いです。私の経験では、明示的にするとほぼ常に “マジック” より冗長となりますが、作者としてのデバッグやレビューアとしてのチェックははるかにやりやすくもなるのです。</p><p>それと同時に、統計計算向けの現行ツールの大部分は型安全な分析を保証するための試みをほとんど行っていないことが、読者の皆さんにお分かりいただければと思います。SQLやR、Python、Juliaで使われている型は、無作為標本や独立構造などについての関連概念をコード化していないのです。<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.sem.html" rel="nofollow" title="" class="ext-link">SciPy</a>の<code>sem</code>のような計算でさえ型安全ではありません（SciPyのドキュメントは、計算の正しさは入力配列がIID無作為標本であるという仮定に依存することにさえ言及していません）。</p><p>要するに、統計計算のための真に安全なツールが実現するのはまだまだ先のことになりそうです。型安全性の概念を活用することは、私たちのツールをいかにより安全にするか考えるための1つの方法ではないでしょうか。</p>
