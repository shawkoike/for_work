<p><a href="http://engineering.flipboard.com/2015/05/scaling-convnets/" rel="nofollow" title="" class="ext-link">Image Scaling using Deep Convolutional Neural Networks</a>（2015-05-06）By <a href="https://twitter.com/normantasfi" rel="nofollow" title="" class="ext-link">Norman Tasfi</a></p><p>この夏、私はカリフォルニア州パロアルトにあるFlipboardでインターンとして仕事をしました。私はそこで機械学習関係の問題に取り組んだのですが、その一つが画像のアップスケーリングでした。この記事では予備的結果を紹介し、また私たちのモデルとFlipboard製品への応用の仕方について議論していきたいと思います。</p><p>Flipboardのデザイン言語では、上質で印刷物のような仕上がりにすることが重要とされています。コンテンツ全体を通して、ユーザには安定感と美しさを楽しんでほしいと思っています。まるで自分専用に印刷された雑誌を手に持っているかのような体験を提供したいのです。このような体験を一貫して提供するというのは難しいことです。画像の質などといった様々な要素が、表示するコンテンツ全体の品質に大きく影響するのです。画像の質は、その画像のソースによって大きく変化します。フルブリード形式の、ページ全体に画像を載せる雑誌などでは、この画像の品質のばらつきが特に明確になります。</p><p>Webや携帯デバイスに画像を表示する場合、きちんと表示するには画像の品質が一定のラインを越えていなければなりません。私たちのWebプロダクト上の大きな画像を使えば、息をのむようなフルブリードのページを作成できます。</p><p><img src="http://engineering.flipboard.com/assets/convnets/good.png"><br>
<em>注釈：フルブリードの高品質な画像</em></p><p>解像度が低い画像は、100%を超えて拡大するとピクセレーションや過平滑化、アーティファクトを引き起こします。下の画像をご覧いただくと分かるように、これはフルブリードで表示する場合に最も顕著に表れます。この画像は私たちの製品における表示品質を大幅に低下させます。</p><p><img src="http://engineering.flipboard.com/assets/convnets/bad.png"><br>
<em>注釈：フルブリードの低品質な画像</em></p><p>原因は何でしょうか。一般的に、サイズXの画像をサイズYにしたい場合はスケーリングアルゴリズムを通さなければなりません。このアルゴリズムは、画像のピクセルを任意のサイズYにスケーリングするために数学的な演算を行うものです。用いられるアルゴリズムとしては、バイキュービック法、バイリニア法、ニアレストネイバー法などの補間法があります。上記に挙げたアルゴリズムの多くは、ピクセル値間の補間を行ってトランジションを作成します。これらのアルゴリズムは、周辺のピクセルを用いて新たな画像の中に何の値が入るべきかを推測します。画像をより大きなサイズにスケーリングする際に問題となるのは、画像中に埋めなくてはならない“新たな”値が多すぎる場合です。これらのアルゴリズムは、新たな値が何になるべきかを“推測”しなければならないのですが、そのせいで処理プロセスにノイズやハロー、アーティファクトといった誤差が生じる可能性が出てくるのです。</p><p>さらに先に進む前に、伝統的かつ畳み込みを取り入れたニューラルネットワークの概略をご紹介しておきたいと思います。これについてよくご存じの方は次の章に進んで頂いて結構です。ニューラルネットワークをご紹介したあとは、予備的結果、モデルアーキテクチャについての議論、デザインの決定、応用と続きます。</p><p>注意:今回の紹介の中では、ニューラルネットワークの種類ごとの微妙な違いについては説明していません。</p><p>ニューラルネットワークとは、与えられたデータから学習することが可能な素晴らしい型のモデルです。広範囲にわたって応用が可能で、コンピュータビジョンや音声認識、自然言語処理といった多くの分野で近年再び盛り上がりを見せています。最近では、<a href="http://googleresearch.blogspot.ca/2014/11/a-picture-is-worth-thousand-coherent.html" rel="nofollow" title="" class="ext-link">画像のキャプション付け</a>や<a href="http://www.forbes.com/sites/paulrodgers/2015/02/28/googles-deepmind-masters-atari-games/" rel="nofollow" title="" class="ext-link">Atariのゲーム</a>に使われ、<a href="http://blogs.nvidia.com/blog/2015/02/24/deep-learning-drive/" rel="nofollow" title="" class="ext-link">自動運転車の技術の一端を担い</a>、また<a href="http://104.131.78.120/" rel="nofollow" title="" class="ext-link">言語の翻訳</a>などにも用いられています。</p><p>ニューラルネットワークは<a href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="nofollow" title="" class="ext-link">畳み込み</a>や<a href="https://en.wikipedia.org/wiki/Recurrent_neural_network" rel="nofollow" title="" class="ext-link">再帰型</a>など様々な形で存在し、それぞれが違った類いのタスクを得意としています。“モデル”の学習も存在します。教師あり学習と教師なし学習がありますが、ここでは教師あり学習のみに焦点を当てていきたいと思います。</p><p><strong>教師あり学習</strong>は、入力と出力の両方について学習を行うネットワークと説明できます。この“モード”は、入力値を与えられた時に新たな出力値を予測するのに用いられます。例えば、何千枚もの猫と犬の写真に人間がラベル付けをし、それをネットワークに学習させて、新たな写真を提示しそれが猫なのか犬なのかを問う、というような学習法です。</p><p>構造レベルの話をすると、ニューラルネットワークはフィードフォワードの図式であり、ユニットとして知られる各ノードが入ってきた入力値について非線形演算を行うものです。各入力値がウエイトを持っており、ネットワークはバックプロパゲーションと呼ばれるアルゴリズムを通してこのウエイトを学習することができます。</p><p><img src="http://engineering.flipboard.com/assets/convnets/basic_nn.png"><br>
<em>注釈：基本のニューラルネットワーク<br>
　引用元：<a href="https://en.wikipedia.org/wiki/Artificial_neural_network#/media/File:Colored_neural_network.svg" rel="nofollow" title="" class="ext-link">Wikipedia</a></em></p><p>ニューラルネットワークの構造は柔軟で、目下のタスクを基にした構造をとります。属性を選択することで、簡単にネットワークをカスタマイズすることができるのです。属性の例としては、隠れ層（上の図では青のノード）の数、1層あたりのユニットの数、1ユニットあたりの結合の数などがあります。ハイパーパラメータと呼ばれるこれらの属性が、モデルの構造と振る舞いを描写します。高いパフォーマンスを得るためには、これらのパラメータを正しく選択することが非常に重要です。ハイパーパラメータは通常、無作為の<a href="https://en.wikipedia.org/wiki/Hyperparameter_optimization#Grid_search" rel="nofollow" title="" class="ext-link">グリッドサーチ</a>や最適化アルゴリズム（<a href="https://en.wikipedia.org/wiki/Bayesian_optimization" rel="nofollow" title="" class="ext-link">ベイズ</a>や<a href="http://www.scipy-lectures.org/advanced/mathematical_optimization/" rel="nofollow" title="" class="ext-link">勾配型</a>）、または単なる試行錯誤を通して選択されます。</p><p>先に述べたように、ネットワークの中のユニットは入力値について数学的演算を行います。ここでは、数個の入力値を持つ1つのユニットを例に取り、簡単な数字を入れて計算を行い、さらに理解を深めていきたいと思います。</p><p><img src="http://engineering.flipboard.com/assets/convnets/our_simple_nn.png"><br>
<em>注釈：簡単なモデル</em></p><p>上記のユニットは、<script type="math/tex"> \displaystyle x_1, x_2, x_3 </script>という3つの入力値と、スカラのバイアス項<script type="math/tex"> \displaystyle b </script> （表示されていません）をとります。この入力値のそれぞれが、<script type="math/tex"> \displaystyle w_1, w_2, w_3</script>と呼ばれる重み付けを持ちます。このウエイトは、入ってくる入力値の重要度を表します。この例では、ユニットの数学演算としてRectified Linear（ReL）関数を用います。もっと正式に言うと、活性化関数として知られるもので、下記のように表記されます。</p><p>この活性化関数で大事なのは、ゼロ未満の入力値は全てゼロとし、ゼロより大きいものはそのままの数であるということです。出力値の範囲は<span class="MathJax" id="MathJax-Element-6-Frame"><nobr><span class="math" id="MathJax-Span-86" role="math" style="width: 2.805em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.505em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.804em 1000em 3.106em -999.997em); top: -2.7em; left: 0.003em;"><span class="mrow" id="MathJax-Span-87"><span class="mstyle" id="MathJax-Span-88"><span class="mrow" id="MathJax-Span-89"><span class="mo" id="MathJax-Span-90" style="font-family: MathJax_Main;">[</span><span class="mn" id="MathJax-Span-91" style="font-family: MathJax_Main;">0</span><span class="mo" id="MathJax-Span-92" style="font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-93" style="font-family: MathJax_Main; padding-left: 0.153em;">∞</span><span class="mo" id="MathJax-Span-94" style="font-family: MathJax_Main;">]</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.705em;"></span></span></span><span style="border-left-width: 0.003em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 1.225em; vertical-align: -0.331em;"></span></span></nobr></span>となります。<a href="https://ja.wikipedia.org/wiki/%E3%82%B7%E3%82%B0%E3%83%A2%E3%82%A4%E3%83%89%E9%96%A2%E6%95%B0" rel="nofollow" title="" class="ext-link">シグモイド</a>、<a href="http://mathworld.wolfram.com/HyperbolicTangent.html" rel="nofollow" title="" class="ext-link">双曲線正接</a>、<a href="http://arxiv.org/abs/1302.4389" rel="nofollow" title="" class="ext-link">maxout</a>など、他の活性化関数を使うこともできます。<br>
では出力値はどのように計算するのでしょうか。これには<span class="MathJax" id="MathJax-Element-7-Frame"><nobr><span class="math" id="MathJax-Span-95" role="math" style="width: 5.808em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.208em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.654em 1000em 3.106em -999.997em); top: -2.7em; left: 0.003em;"><span class="mrow" id="MathJax-Span-96"><span class="mstyle" id="MathJax-Span-97"><span class="mrow" id="MathJax-Span-98"><span class="mi" id="MathJax-Span-99" style="font-family: MathJax_Math-italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.053em;"></span></span><span class="mo" id="MathJax-Span-100" style="font-family: MathJax_Main;">(</span><span class="msubsup" id="MathJax-Span-101"><span style="display: inline-block; position: relative; width: 1.704em; height: 0px;"><span style="position: absolute; clip: rect(3.156em 1000em 4.157em -999.997em); top: -4.002em; left: 0.003em;"><span class="mi" id="MathJax-Span-102" style="font-family: MathJax_Math-italic;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.103em;"></span></span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span><span style="position: absolute; top: -4.402em; left: 1.154em;"><span class="mi" id="MathJax-Span-103" style="font-size: 70.7%; font-family: MathJax_Math-italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.103em;"></span></span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span></span></span><span class="mi" id="MathJax-Span-104" style="font-family: MathJax_Math-italic;">x</span><span class="mo" id="MathJax-Span-105" style="font-family: MathJax_Main; padding-left: 0.203em;">+</span><span class="mi" id="MathJax-Span-106" style="font-family: MathJax_Math-italic; padding-left: 0.203em;">b</span><span class="mo" id="MathJax-Span-107" style="font-family: MathJax_Main;">)</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.705em;"></span></span></span><span style="border-left-width: 0.003em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 1.392em; vertical-align: -0.331em;"></span></span></nobr></span> という計算をする必要があります。まず初めに<span class="MathJax" id="MathJax-Element-10-Frame"><nobr><span class="math" id="MathJax-Span-119" role="math" style="width: 2.555em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.305em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.404em 1000em 2.605em -999.997em); top: -2.45em; left: 0.003em;"><span class="mrow" id="MathJax-Span-120"><span class="mstyle" id="MathJax-Span-121"><span class="mrow" id="MathJax-Span-122"><span class="msubsup" id="MathJax-Span-123"><span style="display: inline-block; position: relative; width: 1.704em; height: 0px;"><span style="position: absolute; clip: rect(3.156em 1000em 4.157em -999.997em); top: -4.002em; left: 0.003em;"><span class="mi" id="MathJax-Span-124" style="font-family: MathJax_Math-italic;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.103em;"></span></span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span><span style="position: absolute; top: -4.402em; left: 1.154em;"><span class="mi" id="MathJax-Span-125" style="font-size: 70.7%; font-family: MathJax_Math-italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.103em;"></span></span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span></span></span><span class="mi" id="MathJax-Span-126" style="font-family: MathJax_Math-italic;">x</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.455em;"></span></span></span><span style="border-left-width: 0.003em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 1.114em; vertical-align: -0.053em;"></span></span></nobr></span>と定義される転置<span class="MathJax" id="MathJax-Element-8-Frame"><nobr><span class="math" id="MathJax-Span-108" role="math" style="width: 1.204em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.054em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.604em 1000em 2.605em -999.997em); top: -2.45em; left: 0.003em;"><span class="mrow" id="MathJax-Span-109"><span class="mstyle" id="MathJax-Span-110"><span class="mrow" id="MathJax-Span-111"><span class="mi" id="MathJax-Span-112" style="font-family: MathJax_Math-italic;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.103em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.455em;"></span></span></span><span style="border-left-width: 0.003em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 0.892em; vertical-align: -0.053em;"></span></span></nobr></span>と<span class="MathJax" id="MathJax-Element-9-Frame"><nobr><span class="math" id="MathJax-Span-113" role="math" style="width: 0.953em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.853em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(2.105em 1000em 3.056em -999.997em); top: -2.7em; left: 0.003em;"><span class="mrow" id="MathJax-Span-114"><span class="mstyle" id="MathJax-Span-115"><span class="mrow" id="MathJax-Span-116"><span class="mi" id="MathJax-Span-117" style="font-family: MathJax_Math-italic;">x</span><span class="mo" id="MathJax-Span-118" style="font-family: MathJax_Main;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.705em;"></span></span></span><span style="border-left-width: 0.003em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 0.836em; vertical-align: -0.275em;"></span></span></nobr></span>間のベクトル積を計算します。続いてこの結果にバイアス値を加算し、最後に活性化関数を通します。</p><p>この例をもう少し具体的に考えるために、ランダムな値を使ってみましょう。以下のように、ウエイト、入力値、そしてスカラのバイアス値に対応したベクトルがあるとしましょう。</p><p>順に値を代入していくことで、<span class="MathJax" id="MathJax-Element-12-Frame"><nobr><span class="math" id="MathJax-Span-154" role="math" style="width: 2.555em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.305em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.404em 1000em 2.605em -999.997em); top: -2.45em; left: 0.003em;"><span class="mrow" id="MathJax-Span-155"><span class="mstyle" id="MathJax-Span-156"><span class="mrow" id="MathJax-Span-157"><span class="msubsup" id="MathJax-Span-158"><span style="display: inline-block; position: relative; width: 1.704em; height: 0px;"><span style="position: absolute; clip: rect(3.156em 1000em 4.157em -999.997em); top: -4.002em; left: 0.003em;"><span class="mi" id="MathJax-Span-159" style="font-family: MathJax_Math-italic;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.103em;"></span></span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span><span style="position: absolute; top: -4.402em; left: 1.154em;"><span class="mi" id="MathJax-Span-160" style="font-size: 70.7%; font-family: MathJax_Math-italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.103em;"></span></span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span></span></span><span class="mi" id="MathJax-Span-161" style="font-family: MathJax_Math-italic;">x</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.455em;"></span></span></span><span style="border-left-width: 0.003em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 1.114em; vertical-align: -0.053em;"></span></span></nobr></span>の値を算出します。</p><p>次にバイアス値を加えて、<span class="MathJax" id="MathJax-Element-14-Frame"><nobr><span class="math" id="MathJax-Span-182" role="math" style="width: 4.357em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.906em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.654em 1000em 2.955em -999.997em); top: -2.7em; left: 0.003em;"><span class="mrow" id="MathJax-Span-183"><span class="mstyle" id="MathJax-Span-184"><span class="mrow" id="MathJax-Span-185"><span class="msubsup" id="MathJax-Span-186"><span style="display: inline-block; position: relative; width: 1.704em; height: 0px;"><span style="position: absolute; clip: rect(3.156em 1000em 4.157em -999.997em); top: -4.002em; left: 0.003em;"><span class="mi" id="MathJax-Span-187" style="font-family: MathJax_Math-italic;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.103em;"></span></span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span><span style="position: absolute; top: -4.402em; left: 1.154em;"><span class="mi" id="MathJax-Span-188" style="font-size: 70.7%; font-family: MathJax_Math-italic;">T<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.103em;"></span></span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span></span></span><span class="mi" id="MathJax-Span-189" style="font-family: MathJax_Math-italic;">x</span><span class="mo" id="MathJax-Span-190" style="font-family: MathJax_Main; padding-left: 0.203em;">+</span><span class="mi" id="MathJax-Span-191" style="font-family: MathJax_Math-italic; padding-left: 0.203em;">b</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.705em;"></span></span></span><span style="border-left-width: 0.003em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 1.169em; vertical-align: -0.164em;"></span></span></nobr></span>をします。</p><p>さらに、この計算結果を活性化関数である<span class="MathJax" id="MathJax-Element-16-Frame"><nobr><span class="math" id="MathJax-Span-201" role="math" style="width: 2.105em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.904em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.804em 1000em 3.106em -999.997em); top: -2.7em; left: 0.003em;"><span class="mrow" id="MathJax-Span-202"><span class="mstyle" id="MathJax-Span-203"><span class="mrow" id="MathJax-Span-204"><span class="mi" id="MathJax-Span-205" style="font-family: MathJax_Math-italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.053em;"></span></span><span class="mo" id="MathJax-Span-206" style="font-family: MathJax_Main;">(</span><span class="mi" id="MathJax-Span-207" style="font-family: MathJax_Math-italic;">x</span><span class="mo" id="MathJax-Span-208" style="font-family: MathJax_Main;">)</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.705em;"></span></span></span><span style="border-left-width: 0.003em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 1.225em; vertical-align: -0.331em;"></span></span></nobr></span>に適用します。</p><p>定義した関数によると、xが0より大きい場合は関数の値がxとなりますので、今回の場合は3.54が得られます。</p><p>この関数に心躍らされる理由は何でしょう。とは言っても、例に挙げた1ユニットのみを見ただけでは、それほど心躍る内容ではありませんね。今のところ、関数における最も基礎的な部分のみをモデル化するために、ウエイトとバイアス値を微調整しています。先ほどまで見てきた例は、“表現力”が欠けています。では、“表現力”を高めるために、ユニット同士をつないで関連づけ、以下に示すような、より大きなネットワークを考えてみましょう。</p><p><img src="http://engineering.flipboard.com/assets/convnets/our_complex_nn.png"><br>
<em>注釈：より大きなネットワーク</em></p><p><span class="MathJax" id="MathJax-Element-18-Frame"><nobr><span class="math" id="MathJax-Span-219" role="math" style="width: 3.956em; display: inline-block;"><span style="display: inline-block; position: relative; width: 3.556em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.254em 1000em 2.555em -999.997em); top: -2.1em; left: 0.003em;"><span class="mrow" id="MathJax-Span-220"><span class="mstyle" id="MathJax-Span-221"><span class="mrow" id="MathJax-Span-222"><span class="msubsup" id="MathJax-Span-223"><span style="display: inline-block; position: relative; width: 3.506em; height: 0px;"><span style="position: absolute; clip: rect(3.156em 1000em 4.157em -999.997em); top: -4.002em; left: 0.003em;"><span class="mi" id="MathJax-Span-224" style="font-family: MathJax_Math-italic;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.103em;"></span></span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span><span style="position: absolute; top: -3.851em; left: 0.953em;"><span class="texatom" id="MathJax-Span-225"><span class="mrow" id="MathJax-Span-226"><span class="mi" id="MathJax-Span-227" style="font-size: 70.7%; font-family: MathJax_Math-italic;">f<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.053em;"></span></span><span class="mi" id="MathJax-Span-228" style="font-size: 70.7%; font-family: MathJax_Math-italic;">r</span><span class="mi" id="MathJax-Span-229" style="font-size: 70.7%; font-family: MathJax_Math-italic;">o</span><span class="mi" id="MathJax-Span-230" style="font-size: 70.7%; font-family: MathJax_Math-italic;">m</span><span class="mo" id="MathJax-Span-231" style="font-size: 70.7%; font-family: MathJax_Main;">,</span><span class="mi" id="MathJax-Span-232" style="font-size: 70.7%; font-family: MathJax_Math-italic;">t</span><span class="mi" id="MathJax-Span-233" style="font-size: 70.7%; font-family: MathJax_Math-italic;">o</span></span></span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.105em;"></span></span></span><span style="border-left-width: 0.003em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 1.225em; vertical-align: -0.386em;"></span></span></nobr></span>は1つのユニットから他のユニットへ移っていくウエイトの値を示しており、上記におけるネットワークの方程式は以下のように表記できます。</p><p><span class="MathJax" id="MathJax-Element-20-Frame"><nobr><span class="math" id="MathJax-Span-303" role="math" style="width: 1.054em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.953em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.504em 1000em 2.405em -999.997em); top: -2.1em; left: 0.003em;"><span class="mrow" id="MathJax-Span-304"><span class="mstyle" id="MathJax-Span-305"><span class="mrow" id="MathJax-Span-306"><span class="msubsup" id="MathJax-Span-307"><span style="display: inline-block; position: relative; width: 0.903em; height: 0px;"><span style="position: absolute; clip: rect(3.406em 1000em 4.157em -999.997em); top: -4.002em; left: 0.003em;"><span class="mi" id="MathJax-Span-308" style="font-family: MathJax_Math-italic;">z<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span><span style="position: absolute; top: -3.851em; left: 0.453em;"><span class="mn" id="MathJax-Span-309" style="font-size: 70.7%; font-family: MathJax_Main;">1</span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.105em;"></span></span></span><span style="border-left-width: 0.003em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 0.781em; vertical-align: -0.219em;"></span></span></nobr></span>は先ほど計算した方程式と同じものです。複雑なネットワークを作るために、どのようにユニット同士をつなげたか分かりますか？　ここでは同じ計算を何度も繰り返し適用していきます。前の層で計算した結果の出力値を、その次の層に適用していくのです。最終層に到達するまで、ネットワークを値が伝播していきます。このプロセスがフォワードプロパゲーションです。しかし、このプロセスはウエイトやバイアスに何の補正も加えないので、ネットワークの出力値を変える必要がある場合は、ほとんど役立ちません。</p><p>ネットワークのウエイトやバイアスを変更するには、バックプロパゲーションとして知られているアルゴリズムを使います。では、入力値であるxと、期待される出力値yというデータセットをネットワークに与えた場合の、教師あり学習に焦点を当ててみましょう。教師あり学習でバックプロパゲーションを使う場合は、ネットワークのパフォーマンスを定量化する必要があります。ネットワークを通ってきたフォワードプロパゲーションの結果である<span class="MathJax" id="MathJax-Element-21-Frame"><nobr><span class="math" id="MathJax-Span-310" role="math" style="width: 0.753em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.653em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.204em 1000em 2.455em -999.997em); top: -2.1em; left: 0.003em;"><span class="mrow" id="MathJax-Span-311"><span class="mstyle" id="MathJax-Span-312"><span class="mrow" id="MathJax-Span-313"><span class="texatom" id="MathJax-Span-314"><span class="mrow" id="MathJax-Span-315"><span class="munderover" id="MathJax-Span-316"><span style="display: inline-block; position: relative; width: 0.603em; height: 0px;"><span style="position: absolute; clip: rect(3.406em 1000em 4.357em -999.997em); top: -4.002em; left: 0.003em;"><span class="mi" id="MathJax-Span-317" style="font-family: MathJax_Math-italic;">y<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span><span style="position: absolute; clip: rect(3.156em 1000em 3.606em -999.997em); top: -4.052em; left: 0.103em;"><span class="mo" id="MathJax-Span-318" style="font-family: MathJax_Main;">^</span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span></span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.105em;"></span></span></span><span style="border-left-width: 0.003em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 1.169em; vertical-align: -0.275em;"></span></span></nobr></span>（推定値）と期待値である<span class="MathJax" id="MathJax-Element-22-Frame"><nobr><span class="math" id="MathJax-Span-319" role="math" style="width: 0.553em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.503em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.854em 1000em 2.805em -999.997em); top: -2.45em; left: 0.003em;"><span class="mrow" id="MathJax-Span-320"><span class="mstyle" id="MathJax-Span-321"><span class="mrow" id="MathJax-Span-322"><span class="mi" id="MathJax-Span-323" style="font-family: MathJax_Math-italic;">y<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.455em;"></span></span></span><span style="border-left-width: 0.003em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 0.836em; vertical-align: -0.275em;"></span></span></nobr></span>の値を比較する誤差を定義しなければならないのです。</p><p>この値同士の比較は、正式にはコスト関数として知られています。他の方法で定義することもできますが、この記事では以下の通り平均二乗誤差の関数を使いましょう。</p><p>この関数を使えば、誤差の大きさを算出できます。ランダムに初期化されたウエイトやバイアスがネットワークに与えられた場合、出力値は期待値であるyの値からかけ離れたものになり、<span class="MathJax" id="MathJax-Element-24-Frame"><nobr><span class="math" id="MathJax-Span-360" role="math" style="width: 2.905em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.605em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.254em 1000em 2.405em -999.997em); top: -2.1em; left: 0.003em;"><span class="mrow" id="MathJax-Span-361"><span class="mstyle" id="MathJax-Span-362"><span class="mrow" id="MathJax-Span-363"><span class="msubsup" id="MathJax-Span-364"><span style="display: inline-block; position: relative; width: 2.555em; height: 0px;"><span style="position: absolute; clip: rect(3.156em 1000em 4.157em -999.997em); top: -4.002em; left: 0.003em;"><span class="mi" id="MathJax-Span-365" style="font-family: MathJax_Math-italic;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.053em;"></span></span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span><span style="position: absolute; top: -3.851em; left: 0.753em;"><span class="texatom" id="MathJax-Span-366"><span class="mrow" id="MathJax-Span-367"><span class="mi" id="MathJax-Span-368" style="font-size: 70.7%; font-family: MathJax_Math-italic;">M<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.053em;"></span></span><span class="mi" id="MathJax-Span-369" style="font-size: 70.7%; font-family: MathJax_Math-italic;">S<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-370" style="font-size: 70.7%; font-family: MathJax_Math-italic;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.105em;"></span></span></span><span style="border-left-width: 0.003em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 1.058em; vertical-align: -0.219em;"></span></span></nobr></span>からの出力値は大きくなるでしょう。</p><p><strong>バックプロパゲーション</strong>では、この誤差の大きさを使い、ネットワークの後方から前方までウエイトとバイアスを補正しながら値を伝播させていきます。各ウエイトとバイアスについて補正した量は、誤差への寄与として扱われ、<a href="https://ja.wikipedia.org/wiki/%E6%9C%80%E6%80%A5%E9%99%8D%E4%B8%8B%E6%B3%95" rel="nofollow" title="" class="ext-link">最急降下法</a>で計算されます。このアルゴリズムで、ウエイトとバイアスの値を変更することにより、誤差関数の値を最小化しようとしているのです。</p><p>入力値としてベクトルxが与えられ、出力値の期待値がyの場合、ニューラルネットワークを開発する一般的なプロセスは以下の通りです。</p><p>上記の手順は、ネットワークのウエイトとバイアスの誤差が可能な限り最小になるまで、異なるxとyの組み合わせを使って、何度も繰り返し行われます。<span class="MathJax" id="MathJax-Element-27-Frame"><nobr><span class="math" id="MathJax-Span-416" role="math" style="width: 2.905em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.605em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.254em 1000em 2.405em -999.997em); top: -2.1em; left: 0.003em;"><span class="mrow" id="MathJax-Span-417"><span class="mstyle" id="MathJax-Span-418"><span class="mrow" id="MathJax-Span-419"><span class="msubsup" id="MathJax-Span-420"><span style="display: inline-block; position: relative; width: 2.555em; height: 0px;"><span style="position: absolute; clip: rect(3.156em 1000em 4.157em -999.997em); top: -4.002em; left: 0.003em;"><span class="mi" id="MathJax-Span-421" style="font-family: MathJax_Math-italic;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.053em;"></span></span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span><span style="position: absolute; top: -3.851em; left: 0.753em;"><span class="texatom" id="MathJax-Span-422"><span class="mrow" id="MathJax-Span-423"><span class="mi" id="MathJax-Span-424" style="font-size: 70.7%; font-family: MathJax_Math-italic;">M<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.053em;"></span></span><span class="mi" id="MathJax-Span-425" style="font-size: 70.7%; font-family: MathJax_Math-italic;">S<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span><span class="mi" id="MathJax-Span-426" style="font-size: 70.7%; font-family: MathJax_Math-italic;">E<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.003em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.105em;"></span></span></span><span style="border-left-width: 0.003em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 1.058em; vertical-align: -0.219em;"></span></span></nobr></span>関数を最小化するのです。</p><p>あなたが最近の技術的な記事に注意を払っているとすれば、ニューラルネットワークが複数の領域において最先端の技術を発展させているという話題を耳にしたことがあるでしょう。畳み込みニューラルネットワークのほんの小さな一部分が、これらのブレイクスルーをもたらしています。</p><p>畳み込みニュートラルネットワーク（ConvNets）は、典型的な順伝播型ニュートラルネットワークとは少しばかり特徴が異なります。ConvNetsは視覚野から生物学的なインスピレーションを得ます。視覚野には、視野の小区域に対し敏感な小さな細胞の集まりも含まれており、これは受容野と呼ばれます。この受容野の挙動は、行列の形で重み付けを学習することで模倣できます。この行列は”カーネル”と呼ばれ、生物学的に受容野が果たす役割と同様に、ある画像の類似した小区域に対して敏感になります。今度は、カーネルと小区域との間の類似性を表す方法が必要になります。畳み込み演算が2つの信号の間で、適切な“類似性”を効果的に返してくるので、私たちは画像の小区域とともに覚えたカーネルを首尾よく通すことができます。この演算を通して、私たちは適切な類似性を返すことができるのです。</p><p>以下はカーネルを表したアニメーションです。黄色は画像上に畳み込まれたもの、緑は、右側に赤で書かれた演算の結果と一緒です。</p><p><img src="http://engineering.flipboard.com/assets/convnets/Convolution_schematic.gif"><br>
<em>注釈：畳み込み演算を表したアニメーション<br>
引用元：スタンフォード大学ディープランニングから<a href="http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution" rel="nofollow" title="" class="ext-link">Feature extraction using convolution</a></em></p><p>これを説明するために、画像上のエッジ方向を検出するとてもシンプルな正方形のカーネルを実行しましょう。カーネルのウエイトは以下で表されます。</p><p>カーネルを使用している畳み込み演算を左の画像について何度か実行すると、右の画像が得られます。</p><p><img src="http://engineering.flipboard.com/assets/convnets/conv_output.jpg"></p><p><em>注釈:畳み込み演算についてのアニメーション。<br>
引用元：<a href="http://www.catenary.com/howto/diagedge.html" rel="nofollow" title="" class="ext-link">Edge Detection with Matrix Convolution</a></em></p><p>どうしてこれが有効なのでしょうか？　ニューラルネットワークのコンテキストでは、いくつかの理由があります。</p><p>まず、右の画像上から情報を引き出すことが可能になります。カーネルはエッジ方向の存在と位置の情報を私たちに教えてくれます。ニュートラルネットワークで使用することで、画僧の基本的な特徴(エッジや勾配、ぼかし具合など)を抽出するための、カーネルの適切な重み付けを学習することができます。ネットワークが十分な深さの畳み込み層を持っていれば、前の層における特徴の組み合わせを学習し始めます。前述のエッジ・勾配・ぼかし具合といった基本的な構成要素が、後ろの層では目や鼻、髪に変わるのです。</p><p><img src="http://engineering.flipboard.com/assets/convnets/yann_filters.png"></p><p><em>注釈：高水準の表現を初期の層から作り上げているカーネル。<br>
引用元：<a href="http://www.cs.nyu.edu/~yann/talks/lecun-ranzato-icml2013.pdf" rel="nofollow" title="" class="ext-link">Yann LecunによるディープラニングのICML 2013チュートリアル</a></em></p><p>慣習的に言えることは、画像や音声を扱う分野で仕事をしたいならば、使用可能な形にデータを前処理するために、別のアルゴリズムを利用して特徴を生成しなければならないことです。これによって、機械学習アルゴリズムは、入って来るデータを理解するために選択できるようになります。このプロセスは冗長的で、もろいものです。畳み込みフロントエンドをネットワークに適用することによって、アルゴリズムに、私たちの持っている側のデータを最小限に前処理するだけで、その特定の領域と状況のために最も効果的に働く特徴を作らせることができます。ネットワークは、単独で特徴を抽出します。ネットワークで学習された特徴は、アルゴリズムや手動で設計された特徴より、よく機能するものがほとんどです。</p><p>以下はモデルから作られた予備的結果です。左の画像は、オリジナルの“高い”解像度です。グランドトルースであり、私たちが望む完璧な復元の画像です。1/2でオリジナルを縮小し、バイキュービック法とニューラルネットワークモデルを通して復元しました。結果は、それぞれ中央と右側に出ます。</p><p><img class="img-responsive" src="http://engineering.flipboard.com/assets/convnets/results/human_orig.jpg"><br>
<em>注釈:オリジナル</em></p><p><img class="img-responsive" src="http://engineering.flipboard.com/assets/convnets/results/human_bicubic.jpg"><br>
<em>注釈:バイキュービック法</em></p><p><img class="img-responsive" src="http://engineering.flipboard.com/assets/convnets/results/human_model.jpg"><br>
<em>注釈:ニューラルネットワークモデル</em></p><p>主な違いは髪の生え際、眉毛、ほほと額の肌の部分に見られます。</p><p><img class="img-responsive" src="http://engineering.flipboard.com/assets/convnets/results/building_orig.jpg"><br>
<em>注釈:オリジナル</em></p><p><img class="img-responsive" src="http://engineering.flipboard.com/assets/convnets/results/building_bicubic.jpg"><br>
<em>注釈:バイキュービック法<br>
<img class="img-responsive" src="http://engineering.flipboard.com/assets/convnets/results/building_model.jpg"><br>
*注釈:ニューラルネットワークモデル</em></p><p>ニューラルネットワークモデルはバルコニーや前景の日焼け用ベッドのハードエッジに沿って、うまく機能しています。</p><p><img class="img-responsive" src="http://engineering.flipboard.com/assets/convnets/results/puppy_orig.jpg"><br>
<em>注釈:オリジナル</em></p><p><img class="img-responsive" src="http://engineering.flipboard.com/assets/convnets/results/puppy_bicubic.jpg"><br>
<em>注釈:バイキュービック法</em></p><p><img class="img-responsive" src="http://engineering.flipboard.com/assets/convnets/results/puppy_model.jpg"><br>
<em>注釈:ニューラルネットワークモデル</em></p><p>初見では分かりづらい例でしょう。耳側の毛の流れや耳の中の毛といった細部がモデルでは見て取れます。</p><p><img class="img-responsive" src="http://engineering.flipboard.com/assets/convnets/results/lenna_orig.jpg"><br>
<em>注釈:オリジナル</em></p><p><img class="img-responsive" src="http://engineering.flipboard.com/assets/convnets/results/lenna_bicubic.jpg"><br>
<em>注釈:バイキュービック法</em></p><p><img class="img-responsive" src="http://engineering.flipboard.com/assets/convnets/results/lenna_model.jpg"><br>
<em>注釈:ニューラルネットワークモデル</em></p><p>Lennaの画像を処理対象に含めずして、画像に関連する仕事を終えるわけにはいきません。羽、鼻、唇と目の鋭さをよく見てください。帽子のパターンも、モデルの出力でよく表されています。</p><p><img class="img-responsive" src="http://engineering.flipboard.com/assets/convnets/results/forest_orig.jpg"><br>
<em>注釈:オリジナル</em></p><p><img class="img-responsive" src="http://engineering.flipboard.com/assets/convnets/results/forest_bicubic.jpg"><br>
<em>注釈:バイキュービック法</em></p><p><img class="img-responsive" src="http://engineering.flipboard.com/assets/convnets/results/forest_model.jpg"><br>
<em>注釈:ニューラルネットワークモデル</em></p><p>主な違いは、葉っぱや影の形、木目などに現れています。</p><p>以下の図は、私たちが使用したアーキテクチャの一つで、主な目的は、画像から取り入れられたピクセル数を倍にすることです。この構造は8層のニューラルネットワークになっていて、ピンク色がかったブロックの積み重ねで表示されている3つの畳み込み層と、青色をした4つの全結合層で構成されています。各層は、ReL活性化関数を使用しており、図には表示されていませんが、最後に線形ガウスユニットである緻密層があります。</p><p><img src="http://engineering.flipboard.com/assets/convnets/architecture.png"></p><p>入力画像の小部分は、最初の畳み込み層を通って取り込まれています。この画像は、正方形のスライディングウィンドウを使ってより大きな画像から取り入れられたものです。そして、最初の畳み込み層には最大数のフィルタマップが含まれています。最初の2つの全結合層を通って高次元として”再出力”された出力画像は、更に次の2つの畳み込み層によって処理が行われます。この畳み込み層で抽出された特徴は、一連の全結合層に送り込まれます。そして、最終的な出力画像は、線形ガウスの層によって算出されます。</p><p>ここでは、畳み込み層の後に、プーリング演算は行っていません。プーリング演算は入力に対する不変性が重要な分類タスクには有用なのですが、このタスクで重要なのは各カーネルで検知される特徴の位置だからです。また、プーリングはこのユースケースで必要となる有益な情報を必要以上に削除してしまうので、そういった意味でも採用しませんでした。</p><p>ウエイトは、<a href="http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf" rel="nofollow" title="" class="ext-link">Glorot &amp; Benigoによって推奨されているXavier initialization</a>で全て初期化され、ハイパーパラメータの最適化を行っている間、微調整されています。これは、<span class="MathJax" id="MathJax-Element-29-Frame"><nobr><span class="math" id="MathJax-Span-463" role="math" style="width: 5.058em; display: inline-block;"><span style="display: inline-block; position: relative; width: 4.557em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(0.603em 1000em 3.106em -999.997em); top: -2.1em; left: 0.003em;"><span class="mrow" id="MathJax-Span-464"><span class="mstyle" id="MathJax-Span-465"><span class="mrow" id="MathJax-Span-466"><span class="mfrac" id="MathJax-Span-467"><span style="display: inline-block; position: relative; width: 4.307em; height: 0px; margin-right: 0.103em; margin-left: 0.103em;"><span style="position: absolute; clip: rect(3.206em 1000em 4.157em -999.997em); top: -4.702em; left: 50%; margin-left: -0.248em;"><span class="mn" id="MathJax-Span-468" style="font-family: MathJax_Main;">2</span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span><span style="position: absolute; clip: rect(3.256em 1000em 4.307em -999.997em); top: -3.301em; left: 50%; margin-left: -2.1em;"><span class="mrow" id="MathJax-Span-469"><span class="msubsup" id="MathJax-Span-470"><span style="display: inline-block; position: relative; width: 1.354em; height: 0px;"><span style="position: absolute; clip: rect(3.406em 1000em 4.157em -999.997em); top: -4.002em; left: 0.003em;"><span class="mi" id="MathJax-Span-471" style="font-family: MathJax_Math-italic;">n</span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span><span style="position: absolute; top: -3.851em; left: 0.603em;"><span class="texatom" id="MathJax-Span-472"><span class="mrow" id="MathJax-Span-473"><span class="mi" id="MathJax-Span-474" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span class="mi" id="MathJax-Span-475" style="font-size: 70.7%; font-family: MathJax_Math-italic;">n</span></span></span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span></span></span><span class="mo" id="MathJax-Span-476" style="font-family: MathJax_Main; padding-left: 0.203em;">+</span><span class="msubsup" id="MathJax-Span-477" style="padding-left: 0.203em;"><span style="display: inline-block; position: relative; width: 1.704em; height: 0px;"><span style="position: absolute; clip: rect(3.406em 1000em 4.157em -999.997em); top: -4.002em; left: 0.003em;"><span class="mi" id="MathJax-Span-478" style="font-family: MathJax_Math-italic;">n</span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span><span style="position: absolute; top: -3.851em; left: 0.603em;"><span class="texatom" id="MathJax-Span-479"><span class="mrow" id="MathJax-Span-480"><span class="mi" id="MathJax-Span-481" style="font-size: 70.7%; font-family: MathJax_Math-italic;">o</span><span class="mi" id="MathJax-Span-482" style="font-size: 70.7%; font-family: MathJax_Math-italic;">u</span><span class="mi" id="MathJax-Span-483" style="font-size: 70.7%; font-family: MathJax_Math-italic;">t</span></span></span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span><span style="position: absolute; clip: rect(0.853em 1000em 1.204em -999.997em); top: -1.249em; left: 0.003em;"><span style="border-left-width: 4.307em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 1.25px; vertical-align: 0.003em;"></span><span style="display: inline-block; width: 0px; height: 1.054em;"></span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.105em;"></span></span></span><span style="border-left-width: 0.003em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 2.558em; vertical-align: -0.997em;"></span></span></nobr></span>と定義され、正規分布からサンプリングされます。また、バイアスは全てゼロに初期化されています。</p><p>ネットワークは、約300万ものサンプルによる巨大なデータセットで学習されています。データセットの画像は、動物やアウトドアの場面といったような自然の画像を使用しました。いくつかの画像については、動物のイラストやテキストが含まれていたため、このデータセットから削除しています。また、各画像のサイズや画質はまちまちだったので、合計ピクセル数が、64万ピクセル以上である画像に絞ることにしました。</p><p>データセット内のサンプルは、それぞれ低解像度と高解像度の画像の組み合わせになっています。入力値”x”で表す低解像度の画像は、高解像度の画像をある倍率でダウンスケールしたもので、求められる出力値”y”は、元々の高解像度の画像となります。入力データには、多少のノイズと歪みを加えておきました。データに対しては、ゼロ平均(データセット全体の平均値を利用)・同一の分散(データセットでの標準偏差で割り算)となるように標準化を行いました。</p><p>データセットは、トレーニング、テスト、バリデーションのサブセットに分かれており、それぞれ、80%、10%、10%の割合です。</p><p>最大ノルム制約は、そのレイヤー上の全ユニットの重みベクトルに対し、大きさの絶対的な上限を設ける制約です。この制約により、勾配の更新が大きすぎた場合にネットワークの重みが”爆発”してしまうのを防ぐことができます。最大ノルム制約は、最後の線形ガウス層以外のどの層でも使われます。ノルムの大きな重みベクトルは全ての畳み込み層で用いられますが、他の層ではノルムはそれほど大きくなりません。</p><p>L2規則とは、大きい重みベクトル<span class="MathJax" id="MathJax-Element-30-Frame"><nobr><span class="math" id="MathJax-Span-484" role="math" style="width: 1.204em; display: inline-block;"><span style="display: inline-block; position: relative; width: 1.054em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.604em 1000em 2.605em -999.997em); top: -2.45em; left: 0.003em;"><span class="mrow" id="MathJax-Span-485"><span class="mstyle" id="MathJax-Span-486"><span class="mrow" id="MathJax-Span-487"><span class="mi" id="MathJax-Span-488" style="font-family: MathJax_Math-italic;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.103em;"></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.455em;"></span></span></span><span style="border-left-width: 0.003em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 0.892em; vertical-align: -0.053em;"></span></span></nobr></span>を使うネットワークにペナルティを与えることです。これは規則の強さとしてパラメータ<span class="MathJax" id="MathJax-Element-31-Frame"><nobr><span class="math" id="MathJax-Span-489" role="math" style="width: 0.703em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.603em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.604em 1000em 2.605em -999.997em); top: -2.45em; left: 0.003em;"><span class="mrow" id="MathJax-Span-490"><span class="mstyle" id="MathJax-Span-491"><span class="mrow" id="MathJax-Span-492"><span class="mi" id="MathJax-Span-493" style="font-family: MathJax_Math-italic;">λ</span></span></span></span><span style="display: inline-block; width: 0px; height: 2.455em;"></span></span></span><span style="border-left-width: 0.003em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 0.892em; vertical-align: -0.053em;"></span></span></nobr></span>で設定されます。<span class="MathJax" id="MathJax-Element-32-Frame"><nobr><span class="math" id="MathJax-Span-494" role="math" style="width: 3.306em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.955em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(0.953em 1000em 3.306em -999.997em); top: -2.45em; left: 0.003em;"><span class="mrow" id="MathJax-Span-495"><span class="mstyle" id="MathJax-Span-496"><span class="mrow" id="MathJax-Span-497"><span class="mfrac" id="MathJax-Span-498"><span style="display: inline-block; position: relative; width: 0.603em; height: 0px; margin-right: 0.103em; margin-left: 0.103em;"><span style="position: absolute; clip: rect(3.206em 1000em 4.157em -999.997em); top: -4.702em; left: 50%; margin-left: -0.248em;"><span class="mn" id="MathJax-Span-499" style="font-family: MathJax_Main;">1</span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span><span style="position: absolute; clip: rect(3.206em 1000em 4.157em -999.997em); top: -3.301em; left: 50%; margin-left: -0.248em;"><span class="mn" id="MathJax-Span-500" style="font-family: MathJax_Main;">2</span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span><span style="position: absolute; clip: rect(0.853em 1000em 1.204em -999.997em); top: -1.249em; left: 0.003em;"><span style="border-left-width: 0.603em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 1.25px; vertical-align: 0.003em;"></span><span style="display: inline-block; width: 0px; height: 1.054em;"></span></span></span></span><span class="mi" id="MathJax-Span-501" style="font-family: MathJax_Math-italic;">λ</span><span class="msubsup" id="MathJax-Span-502"><span style="display: inline-block; position: relative; width: 1.554em; height: 0px;"><span style="position: absolute; clip: rect(3.156em 1000em 4.157em -999.997em); top: -4.002em; left: 0.003em;"><span class="mi" id="MathJax-Span-503" style="font-family: MathJax_Math-italic;">W<span style="display: inline-block; overflow: hidden; height: 1px; width: 0.103em;"></span></span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span><span style="position: absolute; top: -4.402em; left: 1.154em;"><span class="mn" id="MathJax-Span-504" style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.455em;"></span></span></span><span style="border-left-width: 0.003em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 2.392em; vertical-align: -0.831em;"></span></span></nobr></span>項としてコスト関数に加えられます。最適化アルゴリズムは、コスト関数が従来通り最小化している間、ウエイトを小さくしようします。畳み込み層と最初の全結合層には、軽度の規則が適用され、その他の全結合層には、強い値を使います。</p><p><a href="http://www.cs.toronto.edu/~rsalakhu/papers/srivastava14a.pdf" rel="nofollow" title="" class="ext-link">ドロップアウト</a>は、各トレーニングステップで、ユニットを層からランダムに”ドロップ”し、モデル内に”サブ構造”を作り上げます。大きなネットワークの中の小さなネットワークに対する一種のサンプリングとして見ることができます。そこに含まれるユニットのウエイトだけが更新され、ネットワークが少数のユニットに依存しないようにします。ユニットの削除のプロセスは、実行中、繰り返し行われ、残っているユニットだけが変更されていきます。全ての畳み込み層は、1.0に近い高い包含確率を持っていますが、最後の2つの全結合層では、その半分のユニット数となっています。</p><p><img src="http://engineering.flipboard.com/assets/convnets/dropout.png"></p><p>モデルは、学習セット全体で250回のエポックに対して、1回のバッチサイズが250である確率的勾配降下法で学習されました。バッチサイズが小さいとパータベーションが起こって、それが有益に働く場合もありますが、バッチサイズが大きければ更新がスムーズになり、GPUを効果的に使えるようになります。</p><p>ネットワークは平均二乗誤差関数を最小化するために学習されます。学習率のスケールは全てのウエイトとバイアスで使われていました。ウエイト（各層）は、<span class="MathJax" id="MathJax-Element-33-Frame"><nobr><span class="math" id="MathJax-Span-505" role="math" style="width: 6.009em; display: inline-block;"><span style="display: inline-block; position: relative; width: 5.408em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.204em 1000em 3.706em -999.997em); top: -2.7em; left: 0.003em;"><span class="mrow" id="MathJax-Span-506"><span class="mstyle" id="MathJax-Span-507"><span class="mrow" id="MathJax-Span-508"><span class="mn" id="MathJax-Span-509" style="font-family: MathJax_Main;">1</span><span class="mo" id="MathJax-Span-510" style="font-family: MathJax_Main; padding-left: 0.203em;">−</span><span class="mfrac" id="MathJax-Span-511" style="padding-left: 0.203em;"><span style="display: inline-block; position: relative; width: 0.603em; height: 0px; margin-right: 0.103em; margin-left: 0.103em;"><span style="position: absolute; clip: rect(3.206em 1000em 4.157em -999.997em); top: -4.702em; left: 50%; margin-left: -0.248em;"><span class="mn" id="MathJax-Span-512" style="font-family: MathJax_Main;">1</span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span><span style="position: absolute; clip: rect(3.206em 1000em 4.157em -999.997em); top: -3.301em; left: 50%; margin-left: -0.248em;"><span class="mn" id="MathJax-Span-513" style="font-family: MathJax_Main;">2</span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span><span style="position: absolute; clip: rect(0.853em 1000em 1.204em -999.997em); top: -1.249em; left: 0.003em;"><span style="border-left-width: 0.603em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 1.25px; vertical-align: 0.003em;"></span><span style="display: inline-block; width: 0px; height: 1.054em;"></span></span></span></span><span class="msubsup" id="MathJax-Span-514"><span style="display: inline-block; position: relative; width: 2.905em; height: 0px;"><span style="position: absolute; clip: rect(2.755em 1000em 5.008em -999.997em); top: -4.002em; left: 0.003em;"><span class="mfrac" id="MathJax-Span-515"><span style="display: inline-block; position: relative; width: 2.255em; height: 0px; margin-right: 0.103em; margin-left: 0.103em;"><span style="position: absolute; clip: rect(3.406em 1000em 4.307em -999.997em); top: -4.702em; left: 50%; margin-left: -0.448em;"><span class="msubsup" id="MathJax-Span-516"><span style="display: inline-block; position: relative; width: 0.903em; height: 0px;"><span style="position: absolute; clip: rect(3.406em 1000em 4.157em -999.997em); top: -4.002em; left: 0.003em;"><span class="mi" id="MathJax-Span-517" style="font-family: MathJax_Math-italic;">n</span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span><span style="position: absolute; top: -3.851em; left: 0.603em;"><span class="mi" id="MathJax-Span-518" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span><span style="position: absolute; clip: rect(3.406em 1000em 4.307em -999.997em); top: -3.301em; left: 50%; margin-left: -1.049em;"><span class="msubsup" id="MathJax-Span-519"><span style="display: inline-block; position: relative; width: 2.105em; height: 0px;"><span style="position: absolute; clip: rect(3.406em 1000em 4.157em -999.997em); top: -4.002em; left: 0.003em;"><span class="mi" id="MathJax-Span-520" style="font-family: MathJax_Math-italic;">n</span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span><span style="position: absolute; top: -3.851em; left: 0.603em;"><span class="texatom" id="MathJax-Span-521"><span class="mrow" id="MathJax-Span-522"><span class="mi" id="MathJax-Span-523" style="font-size: 70.7%; font-family: MathJax_Math-italic;">t</span><span class="mi" id="MathJax-Span-524" style="font-size: 70.7%; font-family: MathJax_Math-italic;">o</span><span class="mi" id="MathJax-Span-525" style="font-size: 70.7%; font-family: MathJax_Math-italic;">t</span><span class="mi" id="MathJax-Span-526" style="font-size: 70.7%; font-family: MathJax_Math-italic;">a</span><span class="mi" id="MathJax-Span-527" style="font-size: 70.7%; font-family: MathJax_Math-italic;">l</span></span></span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span><span style="position: absolute; clip: rect(0.853em 1000em 1.204em -999.997em); top: -1.249em; left: 0.003em;"><span style="border-left-width: 2.255em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 1.25px; vertical-align: 0.003em;"></span><span style="display: inline-block; width: 0px; height: 1.054em;"></span></span></span></span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span><span style="position: absolute; top: -4.852em; left: 2.455em;"><span class="mn" id="MathJax-Span-528" style="font-size: 70.7%; font-family: MathJax_Main;">2</span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.705em;"></span></span></span><span style="border-left-width: 0.003em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 2.558em; vertical-align: -0.997em;"></span></span></nobr></span>という式で表され、<span class="MathJax" id="MathJax-Element-34-Frame"><nobr><span class="math" id="MathJax-Span-529" role="math" style="width: 1.054em; display: inline-block;"><span style="display: inline-block; position: relative; width: 0.953em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.504em 1000em 2.405em -999.997em); top: -2.1em; left: 0.003em;"><span class="mrow" id="MathJax-Span-530"><span class="mstyle" id="MathJax-Span-531"><span class="mrow" id="MathJax-Span-532"><span class="msubsup" id="MathJax-Span-533"><span style="display: inline-block; position: relative; width: 0.903em; height: 0px;"><span style="position: absolute; clip: rect(3.406em 1000em 4.157em -999.997em); top: -4.002em; left: 0.003em;"><span class="mi" id="MathJax-Span-534" style="font-family: MathJax_Math-italic;">n</span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span><span style="position: absolute; top: -3.851em; left: 0.603em;"><span class="mi" id="MathJax-Span-535" style="font-size: 70.7%; font-family: MathJax_Math-italic;">i</span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.105em;"></span></span></span><span style="border-left-width: 0.003em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 0.781em; vertical-align: -0.219em;"></span></span></nobr></span>は現在の層の位置、<span class="MathJax" id="MathJax-Element-35-Frame"><nobr><span class="math" id="MathJax-Span-536" role="math" style="width: 2.405em; display: inline-block;"><span style="display: inline-block; position: relative; width: 2.155em; height: 0px; font-size: 111%;"><span style="position: absolute; clip: rect(1.504em 1000em 2.405em -999.997em); top: -2.1em; left: 0.003em;"><span class="mrow" id="MathJax-Span-537"><span class="mstyle" id="MathJax-Span-538"><span class="mrow" id="MathJax-Span-539"><span class="msubsup" id="MathJax-Span-540"><span style="display: inline-block; position: relative; width: 2.105em; height: 0px;"><span style="position: absolute; clip: rect(3.406em 1000em 4.157em -999.997em); top: -4.002em; left: 0.003em;"><span class="mi" id="MathJax-Span-541" style="font-family: MathJax_Math-italic;">n</span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span><span style="position: absolute; top: -3.851em; left: 0.603em;"><span class="texatom" id="MathJax-Span-542"><span class="mrow" id="MathJax-Span-543"><span class="mi" id="MathJax-Span-544" style="font-size: 70.7%; font-family: MathJax_Math-italic;">t</span><span class="mi" id="MathJax-Span-545" style="font-size: 70.7%; font-family: MathJax_Math-italic;">o</span><span class="mi" id="MathJax-Span-546" style="font-size: 70.7%; font-family: MathJax_Math-italic;">t</span><span class="mi" id="MathJax-Span-547" style="font-size: 70.7%; font-family: MathJax_Math-italic;">a</span><span class="mi" id="MathJax-Span-548" style="font-size: 70.7%; font-family: MathJax_Math-italic;">l</span></span></span><span style="display: inline-block; width: 0px; height: 4.007em;"></span></span></span></span></span></span></span><span style="display: inline-block; width: 0px; height: 2.105em;"></span></span></span><span style="border-left-width: 0.003em; border-left-style: solid; display: inline-block; overflow: hidden; width: 0px; height: 0.781em; vertical-align: -0.219em;"></span></span></nobr></span>は全層の数を示しています。これで前半層の収束を補助する学習率をスケーリングしました。また、全てのバイアスには2.0の学習率乗数がありました。Nesterov momentumは、最初の値は0.15で使われていましたが、45のエポックで0.7まで増加されました。</p><p>ネットワークの学習にはAmazon EC2のg2.2xlargeというインスタンスを利用し、スピードアップのために<a href="https://developer.nvidia.com/cudnn" rel="nofollow" title="" class="ext-link">NVIDIAのcuDNN</a>というライブラリを加えました。最終モデルの学習にかかった時間は、およそ19時間です。</p><p>大部分のハイパーパラメータを選択するために、Amazonのg2.2xlargeインスタンスのクラスタ上で動作する、社内のハイパーパラメータ最適化ライブラリを使いました。学習のデータセットとバリデーションのデータセットの一部を使うことで、これを実行します。このプロセスには4週間ほどかけて、500種類くらいの異なる構成を評価しました。</p><p>この問題を対処する上で、うまくいかなかった例を挙げます。</p><p>私が学んだ、より大きなネットワークを扱うために最も重要な事は、ウエイトの初期化を正しく行うことの大切さでした。これがモデルの学習の出来に最も影響を与えると感じたのは、いくつか他のハイパーパラメータを選択した後でした。初期化がモデルにどのような影響を与えるかを理解するため、時間を割いて異なる初期化の技術を調べるのはいい考えです。異なる初期化スキームを扱っている論文や機械学習ライブラリが沢山あるので、そこから簡単に学ぶことができます。</p><p>私たちの目標は、バイキュービック法など、他の画像拡大アルゴリズムの必要性を排除したり、置き換えたりすることではなく、異なる技術や方法を駆使して質を向上させようと試みることでした。使用した主なユースケースは、高解像度の画像が使用できない状況で、低解像度の画像を拡大するというものでした。私たちが使っていたプラットフォーム上では、時折この状況が見られました。</p><p>静止画像の主要なユースケースのみならず、この技術はGIFなど異なるメディアフォーマットに適用できます。GIFは切り離されたフレームに分割し、拡大して、リパッケージすることができました。</p><p>私たちが思いつく最終的なユースケースは、帯域幅を抑えることでした。小さい画像をクライアントに送り、クライアントサイド版のこのモデルを実行して大きな画像を得ることができます。これは、カスタムソリューション、または<a href="http://cs.stanford.edu/people/karpathy/convnetjs/" rel="nofollow" title="" class="ext-link">ConvNetJS</a>など、利用可能なニューラルネットワークのjavascript実装を用いて達成できるはずです。</p><p>この問題の領域には多くの可能性が秘められていて、以下のような突拍子もない案も含めて、試してみるべきことが沢山あると感じました。</p><p>原物と同じ見た目を追及することは困難です。どんなに努力をしても、最後の数パーセントの質を絞り出すことができません。私たちは定期的に製品を見直し、最初は明確でなかったり、可能には思えなかったりしても、この数パーセントの違いは何かを再考します。これは製品全体に関係する問題ではないかもしれません。しかし、質を向上させるためには、大まかですが良い方法だと思っています。</p><p>読者の皆さんが、この投稿を楽しみ、内容に興味を持っていただけたら嬉しく思います。また、非常に有意義なインターンシップの経験をさせてもらったFlipboard社の皆さんには感謝を伝えたいと思います。今回のインターンシップの中では、多くを学び、傑出した方々に出会い、かけがえのない経験をすることができました。</p><p>機械学習、大規模データセット、素晴らしい人々と共に面白いプロジェクトに従事することに興味があれば、ぜひ求人に応募してください。<a href="https://ja-jp.about.flipboard.com/careers/?noredirect=ja_JP" rel="nofollow" title="" class="ext-link">ただいま、人員募集中です</a>！</p><p>また、私のTwitter（<a href="https://twitter.com/normantasfi" rel="nofollow" title="" class="ext-link">@normantasfi</a>）も、どんどんフォローしてくださいね。</p><p><em>この記事を執筆するにあたり、提案や編集をしてくれた<a href="https://twitter.com/charlietuna" rel="nofollow" title="" class="ext-link">Charles</a>、<a href="https://twitter.com/emilsjolander" rel="nofollow" title="" class="ext-link">Emil</a>、<a href="https://twitter.com/anhbmai" rel="nofollow" title="" class="ext-link">Anh</a>、<a href="https://twitter.com/mikeklaas" rel="nofollow" title="" class="ext-link">Mike Klaas</a>、<a href="https://twitter.com/bapjuseyo" rel="nofollow" title="" class="ext-link">Michael Johnston</a>に、感謝の意を示したいと思います。また、サーバのセットアップや質問のために、いつも時間を割いて助けてくれた<a href="https://twitter.com/gregoryscallan" rel="nofollow" title="" class="ext-link">Greg</a>には、特に大きな感謝を捧げます。</em></p>
